{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde1e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from src.utils.barrido import NNTrainer\n",
    "from src.config import PATHS\n",
    "\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb81d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = PATHS[\"training_data_folder\"]\n",
    "tokenizer_folder = PATHS[\"tokenizer_folder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46a4db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = NNTrainer(\n",
    "    nombre='equivalencia',\n",
    "    tokenizer_file=tokenizer_folder / 'tokenizer_5.pkl',\n",
    "    path_dataset=dataset_folder / 'bert_data_equivalencia_5.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58929b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e70ee7e57c834e3ea529dfa42088cfb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ejecutando punto...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b67c87e456042489b2363493415e364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd4050a1760421f8584432b4798c663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac558060c864f2f9f6b11772e98c191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab494d0345d84f32ac5409213847a975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c292d2132847959e2355a058d0346c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bebe1c1de906421d9cf18f6687f6c848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81df2874f8074b2fb69e744bfb385e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e745be5dbc324e719c3404bf6780dcbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfee0b53bacb4f11924f0b162d08e6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420589d9ff374c85ac2cc42402d11b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/2130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1edb67c1a83e4374a64fa6c494cd34d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/2130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff565391f3b47d894eaecfb451c6729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/2130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335c9c38cca94504bde9a424bf5515c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5ed91d0b244f0b9b6f11aa47da5ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98565ee664cd48aa8404933771ad81bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a35013a083cd42619631035b9e0e070e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c524f3a09c2a41168c64b511ab5103db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8814b903704ec88361b6b2ca8761e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0668c0d0ee47a1ba07f97e89695292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6ee905993c433f8c1f598b51feaceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00bedd41273a4c87b70d3ecbafccbe7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6033cba31b784a63ab64bbe21e80e13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dcef11c24c84ef09551bb087a750099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56ece29607649bbabd76bc01ed7df40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4fac2b3d3694cd787f4d3d0818683e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25024e35596c459ab08318d6760448c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/2130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09eb27cef32c4dbda8646d94d48476cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/2130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961d03ab10ad4de9ba29461f3bb0a308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/2130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b186270f8847f68f0c32672c5e4563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd70082ee7484bcda225d41a7e2caf37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b459faaafe784a9689f57ffdaf1724c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda9c4cde98b4fa4ad1dc04dc7896a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512ef10ed2fc4e73a301c68c7d3c68a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d94d22faaf948269365336c9269df48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/2130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7583033a1a094858b3a3dae079879c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/2130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b8b5c1fb004d839d20388e2c27be74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/2130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b01ed291ea4f7c83c3a226be9d0f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2298fc6c3d6c4298b593df31747cce36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145083c983a84fe498290d73764081fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efcecc8829264914928cf7a2f21e754e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (32, 10, 2, 0.4, 'adam', 0.0001, 0.1, 1), 'message': 'Error: loss.item()=nan---next_sentence_prediction=tensor([[-0.9926, -0.1228]], grad_fn=<AddmmBackward0>)\\nmasked_language=tensor([[[ 0.6330, -0.5401, -0.4905, -0.2875,  0.5209, -1.4393, -0.1735,\\n          -0.7531,  0.5240, -0.8471, -0.5373, -0.9312,  0.7706, -1.0290,\\n           0.3815,  0.8341, -0.6442,  1.0276,  0.3808, -0.6916, -0.0399,\\n          -0.7026,  0.9479, -0.2729, -0.3086, -0.0595,  0.1314,  0.9327,\\n           0.8023,  0.1291,  0.7731, -0.6390, -0.0985,  0.2472,  0.8053,\\n           0.2393,  0.2995,  0.0185,  0.3466, -0.4442,  0.2406]],\\n\\n        [[ 0.0442, -0.2561,  0.3515, -0.3888, -0.3348, -1.2630,  0.0882,\\n          -0.6791,  0.2616, -0.5348, -0.4634, -0.8301,  0.6843, -1.0532,\\n           0.6121,  1.1965, -0.5020,  1.0531, -0.0439, -0.4260, -0.4710,\\n          -0.5962,  0.7753, -0.6855, -0.0090, -0.1541, -0.3733,  0.7957,\\n           0.3054,  0.4261,  0.5617, -0.3798, -0.0722,  0.1621,  0.3474,\\n           0.6150, -0.0703, -0.4828,  0.4105, -0.5026, -0.2270]],\\n\\n        [[ 0.8542,  0.1261,  0.0371, -0.6576, -0.0309, -0.5264, -0.2459,\\n           0.2286, -0.1931, -0.3868, -0.5085, -0.5233,  0.2384, -1.1603,\\n           0.0515,  0.8165, -0.2415,  0.7747,  0.1167, -0.5773, -0.6448,\\n          -0.8685,  0.3677, -0.6119,  0.0679,  0.3265,  0.2309,  0.9251,\\n           0.4841,  0.2921,  0.4510,  0.2710, -0.6197, -0.2724,  0.6495,\\n           0.5481, -0.4642, -0.6219, -0.5080, -0.2371,  0.2961]],\\n\\n        [[ 0.7835,  0.1500, -0.6564, -0.4244, -0.1314, -1.8659,  0.4631,\\n          -0.1459, -0.2289, -0.9084, -0.1940, -0.3455,  0.9738, -0.0372,\\n           0.2717,  0.9241, -0.9362,  1.0271,  0.1946, -0.4562,  0.3090,\\n           0.3363,  0.4967,  0.0852, -0.1738, -0.3767, -0.3753,  0.2503,\\n          -0.0710,  0.3022,  0.1004, -0.8941, -0.3181, -0.1723,  1.2432,\\n           0.2391,  0.2079,  0.5278,  0.3672,  0.1566, -0.4658]],\\n\\n        [[ 0.5389,  0.5516, -0.6273, -0.1409, -0.5423, -1.5403,  0.3626,\\n          -0.3300, -0.3948, -0.6393, -0.0064,  0.1103,  0.4039, -0.0193,\\n           0.5251,  0.8421, -1.0367,  1.5601,  0.7809,  0.4958, -0.5248,\\n          -0.0068,  0.3402, -0.0895,  0.4054,  0.0650, -0.1852,  0.1332,\\n           0.2011,  0.5370, -0.0751, -0.7215, -0.1579, -0.1300,  0.8421,\\n           0.4327,  0.1975,  0.8718,  0.2696, -0.2184, -0.7184]],\\n\\n        [[-0.2314,  0.0885,  0.1387, -0.8091, -0.0962, -1.3391, -0.0223,\\n           0.0115,  0.1092, -0.5700, -0.3179, -0.8395,  0.9153, -1.2484,\\n           0.8946,  1.1478, -0.9330,  0.8600,  0.2538, -0.2325, -0.4578,\\n          -0.3017,  0.7862, -0.6594,  0.2448, -0.1723,  0.2386,  0.5079,\\n           0.1813,  0.3253, -0.0778, -0.6250,  0.1498,  0.0243,  0.9399,\\n           0.3799, -0.0718,  0.1676,  0.3865, -0.4574, -0.1061]],\\n\\n        [[ 0.5375,  0.4181, -0.1871, -0.4528, -0.1480, -1.3624,  0.4514,\\n          -0.6002, -0.0480, -0.5867, -0.4418, -0.5684,  0.6507, -0.4677,\\n           0.7184,  1.1818, -0.9338,  1.2666, -0.0345, -0.3956, -0.2784,\\n          -0.0486,  1.0011, -0.1659,  0.1503,  0.0394,  0.3116,  0.4890,\\n           0.4908,  0.4961,  0.2469, -0.6258, -0.4904,  0.2413,  0.8032,\\n           0.5395,  0.0822,  0.0256,  0.1291, -0.1845,  0.0303]],\\n\\n        [[ 0.0583,  0.2839, -0.3320, -0.5455,  0.0320, -0.9134,  0.1715,\\n          -0.4274,  0.3176, -0.7388,  0.4321, -1.1547,  1.0452, -0.5148,\\n           0.7332,  1.1570, -0.7321,  0.8487,  0.5503,  0.1989,  0.0039,\\n          -0.2204,  1.3572, -0.0374, -0.4820,  0.1853,  0.4029, -0.0504,\\n           0.4091,  0.1524, -0.2059, -0.6046, -0.2816,  0.0095,  1.3810,\\n           0.0951,  0.5298,  0.2917,  0.8702, -0.2058,  0.4307]],\\n\\n        [[ 0.3660, -0.0029, -0.9500, -0.6340, -0.4300, -1.8532,  0.4314,\\n           0.1981, -0.2394, -0.7404,  0.2394, -0.4636,  0.4199, -0.4029,\\n           0.4227,  1.0263, -0.8290,  0.8108,  0.5190, -0.2069, -0.1603,\\n           0.4226,  0.8065, -0.1269,  0.2319, -0.1679,  0.4475,  0.3172,\\n          -0.2546,  0.7782,  0.2212, -0.6749, -0.4256, -0.3939,  1.4501,\\n           0.2576, -0.0923,  0.3833,  0.4330, -0.2969, -0.0967]],\\n\\n        [[ 0.6330,  0.5010, -0.0614, -0.6536,  0.3680, -1.5260,  0.3927,\\n          -0.1616, -0.3792, -0.9052,  0.0395, -0.6301,  0.7771, -0.5488,\\n           0.7282,  0.9171, -0.7115,  0.9150, -0.1513, -0.6004, -0.0510,\\n          -0.3056,  0.8358, -0.0465,  0.1473, -0.4508,  0.0202,  0.3240,\\n           0.2949,  0.2778,  0.1101, -0.7071, -0.3301, -0.0068,  1.0594,\\n           0.3840, -0.4331,  0.4386,  0.0599, -0.0780, -0.2514]],\\n\\n        [[ 0.3738, -0.2036,  0.1590, -0.4480, -0.0156, -1.6940,  0.6593,\\n          -0.9008,  0.0741, -0.3464, -0.2285, -0.3026,  0.4670, -0.5026,\\n           0.2565,  0.7260, -0.8683,  1.4045,  0.1341,  0.5334,  0.0153,\\n          -0.0250,  0.6624, -0.3265,  0.5835, -0.1808,  0.4143,  0.0261,\\n           0.2176,  0.6316,  0.1395, -0.7495, -0.3409,  0.0258,  0.5336,\\n           0.0058,  0.1531,  0.9149,  0.3537, -0.3761, -0.4401]],\\n\\n        [[ 0.6779,  0.5169, -0.2082, -0.1953, -0.0740, -0.7396,  0.3831,\\n          -0.5070, -0.1595, -0.1125, -0.4601, -0.6881,  0.3534, -0.7518,\\n           1.0976,  0.9815, -0.3211,  1.1933,  0.4265,  0.5475, -0.6570,\\n          -0.2030,  0.6971, -0.4414,  0.6249,  0.4051, -0.0062,  0.3586,\\n           0.5358,  1.0052,  0.5196, -0.7060, -0.3686,  0.3052,  0.4565,\\n           0.1752,  0.1063,  0.1513,  0.2211, -0.3416,  0.1618]],\\n\\n        [[ 0.5031,  0.6096, -0.3514, -0.1443, -0.4221, -1.4533,  0.6415,\\n          -0.1591, -0.0753, -0.0045,  0.1827, -0.5764,  0.4007,  0.4109,\\n           0.8449,  1.0739, -0.7090,  1.4387,  0.3393,  0.6188, -0.0409,\\n           0.1505,  0.7837,  0.0177,  0.3953,  0.2653,  0.0967, -0.2157,\\n           0.4344,  0.2422, -0.1500, -0.4395, -0.6182, -0.0161,  1.0274,\\n           0.4997,  0.5381,  0.6863,  0.4448,  0.1740, -0.1518]],\\n\\n        [[ 0.7488,  0.4561, -0.2077,  0.1673, -0.0114, -1.1239,  0.6123,\\n          -0.5042, -0.1187, -0.1555,  0.0187, -0.4806,  0.4445,  0.1587,\\n           0.7176,  1.2015, -0.3699,  1.3093,  0.4913,  0.4122, -0.5689,\\n          -0.1476,  0.8848, -0.3243,  0.5511, -0.1308, -0.2005,  0.3252,\\n           0.7634,  0.6179, -0.0285, -0.1418, -0.1988,  0.1108,  1.0986,\\n           0.1316,  0.0373,  0.5524,  0.1816,  0.3408, -0.4134]]],\\n       grad_fn=<ViewBackward0>)\\nnext_loss=tensor(0.3500, grad_fn=<NllLossBackward0>)\\nmask_loss=tensor(nan, grad_fn=<NllLossBackward0>)\\ntotal_loss=74.29624247550964\\n bert_inputs=tensor([[ 2],\\n        [ 5],\\n        [24],\\n        [19],\\n        [13],\\n        [17],\\n        [ 3],\\n        [40],\\n        [19],\\n        [13],\\n        [17],\\n        [ 3],\\n        [ 1],\\n        [ 1]])\\nbert_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1]])\\nsegment_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [0],\\n        [0]])\\nis_nexts=tensor([1])'}, {'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (4, 8, 2, 0.4, 'sgd', 1e-05, 0.1, 32), 'message': \"Error: 'accuracy'\"}, {'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (16, 4, 2, 0.4, 'adam', 0.001, 0.3, 1), 'message': 'Error: loss.item()=nan---next_sentence_prediction=tensor([[ 0.5151, -0.3330]], grad_fn=<AddmmBackward0>)\\nmasked_language=tensor([[[-7.1701e-01,  3.2126e-01,  7.0328e-02,  2.5112e-01, -3.4864e-01,\\n          -2.3814e-01, -3.1466e-01,  1.8318e-01,  6.0767e-01,  3.1141e-01,\\n           3.9902e-01, -6.1848e-01, -6.4851e-01, -8.3111e-01,  7.4725e-01,\\n           3.8215e-01,  8.2416e-01, -2.5133e-01, -1.7101e+00,  5.3768e-01,\\n          -7.1547e-01, -9.3553e-02, -1.0108e+00, -1.8344e-01,  1.8670e-01,\\n           6.3253e-01, -2.1177e-01,  6.4524e-01, -1.7307e+00,  1.0198e+00,\\n           8.4286e-01, -3.0097e-01, -5.5011e-01, -1.2577e-01,  2.2159e-01,\\n           7.3645e-01,  1.3156e+00,  4.4565e-01, -3.0537e-01,  3.9048e-01,\\n           1.0807e-01]],\\n\\n        [[ 5.7224e-01,  6.1081e-01,  1.4965e-01, -5.2763e-01,  4.4121e-01,\\n           2.3446e-01,  9.1915e-01,  9.7279e-01,  2.5121e-01, -5.0523e-01,\\n          -3.2007e-01, -2.1663e-01,  2.6771e-01,  3.2352e-01,  1.2089e-01,\\n           6.5207e-02,  4.6234e-01, -1.0231e-01, -9.8661e-01, -1.0049e+00,\\n          -1.2787e-01,  7.7424e-01, -9.2532e-01,  7.9320e-01,  3.3869e-02,\\n          -3.1282e-02, -5.8834e-01,  1.6765e-01, -4.5134e-01,  2.7924e-01,\\n           5.2708e-01,  1.6790e-01,  1.0773e-01,  6.3378e-01,  2.9579e-01,\\n           8.9581e-01, -7.7853e-01, -5.6400e-01,  2.5568e-01, -2.3781e-01,\\n           1.5122e-01]],\\n\\n        [[ 8.5388e-02,  2.0727e-01, -1.3123e-02, -7.0362e-01,  8.5067e-01,\\n           5.7733e-01,  1.1411e+00, -1.1459e+00,  8.1837e-02,  2.5100e-01,\\n          -1.0748e-02, -5.0404e-01,  1.7020e-01,  5.3007e-01, -1.6221e-01,\\n           1.0282e-01,  2.0077e-01, -2.8010e-01, -7.4343e-01, -8.4897e-01,\\n           4.8049e-01,  3.7841e-01, -2.9235e-01,  9.6559e-01, -1.4416e+00,\\n           2.4309e-02, -1.0321e+00,  6.7755e-01, -6.4328e-01,  6.0150e-01,\\n           7.1992e-01,  4.7680e-01, -8.5663e-01,  1.7761e-02,  2.4631e-01,\\n           4.0743e-02, -4.2561e-01, -4.8957e-01, -6.9715e-01, -2.4426e-01,\\n           6.2993e-01]],\\n\\n        [[-5.9268e-01,  1.3145e+00, -4.1651e-01, -6.7661e-01, -2.7160e-01,\\n          -1.1941e+00, -3.9409e-01, -4.7480e-01, -1.9672e-01, -3.7229e-01,\\n           3.2967e-01, -3.0521e-01, -3.6474e-01,  1.2722e-01,  8.9645e-01,\\n          -6.7246e-02,  6.4377e-01, -1.5092e+00,  3.4260e-01,  2.2464e-01,\\n          -1.6262e-01,  1.1509e-01, -5.6706e-01,  2.5176e-02,  4.1940e-01,\\n           8.1343e-01, -1.1478e+00, -5.1323e-01, -1.9548e-02, -2.6912e-01,\\n           8.5983e-01, -2.0667e-01, -1.6121e-01, -5.5655e-01, -1.1658e-01,\\n           6.3578e-01, -8.1378e-01,  9.6121e-01, -3.6826e-01,  8.7201e-01,\\n          -4.9591e-01]],\\n\\n        [[ 4.7186e-01,  7.1342e-01, -9.4726e-01, -3.8139e-01,  3.8051e-01,\\n           4.1646e-02,  8.4943e-01,  2.4253e-01,  3.8972e-01,  1.0051e+00,\\n           3.3379e-01,  6.3187e-03, -5.0868e-01,  4.8289e-01,  2.2704e-01,\\n           5.5486e-01,  1.0791e+00,  1.7594e-01, -1.6858e+00, -6.8345e-01,\\n          -1.4664e-01,  6.7831e-02, -1.6474e-01,  3.3576e-01, -3.5965e-01,\\n           4.9468e-01, -5.7591e-01,  5.7524e-02, -1.0548e+00,  7.9117e-01,\\n           9.8981e-01,  8.3768e-01,  4.0936e-02, -3.7443e-01,  2.1444e-01,\\n          -9.4466e-02, -3.4082e-01,  4.0241e-01, -1.2177e-01,  7.2139e-01,\\n           4.8046e-01]],\\n\\n        [[-5.5580e-01,  5.6956e-01, -2.1450e-01,  2.2354e-01,  2.3018e-01,\\n          -2.9796e-01, -8.1436e-01, -4.3980e-01,  2.5966e-01, -4.5450e-01,\\n           6.4022e-01, -5.4485e-01, -7.2469e-01,  4.2321e-01, -1.1641e-01,\\n          -3.6601e-01,  4.3800e-01, -5.8901e-01, -8.0919e-01, -8.6859e-01,\\n           3.7972e-01,  5.3177e-01, -6.2345e-01,  7.2208e-01,  2.1421e-01,\\n           8.7348e-01, -8.6441e-01,  1.5292e-02,  1.4092e-01,  2.5900e-01,\\n           3.3498e-01,  2.8667e-02, -2.5752e-01,  3.1076e-03,  1.5551e-01,\\n           6.0841e-01, -2.5261e-01,  5.3556e-01, -1.1771e+00, -2.4124e-01,\\n          -2.5349e-01]],\\n\\n        [[-4.2659e-01,  1.2132e+00, -2.5857e-01, -2.4981e-01,  1.0665e+00,\\n          -3.0251e-01, -8.9620e-01, -5.6895e-01,  1.8113e-01, -4.7778e-02,\\n           2.6402e-01,  4.3881e-02, -1.9495e-01,  3.2853e-01, -2.3538e-01,\\n          -5.7041e-01,  2.1150e-01, -4.7433e-01, -1.0207e+00, -1.1383e+00,\\n           5.0889e-01,  2.0268e-01, -3.6388e-01,  4.5107e-01,  1.2610e-01,\\n           6.0187e-01, -8.9740e-01, -4.8671e-01,  9.2957e-02, -5.4097e-03,\\n           2.2917e-01, -5.1021e-01, -2.6148e-01, -3.6687e-01, -6.5834e-02,\\n           4.7077e-01, -1.0570e+00,  5.1172e-01, -8.3788e-01, -1.6956e-01,\\n          -1.2430e-01]],\\n\\n        [[ 1.0272e+00, -1.0468e+00, -3.7849e-01,  8.5365e-01, -1.1052e-01,\\n           9.0345e-01,  5.8549e-01,  6.9792e-01,  1.1451e+00,  3.3075e-01,\\n          -4.7360e-01, -1.6117e-01, -4.3399e-01,  1.0545e-01,  3.3159e-02,\\n           6.0570e-01,  8.9592e-01,  1.4355e+00, -1.0249e+00,  2.8133e-01,\\n          -3.0678e-01,  4.6567e-01,  5.6315e-01,  4.8959e-01,  3.4232e-01,\\n          -1.6832e-01, -1.3322e-02,  1.2371e+00, -6.8182e-01,  1.0124e+00,\\n           1.2883e-01,  5.3464e-01, -2.7716e-01,  1.0513e-01,  3.3737e-02,\\n          -4.3398e-01,  1.1534e+00, -6.0964e-01,  3.9821e-01,  3.0774e-01,\\n           1.2479e-01]],\\n\\n        [[-5.3730e-01,  1.2284e+00, -1.4042e-01,  8.5026e-02, -5.6867e-01,\\n          -8.4161e-01, -1.0368e-01, -2.2905e-01,  3.2457e-01, -6.7742e-02,\\n          -5.1635e-01,  1.9178e-01, -1.1030e+00,  4.1687e-01,  1.0417e+00,\\n          -7.0985e-02,  6.7706e-01, -9.8882e-01, -9.7622e-02,  1.0128e-01,\\n          -6.4416e-01,  2.5100e-01, -4.6435e-01, -4.1059e-01,  1.0694e+00,\\n           4.6228e-01, -5.9408e-01, -1.1391e-01,  4.6933e-02,  9.1241e-02,\\n           3.8767e-01,  1.4612e-01, -3.2959e-01, -6.3605e-01, -5.7480e-01,\\n           7.8988e-01, -3.7580e-01,  8.0727e-01, -5.7127e-02,  7.5172e-01,\\n          -3.2065e-01]],\\n\\n        [[-6.3427e-01,  1.5121e+00, -2.8778e-01,  1.3183e-01,  8.6922e-01,\\n          -3.3217e-01,  1.1018e-01,  5.1467e-01,  4.1747e-02,  4.1507e-01,\\n           6.1125e-02,  1.3040e+00, -4.4564e-01,  9.0728e-01, -7.5807e-01,\\n          -4.2117e-01,  5.3936e-01, -7.3158e-03, -1.7506e+00, -7.1327e-01,\\n           2.5348e-01,  1.5200e-02, -7.3769e-01,  5.3925e-01,  3.0739e-01,\\n           8.2342e-01, -2.9376e-01,  1.7764e-01, -4.5684e-01,  2.3651e-01,\\n           4.9423e-01,  1.2336e-01,  3.5971e-01, -1.6491e-01,  1.5242e-01,\\n           5.8517e-01, -7.2619e-01,  1.4926e-02, -7.8328e-01, -1.3493e-03,\\n           3.6074e-01]],\\n\\n        [[-2.5085e-01,  1.0710e+00,  8.2171e-01, -4.5310e-02, -1.0840e-01,\\n           1.5446e-01, -7.3620e-01, -4.5385e-01,  7.9943e-01, -2.0205e-01,\\n          -1.0329e-01, -1.1746e+00, -1.7192e-01, -8.1908e-01,  4.3529e-01,\\n          -3.2720e-01,  5.9828e-01, -3.4669e-01, -7.1624e-01, -6.8762e-01,\\n          -5.4486e-01,  2.6044e-01,  1.0898e-01, -4.2812e-01,  4.2433e-02,\\n           2.6885e-01, -3.9047e-01, -2.1842e-01, -1.3996e+00,  1.4303e+00,\\n           2.2704e-01, -9.6163e-02, -2.6564e-01, -3.2358e-01,  6.3175e-01,\\n           6.6360e-01, -1.0008e-01,  5.8129e-01,  3.1243e-01, -2.3634e-01,\\n           1.7419e-01]],\\n\\n        [[-4.6669e-01,  1.3844e+00, -7.1804e-01, -3.8029e-02,  6.8118e-01,\\n          -5.6453e-01, -5.7588e-01,  3.5899e-01,  1.7947e-01,  3.7129e-01,\\n           6.0407e-01,  5.9405e-01, -2.7228e-01,  4.9591e-01, -2.8250e-01,\\n          -1.0098e-01,  1.0249e+00, -1.4393e-01, -9.4588e-01,  3.3468e-01,\\n          -1.9522e-01, -2.9150e-01, -8.8408e-02,  4.0877e-01,  2.5050e-01,\\n           1.0116e+00, -8.5171e-01, -1.0440e-02, -8.6519e-01,  3.6916e-01,\\n           1.0613e+00, -1.2395e-01,  3.7089e-01, -4.1368e-01,  3.9187e-01,\\n           1.0442e-01, -5.9414e-01,  5.6248e-01, -3.5341e-01,  8.3664e-01,\\n           9.1746e-02]]], grad_fn=<ViewBackward0>)\\nnext_loss=tensor(0.3564, grad_fn=<NllLossBackward0>)\\nmask_loss=tensor(nan, grad_fn=<NllLossBackward0>)\\ntotal_loss=124.61984276771545\\n bert_inputs=tensor([[ 2],\\n        [24],\\n        [21],\\n        [11],\\n        [16],\\n        [ 3],\\n        [40],\\n        [21],\\n        [11],\\n        [16],\\n        [ 3],\\n        [ 1]])\\nbert_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1]])\\nsegment_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [0]])\\nis_nexts=tensor([0])'}, {'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (32, 4, 4, 0.3, 'adam', 0.01, 0.3, 64), 'message': \"Error: 'accuracy'\"}, {'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (16, 6, 4, 0.2, 'adam', 0.0001, 0.3, 16), 'message': \"Error: 'accuracy'\"}, {'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (4, 8, 6, 0.4, 'sgd', 0.001, 0.2, 1), 'message': 'Error: loss.item()=nan---next_sentence_prediction=tensor([[-0.5044,  0.1069]], grad_fn=<AddmmBackward0>)\\nmasked_language=tensor([[[ 6.7123e-01, -7.5253e-02,  6.8565e-01, -6.6712e-02,  2.1862e-01,\\n           2.4617e-01,  4.8320e-01,  5.9677e-01, -1.8537e-01, -4.5113e-01,\\n           1.7239e-01, -2.2071e-01,  2.3060e-01,  7.6194e-01,  3.0318e-01,\\n          -7.8092e-02, -5.9052e-02,  9.8091e-01,  4.5902e-01, -3.3857e-01,\\n           7.9074e-02,  7.3762e-02, -7.2304e-01,  6.6313e-01,  2.5612e-02,\\n           4.7886e-01,  2.7968e-01, -9.2317e-02, -2.1131e-01,  1.0851e-01,\\n          -3.0950e-01,  6.3967e-01,  4.4314e-01,  1.1771e-01,  2.1609e-01,\\n           7.5956e-01,  5.3123e-01,  5.2976e-01,  7.4852e-01, -9.9075e-01,\\n           2.7045e-01]],\\n\\n        [[ 7.0005e-01, -2.1966e-01,  7.8542e-01, -2.7873e-02,  1.0880e-01,\\n           1.1518e-01,  4.7749e-01,  6.0398e-01, -1.1994e-01, -5.2262e-01,\\n           2.7172e-01, -9.3733e-02,  1.9729e-01,  7.0171e-01,  4.3837e-01,\\n          -1.1123e-02, -2.4052e-02,  8.0304e-01,  3.0438e-01, -3.3025e-01,\\n          -6.9938e-02,  1.2751e-01, -7.8193e-01,  5.3650e-01,  7.3345e-02,\\n           3.9366e-01,  2.3400e-01, -1.1392e-01, -3.5883e-01,  2.0065e-01,\\n          -2.2685e-01,  6.5609e-01,  4.1572e-01,  1.0738e-01,  1.4377e-01,\\n           6.2381e-01,  6.5550e-01,  4.1128e-01,  6.4693e-01, -1.0246e+00,\\n           1.3237e-01]],\\n\\n        [[ 6.5653e-01, -2.2913e-01,  7.6860e-01, -1.7256e-02,  8.5050e-02,\\n           1.3943e-01,  5.0248e-01,  5.9285e-01, -1.0573e-01, -5.4398e-01,\\n           2.3780e-01, -1.5220e-01,  2.1127e-01,  6.9841e-01,  4.1474e-01,\\n          -4.5174e-02, -3.7077e-02,  8.5377e-01,  2.9199e-01, -3.5572e-01,\\n          -6.6436e-02,  8.2353e-02, -7.6547e-01,  5.7253e-01,  3.8918e-02,\\n           4.0604e-01,  2.0856e-01, -1.0832e-01, -3.5348e-01,  2.0172e-01,\\n          -2.2791e-01,  6.0993e-01,  4.1550e-01,  8.2957e-02,  1.8907e-01,\\n           6.5620e-01,  6.1906e-01,  4.6279e-01,  6.6567e-01, -1.0541e+00,\\n           1.5304e-01]],\\n\\n        [[ 4.5109e-01,  1.1080e+00, -2.5686e-01, -5.4037e-01,  1.1331e+00,\\n           6.1119e-01, -1.9940e-01, -6.3519e-02, -6.7943e-01,  2.7257e-01,\\n          -5.4770e-01, -5.3737e-01,  4.7955e-01,  6.5239e-01, -3.4727e-01,\\n          -2.3062e-01, -2.5940e-01,  1.3556e+00,  1.4798e+00, -2.0450e-01,\\n           1.2124e+00,  2.3420e-01,  3.7277e-01,  5.0856e-01, -4.1680e-01,\\n           7.6394e-01,  5.3765e-01,  4.1158e-01,  1.1848e+00, -9.0498e-01,\\n          -8.3603e-01,  4.4606e-01,  3.0177e-01,  2.5745e-01, -7.2961e-03,\\n           1.1506e+00, -1.8937e-01,  7.1389e-01,  1.0482e+00, -7.4814e-02,\\n           6.4901e-01]],\\n\\n        [[ 1.0325e+00,  6.1269e-01,  4.4127e-01, -3.6971e-01,  9.2515e-01,\\n           3.7546e-01,  9.3152e-02,  5.7327e-01, -5.9716e-01,  9.7847e-02,\\n           1.5850e-01,  4.2569e-02,  2.0828e-01,  9.2571e-01,  1.0178e-01,\\n           9.8631e-02, -4.1979e-02,  9.3901e-01,  1.1728e+00, -5.5456e-02,\\n           6.2723e-01,  4.6456e-01, -5.4614e-01,  5.5309e-01,  1.9814e-01,\\n           6.0912e-01,  7.1977e-01, -3.0150e-03,  3.6368e-01, -3.2595e-01,\\n          -6.0358e-01,  1.0655e+00,  4.8607e-01,  4.3666e-01, -1.4253e-01,\\n           8.1678e-01,  4.8308e-01,  2.9578e-01,  8.5272e-01, -4.0875e-01,\\n           4.5894e-01]],\\n\\n        [[ 7.2415e-01,  5.3856e-03,  6.6507e-01, -1.0110e-01,  3.0512e-01,\\n           2.6739e-01,  4.4576e-01,  6.0863e-01, -2.3685e-01, -3.8550e-01,\\n           1.7861e-01, -1.8809e-01,  2.2458e-01,  7.9285e-01,  2.7836e-01,\\n          -5.5964e-02, -5.5080e-02,  9.8236e-01,  5.4808e-01, -3.0313e-01,\\n           1.4187e-01,  1.1941e-01, -7.1925e-01,  6.6308e-01,  5.5846e-02,\\n           4.9795e-01,  3.3893e-01, -8.9967e-02, -1.5120e-01,  6.3870e-02,\\n          -3.4539e-01,  7.0206e-01,  4.5500e-01,  1.5971e-01,  1.7812e-01,\\n           7.7057e-01,  5.3041e-01,  5.0361e-01,  7.6514e-01, -9.2856e-01,\\n           3.0024e-01]],\\n\\n        [[ 6.8338e-01,  1.5155e-02,  6.3721e-01, -9.8120e-02,  2.9847e-01,\\n           2.9846e-01,  4.6175e-01,  5.9312e-01, -2.3241e-01, -3.9380e-01,\\n           1.3799e-01, -2.4788e-01,  2.4050e-01,  7.9239e-01,  2.4519e-01,\\n          -9.0133e-02, -6.9863e-02,  1.0388e+00,  5.5454e-01, -3.2430e-01,\\n           1.6260e-01,  7.9079e-02, -6.9265e-01,  6.9962e-01,  1.9962e-02,\\n           5.1565e-01,  3.2179e-01, -7.9728e-02, -1.2675e-01,  5.1190e-02,\\n          -3.5526e-01,  6.5993e-01,  4.5513e-01,  1.4050e-01,  2.1906e-01,\\n           8.0910e-01,  4.8625e-01,  5.5585e-01,  7.8931e-01, -9.4429e-01,\\n           3.2874e-01]],\\n\\n        [[ 7.0815e-01, -2.2175e-01,  7.9070e-01, -2.8818e-02,  1.1001e-01,\\n           1.0706e-01,  4.7244e-01,  6.0548e-01, -1.2062e-01, -5.2072e-01,\\n           2.8008e-01, -7.9928e-02,  1.9406e-01,  7.0016e-01,  4.4625e-01,\\n          -3.2851e-03, -2.0875e-02,  7.8890e-01,  3.0228e-01, -3.2555e-01,\\n          -7.4425e-02,  1.3707e-01, -7.8564e-01,  5.2605e-01,  8.0332e-02,\\n           3.8900e-01,  2.3702e-01, -1.1511e-01, -3.6333e-01,  2.0258e-01,\\n          -2.2442e-01,  6.6425e-01,  4.1471e-01,  1.1129e-01,  1.3350e-01,\\n           6.1418e-01,  6.6512e-01,  3.9880e-01,  6.4066e-01, -1.0199e+00,\\n           1.2464e-01]],\\n\\n        [[ 5.9687e-01,  9.9689e-02,  5.3655e-01, -1.1584e-01,  3.3782e-01,\\n           3.9191e-01,  4.6926e-01,  5.4192e-01, -2.5332e-01, -3.7114e-01,\\n           2.1655e-02, -3.9089e-01,  2.8391e-01,  7.9957e-01,  1.3771e-01,\\n          -1.6984e-01, -1.0994e-01,  1.1875e+00,  6.2971e-01, -3.5975e-01,\\n           2.6619e-01,  1.1073e-03, -5.9710e-01,  7.8501e-01, -6.8688e-02,\\n           5.7348e-01,  3.0812e-01, -4.0446e-02, -8.0802e-03, -2.2920e-02,\\n          -4.0642e-01,  5.7423e-01,  4.5598e-01,  1.1238e-01,  2.9965e-01,\\n           9.1783e-01,  3.5871e-01,  6.7922e-01,  8.6249e-01, -9.3598e-01,\\n           4.1936e-01]],\\n\\n        [[ 5.0598e-01,  1.7223e-01,  4.3776e-01, -1.3248e-01,  3.6576e-01,\\n           4.6408e-01,  4.6425e-01,  4.7629e-01, -2.6631e-01, -3.5400e-01,\\n          -9.0704e-02, -5.1793e-01,  3.2656e-01,  7.8860e-01,  4.6411e-02,\\n          -2.4131e-01, -1.4761e-01,  1.3074e+00,  6.8627e-01, -3.9415e-01,\\n           3.5756e-01, -6.6837e-02, -4.8978e-01,  8.4065e-01, -1.6039e-01,\\n           6.1798e-01,  2.8459e-01,  5.3234e-03,  1.0481e-01, -9.5834e-02,\\n          -4.4841e-01,  4.8120e-01,  4.4676e-01,  8.0893e-02,  3.6416e-01,\\n           1.0059e+00,  2.4104e-01,  7.8475e-01,  9.1951e-01, -9.2075e-01,\\n           4.8665e-01]],\\n\\n        [[ 5.4197e-01,  8.4900e-01, -3.7130e-03, -4.1579e-01,  9.4685e-01,\\n           6.3055e-01,  6.0708e-02,  2.0496e-01, -5.8913e-01,  1.0518e-01,\\n          -3.6694e-01, -5.3606e-01,  4.1328e-01,  7.8835e-01, -2.5762e-01,\\n          -2.3256e-01, -2.1628e-01,  1.4131e+00,  1.3047e+00, -2.4545e-01,\\n           9.6734e-01,  1.3584e-01, -2.0521e-03,  7.2045e-01, -2.7261e-01,\\n           7.6061e-01,  5.2548e-01,  2.3317e-01,  8.2912e-01, -6.2986e-01,\\n          -7.4241e-01,  5.4699e-01,  3.9950e-01,  2.4047e-01,  1.4366e-01,\\n           1.1582e+00, -4.2401e-02,  7.6088e-01,  1.0565e+00, -3.6707e-01,\\n           6.7686e-01]],\\n\\n        [[ 6.8346e-01, -9.7305e-02,  7.0537e-01, -6.1655e-02,  2.0467e-01,\\n           2.2286e-01,  4.8040e-01,  6.0193e-01, -1.7724e-01, -4.5962e-01,\\n           1.9426e-01, -1.9218e-01,  2.2279e-01,  7.5468e-01,  3.2792e-01,\\n          -6.2535e-02, -5.1340e-02,  9.4659e-01,  4.3663e-01, -3.3347e-01,\\n           5.4312e-02,  8.8382e-02, -7.3764e-01,  6.4014e-01,  3.9595e-02,\\n           4.6413e-01,  2.7699e-01, -9.7942e-02, -2.3708e-01,  1.2432e-01,\\n          -2.9627e-01,  6.5058e-01,  4.3992e-01,  1.2007e-01,  1.9912e-01,\\n           7.3411e-01,  5.5694e-01,  5.0404e-01,  7.3040e-01, -9.9335e-01,\\n           2.4676e-01]],\\n\\n        [[ 1.1401e-01,  1.2249e+00, -6.7363e-01, -7.1594e-01,  1.1192e+00,\\n           3.1508e-02, -9.6329e-01, -9.4242e-01, -6.0421e-01,  3.8831e-01,\\n          -8.0328e-01, -1.8434e-01,  5.9425e-01, -8.3992e-02, -9.7296e-02,\\n          -4.9144e-02, -2.8741e-01,  5.4112e-01,  1.2658e+00, -1.3799e-01,\\n           1.3160e+00,  6.1898e-01,  1.3736e+00, -6.2381e-01, -7.9943e-01,\\n           4.2434e-01,  2.5691e-01,  9.0902e-01,  1.6604e+00, -1.3550e+00,\\n          -7.5331e-01,  7.2825e-03, -1.4393e-01,  1.6297e-01, -6.4880e-01,\\n           6.1995e-01, -2.2866e-01,  2.1626e-01,  6.1974e-01,  5.8782e-01,\\n          -6.2876e-03]],\\n\\n        [[ 3.0392e-01, -4.7925e-01,  7.2142e-01,  1.0682e-01, -2.5098e-01,\\n           1.3644e-01,  6.4795e-01,  4.4410e-01,  9.9867e-02, -8.0278e-01,\\n           5.9076e-02, -4.5677e-01,  2.9510e-01,  5.4165e-01,  4.0386e-01,\\n          -2.3301e-01, -1.0443e-01,  9.9639e-01, -1.9611e-02, -5.5323e-01,\\n          -2.1488e-01, -1.9972e-01, -6.2749e-01,  6.3266e-01, -2.1753e-01,\\n           3.7853e-01, -8.1458e-02, -5.1774e-02, -4.5731e-01,  2.9212e-01,\\n          -1.2782e-01,  2.1239e-01,  3.4673e-01, -1.4092e-01,  4.3036e-01,\\n           7.1894e-01,  4.6626e-01,  7.0923e-01,  6.6435e-01, -1.2940e+00,\\n           1.0575e-01]],\\n\\n        [[ 1.0185e+00,  2.2876e-01,  6.7811e-01, -2.2945e-01,  5.9893e-01,\\n           1.8813e-01,  2.2724e-01,  6.5213e-01, -4.0963e-01, -1.4358e-01,\\n           3.3097e-01,  1.5096e-01,  1.5450e-01,  8.4939e-01,  3.3530e-01,\\n           1.4755e-01,  9.3947e-03,  7.3586e-01,  7.9100e-01, -1.1170e-01,\\n           2.6891e-01,  4.3037e-01, -7.4707e-01,  4.6598e-01,  2.5889e-01,\\n           4.7414e-01,  5.7052e-01, -9.1523e-02, -2.4914e-02, -5.5284e-02,\\n          -4.1708e-01,  1.0252e+00,  4.6635e-01,  3.5538e-01, -1.2562e-01,\\n           6.3504e-01,  6.8586e-01,  2.0397e-01,  7.0503e-01, -6.3935e-01,\\n           2.5279e-01]],\\n\\n        [[ 4.5003e-01, -4.0621e-01,  7.6058e-01,  6.6563e-02, -1.3734e-01,\\n           1.2275e-01,  5.9857e-01,  5.1302e-01,  2.9319e-02, -7.1452e-01,\\n           1.4779e-01, -3.2110e-01,  2.5570e-01,  6.0121e-01,  4.2726e-01,\\n          -1.5078e-01, -7.2143e-02,  9.2080e-01,  7.9421e-02, -4.7545e-01,\\n          -1.8216e-01, -8.5042e-02, -7.0191e-01,  6.0108e-01, -1.0542e-01,\\n           3.7921e-01,  2.7524e-02, -8.2817e-02, -4.4585e-01,  2.7666e-01,\\n          -1.5444e-01,  3.7517e-01,  3.7405e-01, -5.4097e-02,  3.3142e-01,\\n           6.7826e-01,  5.4651e-01,  5.9923e-01,  6.5311e-01, -1.2130e+00,\\n           1.0905e-01]]], grad_fn=<ViewBackward0>)\\nnext_loss=tensor(1.0447, grad_fn=<NllLossBackward0>)\\nmask_loss=tensor(nan, grad_fn=<NllLossBackward0>)\\ntotal_loss=0\\n bert_inputs=tensor([[ 2],\\n        [24],\\n        [21],\\n        [ 8],\\n        [ 9],\\n        [23],\\n        [16],\\n        [ 3],\\n        [40],\\n        [21],\\n        [ 8],\\n        [ 9],\\n        [23],\\n        [16],\\n        [ 3],\\n        [ 1]])\\nbert_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1]])\\nsegment_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [0]])\\nis_nexts=tensor([0])'}, {'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (32, 6, 8, 0.1, 'adam', 0.001, 0.2, 1), 'message': 'Error: loss.item()=nan---next_sentence_prediction=tensor([[0.1311, 0.0441]], grad_fn=<AddmmBackward0>)\\nmasked_language=tensor([[[-0.4978, -0.3174, -0.5764,  0.1442, -0.7046, -0.5076,  0.6573,\\n           0.6596, -0.2724, -0.8272,  0.5125,  0.1418,  1.0263,  0.5478,\\n           0.4015,  0.1029,  0.1320,  0.3092, -0.7604, -0.3483, -0.0162,\\n          -0.6548, -0.3619,  0.7513, -0.0262, -0.4467, -0.3057, -0.5490,\\n           0.0858, -0.5493, -0.5318,  0.2342, -0.7019, -0.0969, -0.2529,\\n          -0.5608,  0.3920, -0.8392, -0.5564,  0.2786,  0.4732]],\\n\\n        [[-0.6195, -0.5285, -0.1007, -0.2020, -0.6773, -0.0249,  0.2859,\\n           1.0627, -0.3535, -0.5750, -0.3766, -0.7448,  0.3074,  0.0824,\\n           0.3588, -0.2073,  0.8194,  0.1405, -1.0980,  0.1474, -0.1138,\\n           0.0075, -0.4329,  0.3745,  1.4810, -0.1342, -0.7103, -1.3642,\\n           0.5035, -1.1898,  0.1538,  0.3461, -0.6266, -0.0703,  0.1730,\\n          -0.2030, -0.1628, -0.5574, -0.5591,  0.3897,  0.3866]],\\n\\n        [[-0.7036,  0.0153, -0.4806, -0.4151, -0.7461, -0.3533,  0.4251,\\n           1.0021, -0.5054, -0.3517,  0.8761,  0.3258,  0.5454,  0.3892,\\n          -0.0670, -0.1214, -0.0227, -0.0015, -0.4356, -0.2173,  0.6150,\\n          -0.5460, -0.3224,  1.0902, -0.1068, -0.3181, -0.8096, -0.5549,\\n          -0.0284, -0.7578, -0.4632, -0.3523, -0.6102, -0.7665,  0.1335,\\n          -0.6167,  0.0453, -0.5965, -0.5181,  0.4067,  0.5478]],\\n\\n        [[-0.7457, -0.4437, -0.1914, -0.3053, -0.9211, -0.1800,  0.6913,\\n           0.4656, -0.4349, -0.6153, -0.0560, -0.4513,  0.7173,  0.3870,\\n           0.6544,  0.4151,  0.3665,  0.4903, -1.0830, -0.1521,  0.4357,\\n          -0.0560, -0.0817,  0.5597,  0.5253, -0.1235, -0.1129, -1.1130,\\n           0.4170, -0.8422, -0.0508,  0.2418, -1.0971, -0.2670,  0.1410,\\n          -0.3617, -0.4479, -0.3953, -0.6406,  0.4404,  0.5306]],\\n\\n        [[-0.2009, -0.6010, -0.4523,  0.1673, -0.5996, -0.0597,  0.6763,\\n           0.8192, -0.0850, -0.8654, -0.1702, -0.4396,  0.5328,  0.3035,\\n           0.4230,  0.1439,  0.5469,  0.2254, -1.3999,  0.1518, -0.2516,\\n          -0.4927, -0.3449,  0.1693,  0.7399, -0.3349, -0.2016, -0.8931,\\n           0.2931, -0.8699,  0.1647,  0.4437, -0.6508,  0.1144,  0.1504,\\n          -0.3926, -0.0016, -0.6410, -0.5815,  0.6026,  0.1042]],\\n\\n        [[-0.6248, -0.3506, -0.3025, -0.0466, -0.8072, -0.0825,  0.3455,\\n           0.6011, -0.0889, -0.6371, -0.1384, -0.8569,  0.6095,  0.4351,\\n           0.7668,  0.3887,  0.3642,  0.4024, -1.4264, -0.2416,  0.5115,\\n          -0.0223, -0.6828,  0.2850,  1.1635, -0.1582, -0.5259, -1.0607,\\n           0.1513, -0.7774,  0.1037,  0.6520, -0.9528, -0.1959, -0.1454,\\n          -0.2642, -0.0095, -0.7088, -0.6342,  0.6989,  0.1787]],\\n\\n        [[-0.4492, -0.2636, -0.3889, -0.4360, -0.9900, -0.3699,  0.7016,\\n           0.5224, -0.3285, -0.9232,  0.1942, -0.7866,  0.7461,  0.7221,\\n           0.7809,  0.3031,  0.4267,  0.7741, -0.8092,  0.0137,  0.0548,\\n          -0.1282, -0.4160,  0.3195,  0.5171, -0.2153, -0.2952, -0.8398,\\n           0.0560, -0.6969, -0.1435,  0.1334, -0.8063, -0.2772, -0.2926,\\n          -0.4006,  0.1750, -0.5477, -0.6777,  0.7829,  0.4227]],\\n\\n        [[-0.7980,  0.0528, -0.5998, -0.5290, -0.5960,  0.1458,  0.3329,\\n          -0.1013, -0.7961, -0.2649,  0.0304,  0.1219,  0.4558, -0.0087,\\n          -0.0845,  0.9815, -0.2973,  0.5456, -0.8736, -1.0307,  0.4648,\\n          -0.4656, -0.5797,  0.7473,  0.3489, -0.2985, -0.8044, -0.6250,\\n           0.2452, -0.8696,  0.0563,  0.3294, -0.9487, -0.8029,  0.0078,\\n          -0.4711,  0.1294, -0.3544, -0.7880,  0.7694,  0.3036]],\\n\\n        [[-0.5542, -0.4672,  0.0519, -0.1997, -0.5003,  0.0262,  0.5875,\\n           0.6005, -0.4881, -0.3452, -0.0573, -0.5636,  0.7858, -0.0163,\\n           0.4083,  0.2530, -0.0462,  0.2720, -1.0274, -0.0383,  0.3242,\\n           0.0386, -0.3860,  0.9165,  0.6682,  0.0072, -0.3214, -1.3475,\\n           0.2045, -1.1356, -0.1252,  0.0963, -0.8807, -0.1324, -0.0706,\\n          -0.3379, -0.2915, -0.5192, -0.5744,  0.4601,  0.4001]],\\n\\n        [[-0.6634, -0.3140, -0.5716, -0.1345, -0.5934,  0.1429,  0.2235,\\n           0.4105, -0.2505, -0.4816,  0.0908, -0.5562,  0.5641, -0.0242,\\n           0.3866,  0.3023,  0.1442,  0.4700, -1.4283, -0.2086,  0.3966,\\n          -0.4451, -0.8423,  0.6553,  0.7549, -0.2306, -0.7322, -0.8827,\\n          -0.0895, -0.8019,  0.1688,  0.4399, -1.0303, -0.3065, -0.2313,\\n          -0.3080, -0.0987, -0.5192, -0.8146,  0.9120,  0.3145]],\\n\\n        [[-0.1867, -0.0736, -0.4791, -0.7038, -0.2960,  0.1208,  0.3136,\\n           0.4330, -0.7785, -0.5692,  0.1074, -0.0870,  0.9743, -0.0867,\\n           0.4417,  0.2493,  0.1105,  0.6730, -1.1531, -0.1658,  0.1110,\\n          -0.6743, -0.7391,  0.6302,  0.4300,  0.0560, -0.9408, -0.9651,\\n           0.0948, -0.9629,  0.1082,  0.0039, -0.7765, -0.4700, -0.5271,\\n          -0.8754,  0.3785, -0.6718, -0.6683,  0.9715,  0.2548]],\\n\\n        [[-0.8033, -0.0113, -0.5449, -0.4229, -0.7312, -0.1544,  0.5379,\\n           0.7141, -0.4839, -0.4176,  0.1798,  0.2852,  0.6625, -0.1364,\\n           0.1908,  0.1911,  0.3204,  0.1576, -1.2021, -0.6441,  0.6019,\\n          -0.7119, -0.5916,  0.6125,  0.5104, -0.0458, -1.1493, -0.7584,\\n          -0.0105, -0.7043, -0.0017,  0.2574, -1.1436, -0.6511, -0.0286,\\n          -0.6997, -0.2325, -0.6670, -0.8448,  0.6908,  0.3056]],\\n\\n        [[-0.5850,  0.0496, -0.4795, -0.1879, -0.4498, -0.2047,  0.4786,\\n           0.7613, -0.4020, -0.2483,  0.3317,  0.4465,  0.7838, -0.1348,\\n           0.0176,  0.3392,  0.1286,  0.1206, -1.0013, -0.5575,  0.2808,\\n          -0.7196, -0.7099,  0.6692,  0.1788, -0.1601, -0.7812, -0.8732,\\n          -0.1283, -0.6971,  0.0321,  0.1949, -1.1198, -0.6425, -0.0667,\\n          -0.5141, -0.1481, -0.4385, -0.8268,  0.6035,  0.4150]],\\n\\n        [[-0.4112, -0.1460, -0.3106, -0.3607, -0.4581,  0.1150,  0.3443,\\n           0.7914, -0.5764, -0.4340,  0.2198,  0.0870,  0.9385, -0.3211,\\n          -0.0343,  0.2500,  0.2460,  0.0665, -1.1907, -0.2730,  0.6231,\\n          -0.9519, -0.5749,  0.7055,  0.3073,  0.2716, -0.9413, -0.7349,\\n           0.0781, -1.0779, -0.0678, -0.1531, -1.1735, -0.7437, -0.2143,\\n          -0.5397, -0.2233, -0.5369, -0.7511,  0.8395,  0.2049]]],\\n       grad_fn=<ViewBackward0>)\\nnext_loss=tensor(0.7376, grad_fn=<NllLossBackward0>)\\nmask_loss=tensor(nan, grad_fn=<NllLossBackward0>)\\ntotal_loss=12.926578760147095\\n bert_inputs=tensor([[ 2],\\n        [ 5],\\n        [24],\\n        [21],\\n        [ 5],\\n        [14],\\n        [ 3],\\n        [ 6],\\n        [21],\\n        [14],\\n        [ 3],\\n        [ 1],\\n        [ 1],\\n        [ 1]])\\nbert_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1]])\\nsegment_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [0],\\n        [0],\\n        [0]])\\nis_nexts=tensor([1])'}, {'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (8, 6, 8, 0.2, 'sgd', 0.01, 0.4, 32), 'message': \"Error: 'accuracy'\"}, {'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (32, 6, 8, 0.3, 'sgd', 0.0001, 0.1, 1), 'message': 'Error: loss.item()=nan---next_sentence_prediction=tensor([[-0.8731,  0.6910]], grad_fn=<AddmmBackward0>)\\nmasked_language=tensor([[[ 4.9214e-01, -4.3837e-02, -1.3495e+00, -4.6924e-01,  4.3491e-01,\\n           4.4218e-01,  4.8570e-01,  7.1297e-01,  1.2205e-01,  8.2952e-01,\\n          -7.3661e-01,  5.1918e-01, -5.0337e-01, -4.7405e-01, -4.5835e-02,\\n           6.9468e-01,  7.8066e-01, -9.7888e-02, -5.1380e-01, -5.3693e-01,\\n          -3.7895e-01, -4.0014e-01,  1.5439e-01, -2.7625e-01, -8.8688e-01,\\n          -2.5702e-01, -1.4982e-02, -2.9888e-01, -7.5908e-01, -6.8823e-01,\\n          -5.0183e-01, -5.6614e-01,  6.2365e-02,  3.8070e-01,  4.8480e-01,\\n           4.3351e-01, -1.7608e-02, -5.5044e-01,  3.7228e-01, -4.4813e-01,\\n           9.3805e-01]],\\n\\n        [[ 2.2046e-01,  2.9152e-01, -7.9577e-01, -7.0391e-01,  3.0978e-01,\\n           6.8208e-01,  3.8415e-01,  3.5337e-01,  4.2574e-01,  9.9195e-01,\\n          -3.8844e-01,  2.3518e-01, -3.6149e-01, -2.4463e-01,  1.5921e-01,\\n           6.2721e-01,  2.8887e-01, -4.6876e-01, -5.3472e-01, -2.4416e-01,\\n          -1.5237e-01,  5.8784e-02,  6.3588e-01, -4.7028e-02, -5.3608e-01,\\n          -2.6414e-01,  4.3432e-01,  1.0694e-01, -7.4417e-01, -8.0407e-01,\\n          -2.7246e-01, -2.4832e-01,  1.1010e-02, -4.4314e-01,  5.7809e-01,\\n           4.2957e-01, -1.5874e-01, -6.7356e-01,  4.3882e-01, -3.4826e-01,\\n           2.7265e-01]],\\n\\n        [[ 2.7792e-01, -3.0018e-01, -1.4747e+00, -8.1879e-02, -1.6740e-01,\\n           1.7562e-02,  1.4387e-01,  2.7901e-01, -1.8383e-02, -3.6334e-01,\\n          -2.5027e-01, -3.1417e-01, -5.5287e-01, -5.1854e-01, -8.0718e-01,\\n           4.5826e-02,  8.2264e-01,  1.2287e-02, -4.5088e-02, -2.1567e-01,\\n          -2.4375e-01, -1.2723e-01, -9.5870e-01,  5.5876e-02, -1.0110e+00,\\n          -8.0113e-01, -4.2288e-02,  2.1356e-01, -1.0710e-01, -9.6908e-01,\\n          -4.6940e-01,  1.2563e-01,  1.2135e-02,  3.3316e-01, -1.1771e-01,\\n           7.7702e-01, -4.4864e-01, -9.1818e-01,  8.8513e-02, -8.5231e-01,\\n           5.3180e-01]],\\n\\n        [[ 3.0126e-01,  1.7700e-01, -9.0349e-01, -6.7594e-01,  3.8183e-01,\\n          -8.5946e-03, -1.6799e-02,  3.1245e-01,  6.2459e-01,  5.0193e-01,\\n          -7.8915e-01,  6.9400e-02, -7.4174e-01, -1.2801e-01, -2.6422e-02,\\n           1.0168e+00,  9.0681e-01, -4.5481e-01, -5.0531e-01, -5.0477e-01,\\n          -2.5755e-01,  6.5649e-01,  7.0441e-02, -4.6813e-01, -6.1198e-01,\\n          -1.5003e-01,  1.4605e-01,  3.2535e-01, -2.7981e-01, -9.3502e-01,\\n          -4.9990e-01, -5.0870e-01,  1.8917e-01, -1.6957e-01,  6.0834e-01,\\n           3.1802e-01,  7.7104e-02, -1.1987e+00,  6.1360e-02, -8.7303e-01,\\n           5.6816e-01]],\\n\\n        [[-3.3837e-03,  2.1727e-01, -7.3909e-01,  2.6649e-01,  1.0538e+00,\\n          -1.2255e-01,  1.7085e-01,  2.4781e-01,  3.6796e-01,  7.3130e-01,\\n          -1.0429e+00,  3.0480e-01, -3.9119e-01, -6.7502e-01,  1.6390e-01,\\n           5.6377e-01,  1.1092e+00, -2.6767e-01, -2.3172e-01, -2.3665e-01,\\n          -4.0793e-01, -1.1518e-02, -3.5537e-01, -3.5484e-01, -7.1985e-01,\\n          -1.4477e-02,  2.8588e-01,  7.3411e-02, -2.2746e-01, -7.9192e-01,\\n          -7.8701e-01, -4.1387e-01,  3.6773e-01,  4.4000e-01, -1.0466e-01,\\n           5.1935e-01, -8.8967e-03, -6.8680e-01,  1.8959e-01, -6.0141e-01,\\n           2.3949e-01]],\\n\\n        [[ 8.8556e-01,  3.2028e-02, -1.9803e-01, -1.5413e-02,  6.2534e-01,\\n           2.4355e-01,  1.2854e-01, -4.5602e-01,  7.8536e-01,  2.6180e-01,\\n          -6.5489e-01, -1.6500e-01,  4.2413e-01, -6.0820e-01, -6.7107e-01,\\n           8.5733e-01,  1.5273e-01, -1.9631e-01, -3.0385e-01,  5.4320e-02,\\n          -2.3438e-01,  6.6440e-01, -6.5720e-02,  8.6337e-03, -4.5791e-01,\\n          -3.1390e-01,  1.2821e-03,  5.6729e-01, -2.1910e-01, -1.1732e+00,\\n          -5.2316e-01, -3.4036e-01, -3.7974e-01,  6.9511e-02,  6.6750e-01,\\n          -1.6626e-01, -2.1264e-01, -6.9132e-01, -1.0522e-01, -4.2732e-01,\\n           7.9853e-02]],\\n\\n        [[ 2.4731e-01,  2.8699e-01, -5.4737e-01, -1.9224e-01,  8.5048e-01,\\n           4.7279e-01,  3.8492e-01,  1.8895e-01,  4.6413e-01, -2.4692e-01,\\n          -9.2835e-01,  3.2585e-01,  1.9359e-01, -2.2114e-01,  1.1734e-01,\\n           8.8724e-01,  5.2669e-01, -6.8152e-01, -5.6345e-02, -1.3768e-01,\\n          -3.7231e-01,  1.4130e-02, -2.3906e-01,  5.8196e-01, -7.3380e-01,\\n          -3.6390e-01,  1.6661e-01,  4.5031e-01, -2.2460e-01, -8.3569e-01,\\n          -9.7802e-01,  2.3574e-01, -2.0879e-01,  3.5169e-01,  1.2091e+00,\\n          -5.7921e-02,  5.3133e-01, -4.9382e-01,  2.8332e-01, -3.4440e-01,\\n           5.8408e-01]],\\n\\n        [[ 5.5607e-02,  9.0895e-03, -1.0314e-01,  1.0054e-02,  1.0981e+00,\\n           2.1405e-01,  8.4982e-02,  1.9171e-01,  4.9698e-01,  5.6521e-01,\\n          -1.0428e+00, -1.0220e-01, -1.2041e-01,  1.7913e-01, -1.5446e-01,\\n          -1.0378e-01,  5.3318e-02,  5.9252e-01,  4.1830e-01, -2.8827e-01,\\n          -2.1792e-01,  3.4508e-01,  5.9766e-02, -1.5521e-01, -3.4674e-01,\\n          -1.8081e-02, -1.3464e-03, -1.6344e-02, -3.2440e-01, -5.3842e-01,\\n          -3.1336e-01, -7.8613e-01, -1.7511e-01,  2.2924e-01,  1.6205e-01,\\n          -7.8736e-02, -2.8046e-01,  3.8973e-02,  5.6365e-01, -3.3243e-02,\\n           6.6421e-01]],\\n\\n        [[-9.9565e-02, -4.3429e-01,  1.6727e-01, -1.5600e-01,  3.7101e-01,\\n          -2.9642e-01, -8.2121e-02, -4.1631e-01,  5.0872e-01,  7.4254e-01,\\n          -1.2649e+00, -1.8126e-01, -6.6000e-01,  4.6306e-01, -3.9590e-01,\\n           5.6817e-01,  6.8607e-01,  4.4823e-02, -1.4532e-01, -3.9494e-01,\\n          -1.7710e-01,  1.1593e+00,  6.4969e-01, -9.4431e-01, -1.5056e-02,\\n           2.3106e-01, -2.3171e-01,  6.0553e-01, -6.0622e-01, -6.0971e-01,\\n          -7.1204e-01, -4.8189e-01,  3.0710e-01, -2.9726e-01,  2.1612e-01,\\n           6.6874e-01, -3.3430e-02, -8.1768e-01, -3.9589e-01, -8.3771e-01,\\n          -1.9747e-01]],\\n\\n        [[-9.7561e-02,  4.6524e-01, -6.5405e-01,  1.4756e-01,  3.5037e-01,\\n           9.4709e-01,  1.6713e-01,  2.2377e-01,  2.5516e-01,  8.7862e-01,\\n           1.9510e-01, -4.4862e-01,  4.7936e-01, -1.0429e+00, -3.4867e-01,\\n           2.2055e-01,  2.9822e-01, -4.1767e-01, -2.2255e-01, -6.6828e-01,\\n          -1.1330e-01, -1.4206e-01, -9.9214e-02,  8.4043e-02, -8.6091e-01,\\n          -1.1953e-01,  9.7752e-01,  7.9519e-01, -3.6055e-01, -1.0429e+00,\\n          -5.3428e-01,  4.7912e-01,  6.1993e-02, -4.1703e-01,  3.3515e-01,\\n           3.2668e-02, -2.6122e-01, -9.0144e-01,  5.6347e-02, -4.7307e-01,\\n           3.5344e-01]],\\n\\n        [[ 2.3927e-01,  3.4092e-01, -6.9088e-01, -5.5529e-01,  3.1081e-01,\\n           3.3540e-01,  7.9978e-01,  1.6872e-01,  2.8290e-01,  6.5386e-01,\\n          -4.8196e-01,  1.1861e-01, -4.9720e-01, -6.8102e-01,  2.8305e-01,\\n           9.5663e-01,  8.0152e-01, -3.6771e-01, -8.0313e-01, -3.4446e-01,\\n          -1.2019e-01,  4.1489e-02,  2.1486e-01, -2.6738e-01, -3.6730e-01,\\n           4.6469e-02,  3.9108e-02,  5.4644e-01, -5.9239e-01, -1.0438e+00,\\n          -1.1450e+00, -6.1940e-01,  1.3138e-01,  1.9611e-01,  7.1988e-01,\\n           1.1908e-01, -1.5498e-01, -8.7860e-01,  4.8472e-01, -5.9149e-01,\\n          -4.4508e-02]],\\n\\n        [[ 1.1447e-01,  2.0419e-02, -1.1274e+00,  3.5955e-01,  6.1503e-01,\\n          -1.7457e-01,  2.4974e-02,  5.7741e-01, -6.7221e-04,  3.1915e-01,\\n          -8.0717e-01,  9.7785e-04, -6.5752e-01, -4.3545e-01, -6.4104e-01,\\n           5.1406e-01,  6.8011e-01, -6.9846e-02,  3.3888e-01, -4.4991e-01,\\n          -3.4428e-01,  3.3264e-01, -8.4933e-01,  3.1350e-01, -9.2513e-01,\\n          -2.1342e-01,  2.7096e-01, -2.4034e-02, -2.8574e-01, -3.4756e-01,\\n          -4.9471e-01, -1.6829e-01,  3.2179e-01,  6.0808e-01,  2.1339e-01,\\n           3.5247e-01,  6.5765e-01, -5.4425e-01,  2.1284e-01, -5.3170e-01,\\n           7.3936e-01]],\\n\\n        [[ 2.5835e-01,  6.6018e-02, -8.3244e-01, -1.8580e-01,  6.5868e-01,\\n           6.1634e-01,  6.8741e-01,  3.0875e-01,  4.1109e-01,  1.7275e-01,\\n          -5.2314e-01,  6.0838e-02, -2.9233e-01, -5.3721e-01, -3.8594e-01,\\n           2.5584e-01,  5.6020e-01, -3.9258e-01, -6.8475e-02, -4.6159e-02,\\n          -1.8679e-01, -3.5210e-01, -6.9672e-01, -7.5426e-02, -8.4257e-01,\\n          -5.4187e-01,  4.6847e-02, -3.0026e-01, -6.2955e-01, -9.7693e-01,\\n          -8.0709e-01, -3.2663e-01, -3.1659e-01,  2.0288e-01,  1.8815e-01,\\n           1.9973e-01, -3.3744e-01, -7.5882e-01,  4.3231e-01, -7.9935e-01,\\n           7.6873e-01]],\\n\\n        [[ 1.4280e-01,  3.9643e-01, -7.0416e-01, -8.2490e-02,  2.7473e-01,\\n           3.2695e-01,  3.4541e-01,  1.8835e-01,  1.7480e-01,  9.5015e-01,\\n          -1.3552e-01, -1.9167e-01,  8.3827e-02, -1.0250e+00, -5.1243e-02,\\n           7.2713e-01,  6.7205e-01, -3.1734e-02, -4.8135e-01, -5.8557e-01,\\n          -2.0399e-01,  1.3429e-01, -1.1232e-01, -7.4506e-02, -7.1634e-01,\\n           4.1862e-02,  3.8972e-01,  8.5218e-01, -3.7321e-01, -1.1466e+00,\\n          -6.2179e-01, -2.1627e-01,  4.3937e-01,  3.7812e-01,  3.6668e-01,\\n           3.9596e-02,  4.0209e-02, -7.2032e-01,  3.3336e-01, -4.3987e-01,\\n           9.0351e-02]],\\n\\n        [[ 4.3063e-01,  3.1229e-01, -3.0298e-01, -3.5380e-01,  7.1267e-01,\\n           7.0970e-01,  4.2374e-01, -3.1382e-01,  6.0624e-01,  1.2460e-01,\\n          -8.9895e-01,  4.0373e-01,  7.2564e-02, -3.4198e-02, -3.7457e-01,\\n           7.6052e-01,  4.3899e-01, -9.2097e-01, -7.8747e-01, -4.4547e-01,\\n          -4.2780e-01, -7.6672e-02,  1.6878e-01, -6.2535e-03, -7.2183e-01,\\n          -4.2141e-01, -6.1422e-03,  1.6010e-01, -8.1163e-01, -1.0670e+00,\\n          -4.3260e-01, -2.0582e-01, -6.4090e-01,  1.1836e-01,  9.5080e-01,\\n           1.3917e-01, -6.0368e-01, -5.0601e-01, -5.4636e-02, -5.8113e-01,\\n           7.8333e-01]],\\n\\n        [[ 1.8695e-01,  9.5733e-01, -2.0029e-01, -3.3096e-01,  8.6602e-01,\\n           3.1515e-01, -1.9445e-01, -6.4736e-02,  5.9009e-01,  1.1802e+00,\\n          -6.9087e-01,  5.8427e-01, -3.8437e-01, -6.1091e-01,  1.7456e-01,\\n           1.1551e-01,  7.6477e-01, -3.7273e-01, -4.3224e-01, -3.6184e-01,\\n          -1.1869e-01,  4.5415e-01,  3.0507e-01, -4.2726e-01,  1.0988e-01,\\n           4.2772e-01,  8.1401e-01,  1.3282e-01, -7.0164e-02, -9.3447e-01,\\n          -2.6002e-01, -5.8514e-01,  6.1552e-01,  1.0344e-01,  1.4585e-01,\\n           5.7130e-01, -3.7793e-01, -9.0224e-01,  5.4769e-01, -1.3094e-01,\\n          -3.5550e-01]]], grad_fn=<ViewBackward0>)\\nnext_loss=tensor(1.7541, grad_fn=<NllLossBackward0>)\\nmask_loss=tensor(nan, grad_fn=<NllLossBackward0>)\\ntotal_loss=151.8860569000244\\n bert_inputs=tensor([[ 2],\\n        [ 6],\\n        [18],\\n        [10],\\n        [14],\\n        [22],\\n        [ 9],\\n        [ 3],\\n        [24],\\n        [18],\\n        [10],\\n        [14],\\n        [22],\\n        [ 9],\\n        [ 3],\\n        [ 1]])\\nbert_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1]])\\nsegment_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [0]])\\nis_nexts=tensor([0])'}, {'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (8, 6, 4, 0.1, 'sgd', 1e-05, 0.3, 64), 'message': \"Error: 'accuracy'\"}, {'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (32, 10, 2, 0.4, 'adam', 0.0001, 0.1, 1), 'message': 'Error: loss.item()=nan---next_sentence_prediction=tensor([[0.4481, 0.3568]], grad_fn=<AddmmBackward0>)\\nmasked_language=tensor([[[-1.0742,  0.5196, -0.1447,  1.3976,  0.7485,  0.1669, -0.8200,\\n           0.3782,  0.5069, -0.0562, -0.7225, -0.2648, -0.6292, -0.2222,\\n           0.3336,  0.0433,  0.8936, -0.8733,  0.4381, -0.8028, -0.7604,\\n          -0.3218, -0.6087, -0.3891,  0.6460, -0.2151,  0.5193, -0.8410,\\n           0.6645, -0.0722, -0.2053, -0.6735, -0.9349, -0.6257, -0.1494,\\n          -0.2907, -0.2708, -0.0950,  0.2535,  0.5919,  0.6029]],\\n\\n        [[ 0.4435,  0.5582,  0.0361,  0.4820,  0.2849,  0.4961,  0.2661,\\n           0.3450,  0.9183,  0.1956,  0.5198,  0.6798, -1.4251,  0.3124,\\n           0.2900, -0.4186,  0.2697, -1.2430,  0.2404, -0.6427, -0.9256,\\n           0.4696, -0.2513, -0.2762, -0.1447,  0.0037,  0.3325, -0.2774,\\n           0.3544, -0.0125,  0.1082, -0.1112, -1.4229,  0.5899,  0.1256,\\n          -0.3124, -1.2952, -0.5927,  0.5859,  0.3889,  0.3591]],\\n\\n        [[ 0.2097,  0.7559,  0.4169,  0.5933,  0.0182,  0.7346, -0.0753,\\n           0.7974,  0.5526, -0.2924, -0.5028, -0.2216, -0.7043, -0.0990,\\n          -0.0722, -0.0770,  0.5845, -0.8348,  0.6113, -0.8763, -1.0386,\\n          -0.0196, -0.0076, -0.1952,  0.3641, -0.5303,  0.7568, -0.5377,\\n           0.1128, -0.1936, -0.3298, -0.6168, -1.0618,  0.0937,  0.4220,\\n          -1.0714, -0.6905, -0.0998,  0.6355,  0.5231,  1.1494]],\\n\\n        [[ 0.0648,  0.9244,  0.6969,  0.3795, -0.3453,  0.2258,  0.5091,\\n           0.6082,  0.7902, -0.0253, -0.4245, -0.0837, -1.4079,  0.2099,\\n          -0.2293,  0.1836,  0.0753, -1.3668,  0.6619, -0.3850, -0.7101,\\n           0.3042, -0.4172, -0.0811,  0.2612,  0.0071,  1.0011,  0.0217,\\n           0.2604,  0.2156,  0.0124, -0.6885, -1.5501,  0.3415,  0.4592,\\n          -0.5581, -1.1454, -0.5255,  0.9180,  0.5511,  0.9590]],\\n\\n        [[ 0.0643,  0.3254, -0.0751,  0.4100, -0.1888,  0.3460,  0.5614,\\n           0.4688,  0.3627, -0.0227,  0.3930,  0.3765, -1.0713,  0.9155,\\n           0.0907, -0.3957,  0.1851, -0.9689,  0.3329, -0.7135, -1.1600,\\n           0.5141, -0.1444,  0.0727, -0.7654,  0.0571,  0.9417, -0.3862,\\n           0.7988, -0.5491, -0.2635, -0.2105, -1.3454,  0.4642,  0.2268,\\n          -0.4158, -1.3210, -0.9074,  0.7466, -0.0604,  0.1990]],\\n\\n        [[ 0.0901,  0.3855,  0.3070,  0.0518, -0.1092,  0.5196,  0.2677,\\n           0.5324,  0.5975,  0.3538,  0.1836,  0.6545, -1.4930,  0.5175,\\n          -0.1834, -0.5449,  0.1786, -1.0470,  0.6002, -0.4445, -0.6911,\\n           0.5031, -0.3120, -0.0276, -0.3943, -0.4043,  0.9041, -0.4833,\\n           0.3997, -0.2956,  0.1056, -0.4905, -1.3373,  0.6560,  0.6127,\\n           0.0724, -1.1518, -0.9010,  0.9230,  0.4414,  0.5855]],\\n\\n        [[-0.0505,  0.8147,  0.3050,  0.4620, -0.1503,  0.1373, -0.0187,\\n           0.6021,  0.6890,  0.4070,  0.1046,  0.5490, -1.2355,  0.1941,\\n          -0.1812, -0.3236,  0.7793, -1.3852,  0.0250, -0.3123, -0.9803,\\n           0.6015, -0.3831,  0.0109,  0.0694,  0.1910,  1.2640, -0.1643,\\n          -0.1953, -0.1332,  0.2526, -0.6162, -1.1623,  0.7801,  0.5038,\\n          -0.4512, -1.1713, -0.8431,  0.6320, -0.2384, -0.1262]],\\n\\n        [[ 0.7563, -0.1407,  0.1950, -0.1233, -0.3909,  0.4870,  0.7836,\\n           0.6816,  0.6705, -0.4894,  0.0824,  0.5712, -0.9508,  0.5200,\\n           0.2735,  0.0729,  0.3589, -0.9576,  0.3820, -0.9582, -1.0240,\\n           0.2542,  0.3566, -0.4163,  0.0542, -0.3279,  0.6008, -0.8775,\\n           0.7200, -0.4615, -0.4234, -0.5646, -1.1420,  0.1888,  0.5244,\\n          -0.5474, -0.9321,  0.0287,  0.6704,  0.6937,  1.0301]],\\n\\n        [[-0.0737,  0.7628,  0.4392,  0.1767, -0.2740, -0.2216, -0.0572,\\n           0.2621,  1.1979, -0.0294, -0.0211,  0.8111, -1.6696,  0.1212,\\n          -0.8955, -0.2207,  0.2719, -1.4956,  0.3269, -0.4139, -0.0385,\\n           0.0629, -0.4714, -0.0038,  0.2875,  0.1811,  0.9679, -0.0331,\\n           0.2441,  0.4230, -0.0653, -0.5741, -1.1803,  0.5721,  0.4169,\\n          -0.1436, -0.7313, -0.6020,  0.0283, -0.1279,  0.5397]],\\n\\n        [[-0.4696,  0.8387,  0.8412,  0.4598,  0.4408,  0.7305,  0.0941,\\n           0.4964,  1.2780, -0.2498, -0.0708,  0.1612, -1.2263, -0.0033,\\n          -0.7460,  0.5605, -0.0715, -1.5274,  0.3224, -0.3599, -0.4208,\\n          -0.0412,  0.0441,  0.1264,  0.3517, -0.0131,  0.6257, -0.3518,\\n          -0.1062,  0.5345,  0.1952, -0.9772, -1.4756,  0.8112,  0.2875,\\n          -0.2048, -1.1556,  0.2440,  0.4948,  0.1376,  0.7321]],\\n\\n        [[-0.3058,  0.3408,  0.0452,  0.0132, -0.0700,  0.2645,  0.2562,\\n           0.7671,  0.0776, -0.0796, -0.4892,  0.1940, -1.4775,  0.9019,\\n           0.2048, -0.1687,  0.6182, -0.6692,  0.8525, -0.1703, -0.4783,\\n           0.5428, -0.2463, -0.0213, -0.7120, -0.6475,  0.2021, -0.7290,\\n           0.4761, -0.0380, -0.1765, -0.1121, -1.2103,  0.7378,  0.7376,\\n          -0.2929, -0.7928, -0.3354,  0.2067,  0.8928,  0.4180]],\\n\\n        [[ 0.0390,  0.1588, -0.2781, -0.4036, -0.6461, -0.0462,  0.0293,\\n           0.2952,  0.2260, -0.5529, -0.1298,  0.4023, -1.0405,  0.6025,\\n          -0.8132, -0.7450,  0.5365, -0.6980,  0.8331, -0.3815, -0.2711,\\n           0.4613, -0.4331, -0.1349, -0.7934, -0.1202,  1.1456, -0.2506,\\n           0.4359, -0.4552, -0.2425, -0.2803, -0.3554,  0.8167,  1.1192,\\n          -0.3783, -0.6112, -1.1492,  0.2531, -0.0980,  0.5420]],\\n\\n        [[-0.1103,  0.3018,  0.0765,  0.5173, -0.1439,  0.3474,  0.3077,\\n           0.2981,  0.1957, -0.2022, -0.0558, -0.0408, -0.8603, -0.0075,\\n          -0.3894, -0.0507,  0.6325, -0.9788,  0.5353, -0.6579, -0.9290,\\n           0.5560, -0.3643, -0.3905, -0.5208, -0.0461,  0.8096, -0.2843,\\n           0.2232, -0.3604, -0.0276, -0.5153, -0.8971,  0.4241,  0.5013,\\n          -0.3506, -1.1698, -0.6590,  0.8041,  0.0559,  0.9148]],\\n\\n        [[ 0.0867,  0.5324,  0.5988,  0.2178, -0.4183,  0.5854,  0.3828,\\n           1.1189,  0.8451,  0.0206, -0.4258,  0.2156, -1.1209,  0.3940,\\n           0.1602,  0.1482,  0.6133, -1.2183,  0.6901, -0.6666, -0.7772,\\n           0.2421, -0.1107,  0.1797,  0.4915, -0.7092,  0.6160, -0.8990,\\n           0.7140, -0.0954, -0.4515, -0.6870, -1.1407,  0.1043,  0.2578,\\n          -0.7538, -0.4419, -0.2638,  0.0818,  0.6954,  1.1268]],\\n\\n        [[-0.3320,  0.3137,  0.4546, -0.0060, -0.1263, -0.1438, -0.3364,\\n           0.6610,  1.2508,  0.3794, -0.3697,  0.7928, -1.4125,  0.3989,\\n          -0.2887,  0.1570,  0.5891, -1.2720,  0.6491, -0.5662, -0.5044,\\n           0.5576, -0.5709, -0.1812,  0.3346, -0.1315,  0.4445, -0.6347,\\n           0.1068,  0.1080, -0.1258, -0.7244, -1.3942,  0.3847,  0.2579,\\n          -0.0574, -0.5430, -0.5542,  0.2463,  0.3108,  0.5822]],\\n\\n        [[ 0.4742,  0.4557,  0.3606,  0.5218, -0.1592,  0.6480,  0.4459,\\n           1.1230,  0.7519,  0.1402, -0.0802, -0.0747, -1.2827,  0.5948,\\n           0.3042, -0.2745,  0.7163, -0.9951,  0.5365, -0.6801, -1.2151,\\n           0.3800, -0.2517,  0.0180, -0.1302, -0.3623, -0.2078, -0.4654,\\n           0.3793, -0.3219, -0.0276, -0.2944, -1.2142,  0.6530,  0.0177,\\n          -0.4379, -0.6932, -0.4051,  0.0740,  0.8550,  0.7258]]],\\n       grad_fn=<ViewBackward0>)\\nnext_loss=tensor(0.6485, grad_fn=<NllLossBackward0>)\\nmask_loss=tensor(nan, grad_fn=<NllLossBackward0>)\\ntotal_loss=252.04664540290833\\n bert_inputs=tensor([[ 2],\\n        [ 6],\\n        [21],\\n        [12],\\n        [16],\\n        [23],\\n        [14],\\n        [ 3],\\n        [24],\\n        [21],\\n        [12],\\n        [16],\\n        [23],\\n        [14],\\n        [ 3],\\n        [ 1]])\\nbert_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1]])\\nsegment_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [0]])\\nis_nexts=tensor([0])'}, {'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (32, 10, 2, 0.4, 'adam', 0.0001, 0.1, 1), 'message': 'Error: loss.item()=nan---next_sentence_prediction=tensor([[0.1567, 0.4767]], grad_fn=<AddmmBackward0>)\\nmasked_language=tensor([[[-7.5359e-02, -2.5709e-01,  7.1122e-03, -1.0329e-02,  6.0017e-01,\\n           3.8143e-01, -3.3286e-01,  7.3484e-01,  5.3759e-01,  1.1806e+00,\\n          -1.9132e-01, -3.6444e-01,  2.3935e-01,  9.0606e-01,  2.8028e-01,\\n           6.5761e-01, -4.9913e-01,  1.6437e-01,  3.2560e-01,  5.7275e-01,\\n          -5.4260e-01, -1.1331e+00,  9.0116e-02, -3.1134e-01, -2.3211e-01,\\n          -2.7427e-01, -3.9817e-01,  1.6222e-01, -1.2516e+00,  1.1640e+00,\\n           4.8634e-04, -4.4370e-01,  1.6797e-01, -4.6898e-01,  7.2326e-01,\\n          -2.5727e-03,  3.2979e-01, -9.7640e-01,  1.0014e-01, -5.5037e-02,\\n          -3.3373e-01]],\\n\\n        [[ 1.4905e-01,  2.5236e-01, -2.0782e-01,  8.4933e-01,  8.5752e-02,\\n           6.5259e-01,  1.8806e-02, -4.9180e-02, -1.7259e-01,  4.0561e-01,\\n          -7.5185e-01, -3.1291e-01,  5.4973e-01,  1.4261e+00,  7.3339e-01,\\n           1.2604e+00, -2.6563e-01, -2.7982e-01,  1.5739e-01,  1.2243e-01,\\n           9.1390e-02, -1.4328e-01,  7.2209e-01, -6.0960e-01, -3.7804e-01,\\n          -1.6384e-01, -6.4740e-01, -6.8289e-01, -2.6466e-01,  1.1280e+00,\\n           4.5693e-01, -5.0841e-01, -2.7861e-01,  3.1972e-01,  1.3661e+00,\\n           3.2981e-02, -4.8329e-02, -6.6940e-01, -3.9479e-02, -3.6844e-01,\\n          -3.6452e-01]],\\n\\n        [[-1.4082e-01, -1.3628e-01, -2.9891e-01, -4.0928e-02,  8.2343e-01,\\n           5.7942e-01,  1.1649e-01,  4.1253e-01,  1.3069e-01,  9.1964e-01,\\n           6.3725e-02, -5.0703e-01, -5.1916e-01,  4.9367e-01,  3.7403e-01,\\n           5.9944e-01, -4.1803e-01,  6.7663e-01,  4.5347e-01,  8.3338e-01,\\n          -3.4628e-01, -1.0979e+00, -8.3152e-02,  1.2866e-01, -8.8453e-01,\\n           4.8398e-02,  1.9366e-02,  3.4068e-01, -8.8386e-01,  9.8316e-01,\\n           2.3247e-01, -5.0375e-01,  3.1655e-01, -3.3908e-01,  6.6379e-01,\\n          -9.5238e-02,  6.2919e-01, -3.9763e-01, -6.7271e-03,  3.2381e-01,\\n          -1.4599e-01]],\\n\\n        [[-5.4806e-01,  9.8398e-01, -1.3540e-01,  7.7432e-02, -5.8351e-01,\\n           1.1216e+00,  1.9810e-01, -2.0149e-01,  3.3244e-01,  6.6991e-01,\\n          -2.6945e-01,  1.6221e-01, -7.5317e-01,  5.5389e-01,  7.5781e-01,\\n           1.6827e+00, -1.0997e+00,  4.3032e-01,  4.4258e-01, -1.2166e+00,\\n           1.0170e+00, -2.5314e-01,  1.3133e-01, -1.1422e+00, -3.8891e-01,\\n           4.0276e-01, -1.9147e-01, -3.0587e-01, -6.4773e-01,  2.2567e-01,\\n           2.8866e-02, -6.9681e-01, -8.2124e-01, -6.1827e-01,  5.8397e-01,\\n           7.0043e-01,  2.3213e-02, -4.3687e-01,  4.2459e-01, -8.6213e-01,\\n          -1.1765e+00]],\\n\\n        [[ 1.0204e-01,  1.8070e-01, -1.6793e-01, -2.9762e-02, -5.3158e-01,\\n           7.0566e-01,  2.6839e-01,  3.0602e-01,  4.8965e-01,  1.3568e+00,\\n           9.7991e-02,  4.1683e-01, -3.1349e-01,  3.9317e-01,  2.0905e-01,\\n           9.6094e-01,  1.9058e-01,  1.5696e-01,  8.0372e-02, -4.4779e-03,\\n           1.0591e+00, -1.9971e-01, -5.0287e-01, -1.7386e-01, -1.9183e-01,\\n          -5.9735e-01,  1.3930e-01, -5.7821e-01, -8.7579e-01,  9.6529e-01,\\n           2.8811e-01,  8.3833e-02, -4.7115e-01,  2.9413e-02,  1.1247e+00,\\n          -1.6239e-01,  9.1873e-04, -8.0062e-01, -4.6086e-02, -3.5359e-01,\\n          -1.3303e+00]],\\n\\n        [[-1.9248e-01, -6.6039e-01, -1.0322e-01, -6.9612e-01,  5.8641e-01,\\n           1.3782e+00,  6.5347e-02, -3.2913e-01,  5.0369e-01,  7.9371e-01,\\n           3.6715e-01, -4.8209e-01, -5.2709e-01, -2.5099e-01,  3.1052e-01,\\n          -2.7015e-03, -8.7238e-01,  1.4365e+00,  1.3016e-01,  2.9612e-01,\\n          -1.2608e-01, -5.7876e-01, -3.2107e-02,  4.0885e-01, -5.5368e-01,\\n           1.8907e-01,  1.4469e-01,  8.2294e-01, -1.4966e+00,  3.0177e-01,\\n          -1.7778e-01, -3.4443e-01,  6.6757e-01, -4.6816e-02,  9.7292e-02,\\n          -2.0008e-01,  7.8533e-01, -9.2942e-01, -2.5989e-01, -7.6732e-02,\\n          -4.7235e-01]],\\n\\n        [[ 1.7579e-01, -7.1447e-01, -5.3314e-01, -2.9648e-01,  2.8026e-01,\\n           1.8181e+00,  1.4851e-01,  6.4801e-01,  5.0590e-01,  4.2946e-01,\\n           2.4275e-01, -6.7309e-01, -1.7445e-01, -2.4605e-01,  1.3889e-01,\\n           4.8100e-01, -3.1625e-01,  1.2581e+00,  7.8886e-02,  7.5337e-01,\\n           5.3562e-02, -4.4674e-01, -1.4998e-01, -5.8429e-02, -1.0185e+00,\\n           4.9788e-02,  2.0335e-01,  5.0648e-01, -1.1966e+00,  5.8439e-01,\\n          -5.9160e-01, -2.3787e-01,  3.9401e-01, -6.7919e-01, -2.9637e-01,\\n          -2.1829e-02,  9.3474e-01, -4.4899e-02,  1.4231e-01,  5.7999e-01,\\n          -1.1526e+00]],\\n\\n        [[-1.9740e-02, -2.7130e-01, -4.7853e-02,  1.1269e-01, -4.0314e-02,\\n           1.2013e+00, -3.1235e-01,  5.5993e-01,  8.8388e-01,  7.9406e-01,\\n           3.2115e-02,  3.9221e-01, -1.8837e-01,  4.4084e-01,  3.8913e-01,\\n           4.6056e-01, -6.1974e-01,  2.3558e-01,  7.8369e-01,  6.2000e-01,\\n          -1.5692e-01, -9.9517e-01,  1.7596e-01,  6.8479e-01, -3.5890e-01,\\n          -7.3273e-01,  1.5127e-02,  4.5828e-01, -1.1117e+00,  7.0079e-01,\\n           5.4200e-01,  9.5768e-02, -4.7527e-01, -3.3786e-01, -2.2734e-01,\\n           5.1938e-01, -1.2699e-01, -3.5300e-01, -8.3028e-02, -1.8761e-01,\\n          -2.1226e-01]],\\n\\n        [[-3.3762e-01,  1.2187e-01, -4.4586e-01,  1.3724e-01,  3.4719e-01,\\n           1.4122e+00,  1.3776e-01, -6.6216e-02,  9.0900e-02,  7.2348e-01,\\n          -2.3432e-01, -3.6988e-02, -3.4940e-01,  2.5655e-01,  2.4803e-02,\\n           9.8125e-01, -1.3508e+00,  7.0188e-01,  7.8505e-02, -6.3611e-01,\\n           5.9970e-01, -8.0006e-01,  4.4610e-01, -4.0939e-01, -9.1084e-01,\\n           3.2691e-01, -1.0413e+00, -2.4829e-01, -1.0584e+00,  3.1206e-01,\\n           1.7829e-01, -7.3772e-01, -3.1092e-01, -7.0247e-01, -1.9758e-01,\\n           3.4119e-01,  3.7080e-01, -3.8059e-01,  1.2020e-01,  4.1815e-02,\\n          -8.5717e-01]],\\n\\n        [[ 3.3667e-02, -6.4889e-01,  1.7453e-01, -1.5446e-01,  7.8027e-01,\\n           1.5914e+00,  4.5093e-01,  2.0854e-01, -5.8563e-01,  2.8717e-01,\\n          -4.3562e-01, -3.2432e-01, -1.1218e-01, -3.9381e-01,  3.7522e-01,\\n           5.0449e-01, -3.9999e-01,  1.4933e+00, -1.5490e-01,  5.0262e-01,\\n          -4.3046e-01, -7.3996e-01,  3.2294e-01,  1.8764e-01, -1.0715e+00,\\n           2.9763e-01, -2.0804e-01,  4.7540e-01, -1.0346e+00,  6.8931e-01,\\n           6.0289e-02, -1.1392e-01,  4.8008e-01, -2.8344e-01, -1.2021e-01,\\n          -3.6287e-01,  1.0036e+00, -7.5835e-01,  4.9801e-01,  4.5049e-01,\\n          -7.5027e-01]],\\n\\n        [[-1.3075e-01,  8.7994e-01, -1.6683e-01,  1.5776e-01, -1.5562e-02,\\n           1.0219e+00,  6.3893e-02,  6.5325e-01,  5.8342e-01,  9.7113e-01,\\n           6.0181e-02,  2.9051e-01, -4.4676e-01,  9.9070e-02,  7.0502e-02,\\n           9.0707e-01, -1.4337e+00,  1.3031e+00, -3.2724e-01, -7.3566e-02,\\n           5.8713e-01,  2.3454e-01,  4.4065e-01, -2.8466e-01, -1.1663e+00,\\n           8.2886e-02, -4.2388e-02,  9.0402e-02, -1.7830e-01,  5.8090e-01,\\n           2.4722e-01, -4.3948e-01, -6.7810e-01, -1.1872e+00, -1.7815e-01,\\n           2.0908e-01,  2.7836e-01,  5.7752e-01, -1.6943e-01, -4.4537e-01,\\n          -1.0169e+00]],\\n\\n        [[-6.3090e-01,  6.4337e-01, -4.4125e-01, -1.7749e-02, -9.8697e-01,\\n           5.0829e-01, -1.0055e-01, -9.8866e-02,  1.0391e+00,  1.1164e+00,\\n          -3.1101e-01,  1.1488e-01, -5.6773e-01,  3.0594e-01,  6.2342e-01,\\n           1.2415e+00, -1.3056e+00, -3.0370e-01,  6.5574e-01, -9.9620e-01,\\n           1.0506e+00, -5.2388e-01,  1.9770e-01, -1.0106e-01, -5.4761e-01,\\n          -6.6935e-01,  6.9304e-01,  1.9952e-01, -8.4256e-01,  1.2152e-01,\\n           2.1429e-01, -1.4300e-01, -8.1282e-01, -1.3092e+00, -1.2299e-01,\\n           6.0932e-01, -5.4673e-01, -1.4650e-01, -9.9558e-02, -1.6495e+00,\\n          -1.4388e+00]],\\n\\n        [[ 6.1580e-02,  2.7298e-01, -4.8727e-01,  4.3055e-03,  2.7982e-01,\\n           5.3965e-01, -2.9747e-03,  7.8386e-01,  4.8776e-01,  1.2986e+00,\\n           2.5264e-01,  3.9371e-01, -3.8069e-01,  3.6542e-01, -2.4457e-01,\\n           9.9142e-01, -5.7565e-01,  4.9062e-01,  4.5116e-01,  5.3489e-01,\\n          -2.7260e-01, -9.7150e-01,  3.9697e-01, -1.6544e-01, -1.7666e-01,\\n           2.5531e-01, -1.1492e+00, -1.1901e-01, -2.0004e-01,  5.1426e-01,\\n           7.7426e-01,  3.2914e-02, -3.4239e-01, -2.3834e-02,  3.7402e-01,\\n           7.2786e-01, -1.9708e-01, -1.0330e+00, -1.4175e-01, -2.8168e-01,\\n           1.9362e-01]],\\n\\n        [[ 3.2474e-01, -3.3353e-01,  3.2173e-01,  3.0983e-01,  3.8148e-01,\\n           5.7036e-01, -6.9424e-02,  1.3797e-01,  2.0476e-01,  9.2082e-01,\\n          -6.4550e-01, -9.6774e-01,  3.9776e-01,  9.0481e-01,  8.1189e-01,\\n           4.1496e-01, -3.9556e-01,  7.2853e-01, -3.5652e-01,  4.4017e-01,\\n           1.2557e-01, -3.4091e-01, -1.5560e-02, -4.6013e-01, -4.9457e-01,\\n          -5.4021e-02, -5.8988e-01,  5.3100e-01, -8.9531e-01,  7.1164e-01,\\n          -1.7928e-02, -1.0075e+00, -7.0688e-02, -9.6377e-01,  7.6342e-01,\\n          -5.9777e-01,  5.4576e-01, -6.5353e-01, -1.3081e-02,  8.4761e-01,\\n          -3.5528e-01]],\\n\\n        [[ 4.6896e-01, -2.1258e-01,  4.0839e-01, -3.7776e-01,  4.1750e-01,\\n           1.0203e+00, -3.2065e-02, -6.9854e-02,  4.9544e-01,  5.5528e-01,\\n          -5.1350e-01, -3.2688e-01,  7.2819e-02,  3.3259e-01,  5.5625e-01,\\n           5.5903e-01, -8.9481e-01,  1.1083e+00, -6.2923e-01,  6.5171e-01,\\n           2.1512e-01, -4.4360e-01,  3.6267e-01,  2.2794e-01, -7.3473e-01,\\n          -4.4097e-01,  6.7375e-02,  1.1875e-01, -1.1911e+00,  6.2190e-01,\\n          -5.0296e-01, -6.1862e-01,  2.9540e-01, -5.9391e-01,  5.8167e-01,\\n          -2.6986e-01,  9.1171e-01, -3.2234e-01, -1.9823e-01, -2.8068e-02,\\n          -1.1765e+00]],\\n\\n        [[-3.4082e-01,  5.6594e-01, -1.2435e-01, -3.1517e-01, -1.5885e-01,\\n           1.0378e-02, -4.7950e-02,  4.3871e-01,  2.8514e-01,  1.2547e+00,\\n           7.1358e-01,  1.1947e+00, -4.3134e-01,  3.9725e-01, -2.1368e-01,\\n           3.2990e-01, -9.7292e-01,  1.9152e-01, -5.0613e-01,  1.1844e-01,\\n           5.9372e-01, -1.0557e+00,  5.0563e-02, -2.3788e-01,  3.6958e-01,\\n          -1.0343e+00, -1.2578e-01,  8.8337e-02, -5.6542e-01,  6.7194e-01,\\n           6.5527e-01,  1.4104e-01, -7.1430e-01, -6.7695e-01,  2.5509e-01,\\n           8.1092e-01,  2.1964e-01, -3.8864e-01, -2.6910e-01, -5.2928e-01,\\n          -1.5765e-01]],\\n\\n        [[ 5.4998e-01, -1.0341e+00,  1.2665e-01,  1.1639e-01,  6.3071e-01,\\n           9.2799e-01,  1.1926e-01, -2.5175e-02,  1.0927e-01,  4.1401e-01,\\n          -6.0166e-01, -7.8037e-01,  2.3954e-01,  5.5774e-01,  5.8185e-01,\\n          -2.2241e-01,  5.0221e-01,  4.2605e-01,  9.6648e-03,  7.0864e-01,\\n           1.9520e-01,  2.5846e-01,  7.2891e-02,  1.6031e-01, -4.9231e-01,\\n          -4.2171e-01,  5.6706e-01, -1.0437e-01, -8.1088e-01,  8.4030e-01,\\n          -4.4900e-01,  5.2911e-01,  9.9639e-01,  2.6459e-01,  5.7423e-01,\\n          -6.1536e-01,  1.4955e-01, -7.4051e-01, -5.1943e-01,  6.0233e-01,\\n          -1.6532e-01]],\\n\\n        [[-2.0030e-01, -1.1772e-01, -1.7717e-02, -4.9251e-01,  5.5693e-01,\\n           1.3960e+00,  5.6276e-01,  8.1380e-01,  5.0433e-01,  6.3368e-01,\\n          -8.0024e-02, -8.6109e-01, -3.0680e-01, -1.6004e-01, -2.5818e-01,\\n           5.9385e-01,  2.9805e-04,  8.9716e-01,  6.6300e-01,  9.9566e-01,\\n          -5.1352e-01, -1.0402e+00, -1.4929e-01,  4.5068e-01, -3.5177e-01,\\n          -1.5848e-01, -5.2013e-01,  1.0469e+00, -1.1266e+00,  7.2700e-01,\\n          -1.8127e-01, -3.1319e-01,  1.4969e-01, -2.9587e-01, -4.6577e-01,\\n           1.7808e-01,  7.9248e-01, -6.1970e-01,  1.1871e-02,  3.6187e-02,\\n          -3.1269e-01]]], grad_fn=<ViewBackward0>)\\nnext_loss=tensor(0.5459, grad_fn=<NllLossBackward0>)\\nmask_loss=tensor(nan, grad_fn=<NllLossBackward0>)\\ntotal_loss=36.154011249542236\\n bert_inputs=tensor([[ 2],\\n        [ 5],\\n        [ 6],\\n        [18],\\n        [10],\\n        [16],\\n        [23],\\n        [17],\\n        [ 3],\\n        [24],\\n        [18],\\n        [10],\\n        [ 5],\\n        [16],\\n        [22],\\n        [ 5],\\n        [17],\\n        [ 3]])\\nbert_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1]])\\nsegment_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2]])\\nis_nexts=tensor([1])'}, {'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (4, 4, 6, 0.2, 'adam', 1e-05, 0.1, 64), 'message': \"Error: 'accuracy'\"}, {'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (16, 10, 8, 0.2, 'adam', 0.0001, 0.3, 64), 'message': \"Error: 'accuracy'\"}, {'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (16, 10, 2, 0.3, 'sgd', 0.0001, 0.4, 4), 'message': \"Error: 'accuracy'\"}, {'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (4, 8, 6, 0.1, 'sgd', 0.01, 0.1, 16), 'message': \"Error: 'accuracy'\"}, {'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (16, 10, 8, 0.3, 'adam', 0.0001, 0.1, 16), 'message': \"Error: 'accuracy'\"}, {'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (4, 10, 4, 0.4, 'adam', 0.01, 0.4, 64), 'message': \"Error: 'accuracy'\"}, {'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (4, 4, 6, 0.4, 'adam', 0.0001, 0.4, 4), 'message': \"Error: 'accuracy'\"}, {'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (16, 10, 6, 0.4, 'adam', 0.0001, 0.3, 16), 'message': \"Error: 'accuracy'\"}, {'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (4, 6, 6, 0.2, 'sgd', 1e-05, 0.2, 4), 'message': \"Error: 'accuracy'\"}, {'loss': inf, 'accurracy': inf, 'f1': inf, 'hiperparametros': (32, 6, 8, 0.3, 'sgd', 0.01, 0.4, 32), 'message': \"Error: 'accuracy'\"}]\n",
      "¡Barrido terminado!\n"
     ]
    }
   ],
   "source": [
    "trainer.ejecutar_barrido()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b06c12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f1: inf\n",
      "Best embedding_dim: 32\n",
      "Best net_layers: 10\n",
      "Best net_heads: 2\n",
      "Best dropout: 0.4\n",
      "Best optimizer_class: adam\n",
      "Best learning_rate_initial: 0.0001\n",
      "Best gamma: 0.1\n",
      "Best batch_size: 1\n"
     ]
    }
   ],
   "source": [
    "mejor_punto_idx = trainer.retornar_mejor_combinacion_idx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be3db856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (32, 10, 2, 0.4, 'adam', 0.0001, 0.1, 1),\n",
       "  'message': 'Error: loss.item()=nan---next_sentence_prediction=tensor([[-0.9926, -0.1228]], grad_fn=<AddmmBackward0>)\\nmasked_language=tensor([[[ 0.6330, -0.5401, -0.4905, -0.2875,  0.5209, -1.4393, -0.1735,\\n          -0.7531,  0.5240, -0.8471, -0.5373, -0.9312,  0.7706, -1.0290,\\n           0.3815,  0.8341, -0.6442,  1.0276,  0.3808, -0.6916, -0.0399,\\n          -0.7026,  0.9479, -0.2729, -0.3086, -0.0595,  0.1314,  0.9327,\\n           0.8023,  0.1291,  0.7731, -0.6390, -0.0985,  0.2472,  0.8053,\\n           0.2393,  0.2995,  0.0185,  0.3466, -0.4442,  0.2406]],\\n\\n        [[ 0.0442, -0.2561,  0.3515, -0.3888, -0.3348, -1.2630,  0.0882,\\n          -0.6791,  0.2616, -0.5348, -0.4634, -0.8301,  0.6843, -1.0532,\\n           0.6121,  1.1965, -0.5020,  1.0531, -0.0439, -0.4260, -0.4710,\\n          -0.5962,  0.7753, -0.6855, -0.0090, -0.1541, -0.3733,  0.7957,\\n           0.3054,  0.4261,  0.5617, -0.3798, -0.0722,  0.1621,  0.3474,\\n           0.6150, -0.0703, -0.4828,  0.4105, -0.5026, -0.2270]],\\n\\n        [[ 0.8542,  0.1261,  0.0371, -0.6576, -0.0309, -0.5264, -0.2459,\\n           0.2286, -0.1931, -0.3868, -0.5085, -0.5233,  0.2384, -1.1603,\\n           0.0515,  0.8165, -0.2415,  0.7747,  0.1167, -0.5773, -0.6448,\\n          -0.8685,  0.3677, -0.6119,  0.0679,  0.3265,  0.2309,  0.9251,\\n           0.4841,  0.2921,  0.4510,  0.2710, -0.6197, -0.2724,  0.6495,\\n           0.5481, -0.4642, -0.6219, -0.5080, -0.2371,  0.2961]],\\n\\n        [[ 0.7835,  0.1500, -0.6564, -0.4244, -0.1314, -1.8659,  0.4631,\\n          -0.1459, -0.2289, -0.9084, -0.1940, -0.3455,  0.9738, -0.0372,\\n           0.2717,  0.9241, -0.9362,  1.0271,  0.1946, -0.4562,  0.3090,\\n           0.3363,  0.4967,  0.0852, -0.1738, -0.3767, -0.3753,  0.2503,\\n          -0.0710,  0.3022,  0.1004, -0.8941, -0.3181, -0.1723,  1.2432,\\n           0.2391,  0.2079,  0.5278,  0.3672,  0.1566, -0.4658]],\\n\\n        [[ 0.5389,  0.5516, -0.6273, -0.1409, -0.5423, -1.5403,  0.3626,\\n          -0.3300, -0.3948, -0.6393, -0.0064,  0.1103,  0.4039, -0.0193,\\n           0.5251,  0.8421, -1.0367,  1.5601,  0.7809,  0.4958, -0.5248,\\n          -0.0068,  0.3402, -0.0895,  0.4054,  0.0650, -0.1852,  0.1332,\\n           0.2011,  0.5370, -0.0751, -0.7215, -0.1579, -0.1300,  0.8421,\\n           0.4327,  0.1975,  0.8718,  0.2696, -0.2184, -0.7184]],\\n\\n        [[-0.2314,  0.0885,  0.1387, -0.8091, -0.0962, -1.3391, -0.0223,\\n           0.0115,  0.1092, -0.5700, -0.3179, -0.8395,  0.9153, -1.2484,\\n           0.8946,  1.1478, -0.9330,  0.8600,  0.2538, -0.2325, -0.4578,\\n          -0.3017,  0.7862, -0.6594,  0.2448, -0.1723,  0.2386,  0.5079,\\n           0.1813,  0.3253, -0.0778, -0.6250,  0.1498,  0.0243,  0.9399,\\n           0.3799, -0.0718,  0.1676,  0.3865, -0.4574, -0.1061]],\\n\\n        [[ 0.5375,  0.4181, -0.1871, -0.4528, -0.1480, -1.3624,  0.4514,\\n          -0.6002, -0.0480, -0.5867, -0.4418, -0.5684,  0.6507, -0.4677,\\n           0.7184,  1.1818, -0.9338,  1.2666, -0.0345, -0.3956, -0.2784,\\n          -0.0486,  1.0011, -0.1659,  0.1503,  0.0394,  0.3116,  0.4890,\\n           0.4908,  0.4961,  0.2469, -0.6258, -0.4904,  0.2413,  0.8032,\\n           0.5395,  0.0822,  0.0256,  0.1291, -0.1845,  0.0303]],\\n\\n        [[ 0.0583,  0.2839, -0.3320, -0.5455,  0.0320, -0.9134,  0.1715,\\n          -0.4274,  0.3176, -0.7388,  0.4321, -1.1547,  1.0452, -0.5148,\\n           0.7332,  1.1570, -0.7321,  0.8487,  0.5503,  0.1989,  0.0039,\\n          -0.2204,  1.3572, -0.0374, -0.4820,  0.1853,  0.4029, -0.0504,\\n           0.4091,  0.1524, -0.2059, -0.6046, -0.2816,  0.0095,  1.3810,\\n           0.0951,  0.5298,  0.2917,  0.8702, -0.2058,  0.4307]],\\n\\n        [[ 0.3660, -0.0029, -0.9500, -0.6340, -0.4300, -1.8532,  0.4314,\\n           0.1981, -0.2394, -0.7404,  0.2394, -0.4636,  0.4199, -0.4029,\\n           0.4227,  1.0263, -0.8290,  0.8108,  0.5190, -0.2069, -0.1603,\\n           0.4226,  0.8065, -0.1269,  0.2319, -0.1679,  0.4475,  0.3172,\\n          -0.2546,  0.7782,  0.2212, -0.6749, -0.4256, -0.3939,  1.4501,\\n           0.2576, -0.0923,  0.3833,  0.4330, -0.2969, -0.0967]],\\n\\n        [[ 0.6330,  0.5010, -0.0614, -0.6536,  0.3680, -1.5260,  0.3927,\\n          -0.1616, -0.3792, -0.9052,  0.0395, -0.6301,  0.7771, -0.5488,\\n           0.7282,  0.9171, -0.7115,  0.9150, -0.1513, -0.6004, -0.0510,\\n          -0.3056,  0.8358, -0.0465,  0.1473, -0.4508,  0.0202,  0.3240,\\n           0.2949,  0.2778,  0.1101, -0.7071, -0.3301, -0.0068,  1.0594,\\n           0.3840, -0.4331,  0.4386,  0.0599, -0.0780, -0.2514]],\\n\\n        [[ 0.3738, -0.2036,  0.1590, -0.4480, -0.0156, -1.6940,  0.6593,\\n          -0.9008,  0.0741, -0.3464, -0.2285, -0.3026,  0.4670, -0.5026,\\n           0.2565,  0.7260, -0.8683,  1.4045,  0.1341,  0.5334,  0.0153,\\n          -0.0250,  0.6624, -0.3265,  0.5835, -0.1808,  0.4143,  0.0261,\\n           0.2176,  0.6316,  0.1395, -0.7495, -0.3409,  0.0258,  0.5336,\\n           0.0058,  0.1531,  0.9149,  0.3537, -0.3761, -0.4401]],\\n\\n        [[ 0.6779,  0.5169, -0.2082, -0.1953, -0.0740, -0.7396,  0.3831,\\n          -0.5070, -0.1595, -0.1125, -0.4601, -0.6881,  0.3534, -0.7518,\\n           1.0976,  0.9815, -0.3211,  1.1933,  0.4265,  0.5475, -0.6570,\\n          -0.2030,  0.6971, -0.4414,  0.6249,  0.4051, -0.0062,  0.3586,\\n           0.5358,  1.0052,  0.5196, -0.7060, -0.3686,  0.3052,  0.4565,\\n           0.1752,  0.1063,  0.1513,  0.2211, -0.3416,  0.1618]],\\n\\n        [[ 0.5031,  0.6096, -0.3514, -0.1443, -0.4221, -1.4533,  0.6415,\\n          -0.1591, -0.0753, -0.0045,  0.1827, -0.5764,  0.4007,  0.4109,\\n           0.8449,  1.0739, -0.7090,  1.4387,  0.3393,  0.6188, -0.0409,\\n           0.1505,  0.7837,  0.0177,  0.3953,  0.2653,  0.0967, -0.2157,\\n           0.4344,  0.2422, -0.1500, -0.4395, -0.6182, -0.0161,  1.0274,\\n           0.4997,  0.5381,  0.6863,  0.4448,  0.1740, -0.1518]],\\n\\n        [[ 0.7488,  0.4561, -0.2077,  0.1673, -0.0114, -1.1239,  0.6123,\\n          -0.5042, -0.1187, -0.1555,  0.0187, -0.4806,  0.4445,  0.1587,\\n           0.7176,  1.2015, -0.3699,  1.3093,  0.4913,  0.4122, -0.5689,\\n          -0.1476,  0.8848, -0.3243,  0.5511, -0.1308, -0.2005,  0.3252,\\n           0.7634,  0.6179, -0.0285, -0.1418, -0.1988,  0.1108,  1.0986,\\n           0.1316,  0.0373,  0.5524,  0.1816,  0.3408, -0.4134]]],\\n       grad_fn=<ViewBackward0>)\\nnext_loss=tensor(0.3500, grad_fn=<NllLossBackward0>)\\nmask_loss=tensor(nan, grad_fn=<NllLossBackward0>)\\ntotal_loss=74.29624247550964\\n bert_inputs=tensor([[ 2],\\n        [ 5],\\n        [24],\\n        [19],\\n        [13],\\n        [17],\\n        [ 3],\\n        [40],\\n        [19],\\n        [13],\\n        [17],\\n        [ 3],\\n        [ 1],\\n        [ 1]])\\nbert_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1]])\\nsegment_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [0],\\n        [0]])\\nis_nexts=tensor([1])'},\n",
       " {'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (4, 8, 2, 0.4, 'sgd', 1e-05, 0.1, 32),\n",
       "  'message': \"Error: 'accuracy'\"},\n",
       " {'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (16, 4, 2, 0.4, 'adam', 0.001, 0.3, 1),\n",
       "  'message': 'Error: loss.item()=nan---next_sentence_prediction=tensor([[ 0.5151, -0.3330]], grad_fn=<AddmmBackward0>)\\nmasked_language=tensor([[[-7.1701e-01,  3.2126e-01,  7.0328e-02,  2.5112e-01, -3.4864e-01,\\n          -2.3814e-01, -3.1466e-01,  1.8318e-01,  6.0767e-01,  3.1141e-01,\\n           3.9902e-01, -6.1848e-01, -6.4851e-01, -8.3111e-01,  7.4725e-01,\\n           3.8215e-01,  8.2416e-01, -2.5133e-01, -1.7101e+00,  5.3768e-01,\\n          -7.1547e-01, -9.3553e-02, -1.0108e+00, -1.8344e-01,  1.8670e-01,\\n           6.3253e-01, -2.1177e-01,  6.4524e-01, -1.7307e+00,  1.0198e+00,\\n           8.4286e-01, -3.0097e-01, -5.5011e-01, -1.2577e-01,  2.2159e-01,\\n           7.3645e-01,  1.3156e+00,  4.4565e-01, -3.0537e-01,  3.9048e-01,\\n           1.0807e-01]],\\n\\n        [[ 5.7224e-01,  6.1081e-01,  1.4965e-01, -5.2763e-01,  4.4121e-01,\\n           2.3446e-01,  9.1915e-01,  9.7279e-01,  2.5121e-01, -5.0523e-01,\\n          -3.2007e-01, -2.1663e-01,  2.6771e-01,  3.2352e-01,  1.2089e-01,\\n           6.5207e-02,  4.6234e-01, -1.0231e-01, -9.8661e-01, -1.0049e+00,\\n          -1.2787e-01,  7.7424e-01, -9.2532e-01,  7.9320e-01,  3.3869e-02,\\n          -3.1282e-02, -5.8834e-01,  1.6765e-01, -4.5134e-01,  2.7924e-01,\\n           5.2708e-01,  1.6790e-01,  1.0773e-01,  6.3378e-01,  2.9579e-01,\\n           8.9581e-01, -7.7853e-01, -5.6400e-01,  2.5568e-01, -2.3781e-01,\\n           1.5122e-01]],\\n\\n        [[ 8.5388e-02,  2.0727e-01, -1.3123e-02, -7.0362e-01,  8.5067e-01,\\n           5.7733e-01,  1.1411e+00, -1.1459e+00,  8.1837e-02,  2.5100e-01,\\n          -1.0748e-02, -5.0404e-01,  1.7020e-01,  5.3007e-01, -1.6221e-01,\\n           1.0282e-01,  2.0077e-01, -2.8010e-01, -7.4343e-01, -8.4897e-01,\\n           4.8049e-01,  3.7841e-01, -2.9235e-01,  9.6559e-01, -1.4416e+00,\\n           2.4309e-02, -1.0321e+00,  6.7755e-01, -6.4328e-01,  6.0150e-01,\\n           7.1992e-01,  4.7680e-01, -8.5663e-01,  1.7761e-02,  2.4631e-01,\\n           4.0743e-02, -4.2561e-01, -4.8957e-01, -6.9715e-01, -2.4426e-01,\\n           6.2993e-01]],\\n\\n        [[-5.9268e-01,  1.3145e+00, -4.1651e-01, -6.7661e-01, -2.7160e-01,\\n          -1.1941e+00, -3.9409e-01, -4.7480e-01, -1.9672e-01, -3.7229e-01,\\n           3.2967e-01, -3.0521e-01, -3.6474e-01,  1.2722e-01,  8.9645e-01,\\n          -6.7246e-02,  6.4377e-01, -1.5092e+00,  3.4260e-01,  2.2464e-01,\\n          -1.6262e-01,  1.1509e-01, -5.6706e-01,  2.5176e-02,  4.1940e-01,\\n           8.1343e-01, -1.1478e+00, -5.1323e-01, -1.9548e-02, -2.6912e-01,\\n           8.5983e-01, -2.0667e-01, -1.6121e-01, -5.5655e-01, -1.1658e-01,\\n           6.3578e-01, -8.1378e-01,  9.6121e-01, -3.6826e-01,  8.7201e-01,\\n          -4.9591e-01]],\\n\\n        [[ 4.7186e-01,  7.1342e-01, -9.4726e-01, -3.8139e-01,  3.8051e-01,\\n           4.1646e-02,  8.4943e-01,  2.4253e-01,  3.8972e-01,  1.0051e+00,\\n           3.3379e-01,  6.3187e-03, -5.0868e-01,  4.8289e-01,  2.2704e-01,\\n           5.5486e-01,  1.0791e+00,  1.7594e-01, -1.6858e+00, -6.8345e-01,\\n          -1.4664e-01,  6.7831e-02, -1.6474e-01,  3.3576e-01, -3.5965e-01,\\n           4.9468e-01, -5.7591e-01,  5.7524e-02, -1.0548e+00,  7.9117e-01,\\n           9.8981e-01,  8.3768e-01,  4.0936e-02, -3.7443e-01,  2.1444e-01,\\n          -9.4466e-02, -3.4082e-01,  4.0241e-01, -1.2177e-01,  7.2139e-01,\\n           4.8046e-01]],\\n\\n        [[-5.5580e-01,  5.6956e-01, -2.1450e-01,  2.2354e-01,  2.3018e-01,\\n          -2.9796e-01, -8.1436e-01, -4.3980e-01,  2.5966e-01, -4.5450e-01,\\n           6.4022e-01, -5.4485e-01, -7.2469e-01,  4.2321e-01, -1.1641e-01,\\n          -3.6601e-01,  4.3800e-01, -5.8901e-01, -8.0919e-01, -8.6859e-01,\\n           3.7972e-01,  5.3177e-01, -6.2345e-01,  7.2208e-01,  2.1421e-01,\\n           8.7348e-01, -8.6441e-01,  1.5292e-02,  1.4092e-01,  2.5900e-01,\\n           3.3498e-01,  2.8667e-02, -2.5752e-01,  3.1076e-03,  1.5551e-01,\\n           6.0841e-01, -2.5261e-01,  5.3556e-01, -1.1771e+00, -2.4124e-01,\\n          -2.5349e-01]],\\n\\n        [[-4.2659e-01,  1.2132e+00, -2.5857e-01, -2.4981e-01,  1.0665e+00,\\n          -3.0251e-01, -8.9620e-01, -5.6895e-01,  1.8113e-01, -4.7778e-02,\\n           2.6402e-01,  4.3881e-02, -1.9495e-01,  3.2853e-01, -2.3538e-01,\\n          -5.7041e-01,  2.1150e-01, -4.7433e-01, -1.0207e+00, -1.1383e+00,\\n           5.0889e-01,  2.0268e-01, -3.6388e-01,  4.5107e-01,  1.2610e-01,\\n           6.0187e-01, -8.9740e-01, -4.8671e-01,  9.2957e-02, -5.4097e-03,\\n           2.2917e-01, -5.1021e-01, -2.6148e-01, -3.6687e-01, -6.5834e-02,\\n           4.7077e-01, -1.0570e+00,  5.1172e-01, -8.3788e-01, -1.6956e-01,\\n          -1.2430e-01]],\\n\\n        [[ 1.0272e+00, -1.0468e+00, -3.7849e-01,  8.5365e-01, -1.1052e-01,\\n           9.0345e-01,  5.8549e-01,  6.9792e-01,  1.1451e+00,  3.3075e-01,\\n          -4.7360e-01, -1.6117e-01, -4.3399e-01,  1.0545e-01,  3.3159e-02,\\n           6.0570e-01,  8.9592e-01,  1.4355e+00, -1.0249e+00,  2.8133e-01,\\n          -3.0678e-01,  4.6567e-01,  5.6315e-01,  4.8959e-01,  3.4232e-01,\\n          -1.6832e-01, -1.3322e-02,  1.2371e+00, -6.8182e-01,  1.0124e+00,\\n           1.2883e-01,  5.3464e-01, -2.7716e-01,  1.0513e-01,  3.3737e-02,\\n          -4.3398e-01,  1.1534e+00, -6.0964e-01,  3.9821e-01,  3.0774e-01,\\n           1.2479e-01]],\\n\\n        [[-5.3730e-01,  1.2284e+00, -1.4042e-01,  8.5026e-02, -5.6867e-01,\\n          -8.4161e-01, -1.0368e-01, -2.2905e-01,  3.2457e-01, -6.7742e-02,\\n          -5.1635e-01,  1.9178e-01, -1.1030e+00,  4.1687e-01,  1.0417e+00,\\n          -7.0985e-02,  6.7706e-01, -9.8882e-01, -9.7622e-02,  1.0128e-01,\\n          -6.4416e-01,  2.5100e-01, -4.6435e-01, -4.1059e-01,  1.0694e+00,\\n           4.6228e-01, -5.9408e-01, -1.1391e-01,  4.6933e-02,  9.1241e-02,\\n           3.8767e-01,  1.4612e-01, -3.2959e-01, -6.3605e-01, -5.7480e-01,\\n           7.8988e-01, -3.7580e-01,  8.0727e-01, -5.7127e-02,  7.5172e-01,\\n          -3.2065e-01]],\\n\\n        [[-6.3427e-01,  1.5121e+00, -2.8778e-01,  1.3183e-01,  8.6922e-01,\\n          -3.3217e-01,  1.1018e-01,  5.1467e-01,  4.1747e-02,  4.1507e-01,\\n           6.1125e-02,  1.3040e+00, -4.4564e-01,  9.0728e-01, -7.5807e-01,\\n          -4.2117e-01,  5.3936e-01, -7.3158e-03, -1.7506e+00, -7.1327e-01,\\n           2.5348e-01,  1.5200e-02, -7.3769e-01,  5.3925e-01,  3.0739e-01,\\n           8.2342e-01, -2.9376e-01,  1.7764e-01, -4.5684e-01,  2.3651e-01,\\n           4.9423e-01,  1.2336e-01,  3.5971e-01, -1.6491e-01,  1.5242e-01,\\n           5.8517e-01, -7.2619e-01,  1.4926e-02, -7.8328e-01, -1.3493e-03,\\n           3.6074e-01]],\\n\\n        [[-2.5085e-01,  1.0710e+00,  8.2171e-01, -4.5310e-02, -1.0840e-01,\\n           1.5446e-01, -7.3620e-01, -4.5385e-01,  7.9943e-01, -2.0205e-01,\\n          -1.0329e-01, -1.1746e+00, -1.7192e-01, -8.1908e-01,  4.3529e-01,\\n          -3.2720e-01,  5.9828e-01, -3.4669e-01, -7.1624e-01, -6.8762e-01,\\n          -5.4486e-01,  2.6044e-01,  1.0898e-01, -4.2812e-01,  4.2433e-02,\\n           2.6885e-01, -3.9047e-01, -2.1842e-01, -1.3996e+00,  1.4303e+00,\\n           2.2704e-01, -9.6163e-02, -2.6564e-01, -3.2358e-01,  6.3175e-01,\\n           6.6360e-01, -1.0008e-01,  5.8129e-01,  3.1243e-01, -2.3634e-01,\\n           1.7419e-01]],\\n\\n        [[-4.6669e-01,  1.3844e+00, -7.1804e-01, -3.8029e-02,  6.8118e-01,\\n          -5.6453e-01, -5.7588e-01,  3.5899e-01,  1.7947e-01,  3.7129e-01,\\n           6.0407e-01,  5.9405e-01, -2.7228e-01,  4.9591e-01, -2.8250e-01,\\n          -1.0098e-01,  1.0249e+00, -1.4393e-01, -9.4588e-01,  3.3468e-01,\\n          -1.9522e-01, -2.9150e-01, -8.8408e-02,  4.0877e-01,  2.5050e-01,\\n           1.0116e+00, -8.5171e-01, -1.0440e-02, -8.6519e-01,  3.6916e-01,\\n           1.0613e+00, -1.2395e-01,  3.7089e-01, -4.1368e-01,  3.9187e-01,\\n           1.0442e-01, -5.9414e-01,  5.6248e-01, -3.5341e-01,  8.3664e-01,\\n           9.1746e-02]]], grad_fn=<ViewBackward0>)\\nnext_loss=tensor(0.3564, grad_fn=<NllLossBackward0>)\\nmask_loss=tensor(nan, grad_fn=<NllLossBackward0>)\\ntotal_loss=124.61984276771545\\n bert_inputs=tensor([[ 2],\\n        [24],\\n        [21],\\n        [11],\\n        [16],\\n        [ 3],\\n        [40],\\n        [21],\\n        [11],\\n        [16],\\n        [ 3],\\n        [ 1]])\\nbert_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1]])\\nsegment_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [0]])\\nis_nexts=tensor([0])'},\n",
       " {'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (32, 4, 4, 0.3, 'adam', 0.01, 0.3, 64),\n",
       "  'message': \"Error: 'accuracy'\"},\n",
       " {'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (16, 6, 4, 0.2, 'adam', 0.0001, 0.3, 16),\n",
       "  'message': \"Error: 'accuracy'\"},\n",
       " {'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (4, 8, 6, 0.4, 'sgd', 0.001, 0.2, 1),\n",
       "  'message': 'Error: loss.item()=nan---next_sentence_prediction=tensor([[-0.5044,  0.1069]], grad_fn=<AddmmBackward0>)\\nmasked_language=tensor([[[ 6.7123e-01, -7.5253e-02,  6.8565e-01, -6.6712e-02,  2.1862e-01,\\n           2.4617e-01,  4.8320e-01,  5.9677e-01, -1.8537e-01, -4.5113e-01,\\n           1.7239e-01, -2.2071e-01,  2.3060e-01,  7.6194e-01,  3.0318e-01,\\n          -7.8092e-02, -5.9052e-02,  9.8091e-01,  4.5902e-01, -3.3857e-01,\\n           7.9074e-02,  7.3762e-02, -7.2304e-01,  6.6313e-01,  2.5612e-02,\\n           4.7886e-01,  2.7968e-01, -9.2317e-02, -2.1131e-01,  1.0851e-01,\\n          -3.0950e-01,  6.3967e-01,  4.4314e-01,  1.1771e-01,  2.1609e-01,\\n           7.5956e-01,  5.3123e-01,  5.2976e-01,  7.4852e-01, -9.9075e-01,\\n           2.7045e-01]],\\n\\n        [[ 7.0005e-01, -2.1966e-01,  7.8542e-01, -2.7873e-02,  1.0880e-01,\\n           1.1518e-01,  4.7749e-01,  6.0398e-01, -1.1994e-01, -5.2262e-01,\\n           2.7172e-01, -9.3733e-02,  1.9729e-01,  7.0171e-01,  4.3837e-01,\\n          -1.1123e-02, -2.4052e-02,  8.0304e-01,  3.0438e-01, -3.3025e-01,\\n          -6.9938e-02,  1.2751e-01, -7.8193e-01,  5.3650e-01,  7.3345e-02,\\n           3.9366e-01,  2.3400e-01, -1.1392e-01, -3.5883e-01,  2.0065e-01,\\n          -2.2685e-01,  6.5609e-01,  4.1572e-01,  1.0738e-01,  1.4377e-01,\\n           6.2381e-01,  6.5550e-01,  4.1128e-01,  6.4693e-01, -1.0246e+00,\\n           1.3237e-01]],\\n\\n        [[ 6.5653e-01, -2.2913e-01,  7.6860e-01, -1.7256e-02,  8.5050e-02,\\n           1.3943e-01,  5.0248e-01,  5.9285e-01, -1.0573e-01, -5.4398e-01,\\n           2.3780e-01, -1.5220e-01,  2.1127e-01,  6.9841e-01,  4.1474e-01,\\n          -4.5174e-02, -3.7077e-02,  8.5377e-01,  2.9199e-01, -3.5572e-01,\\n          -6.6436e-02,  8.2353e-02, -7.6547e-01,  5.7253e-01,  3.8918e-02,\\n           4.0604e-01,  2.0856e-01, -1.0832e-01, -3.5348e-01,  2.0172e-01,\\n          -2.2791e-01,  6.0993e-01,  4.1550e-01,  8.2957e-02,  1.8907e-01,\\n           6.5620e-01,  6.1906e-01,  4.6279e-01,  6.6567e-01, -1.0541e+00,\\n           1.5304e-01]],\\n\\n        [[ 4.5109e-01,  1.1080e+00, -2.5686e-01, -5.4037e-01,  1.1331e+00,\\n           6.1119e-01, -1.9940e-01, -6.3519e-02, -6.7943e-01,  2.7257e-01,\\n          -5.4770e-01, -5.3737e-01,  4.7955e-01,  6.5239e-01, -3.4727e-01,\\n          -2.3062e-01, -2.5940e-01,  1.3556e+00,  1.4798e+00, -2.0450e-01,\\n           1.2124e+00,  2.3420e-01,  3.7277e-01,  5.0856e-01, -4.1680e-01,\\n           7.6394e-01,  5.3765e-01,  4.1158e-01,  1.1848e+00, -9.0498e-01,\\n          -8.3603e-01,  4.4606e-01,  3.0177e-01,  2.5745e-01, -7.2961e-03,\\n           1.1506e+00, -1.8937e-01,  7.1389e-01,  1.0482e+00, -7.4814e-02,\\n           6.4901e-01]],\\n\\n        [[ 1.0325e+00,  6.1269e-01,  4.4127e-01, -3.6971e-01,  9.2515e-01,\\n           3.7546e-01,  9.3152e-02,  5.7327e-01, -5.9716e-01,  9.7847e-02,\\n           1.5850e-01,  4.2569e-02,  2.0828e-01,  9.2571e-01,  1.0178e-01,\\n           9.8631e-02, -4.1979e-02,  9.3901e-01,  1.1728e+00, -5.5456e-02,\\n           6.2723e-01,  4.6456e-01, -5.4614e-01,  5.5309e-01,  1.9814e-01,\\n           6.0912e-01,  7.1977e-01, -3.0150e-03,  3.6368e-01, -3.2595e-01,\\n          -6.0358e-01,  1.0655e+00,  4.8607e-01,  4.3666e-01, -1.4253e-01,\\n           8.1678e-01,  4.8308e-01,  2.9578e-01,  8.5272e-01, -4.0875e-01,\\n           4.5894e-01]],\\n\\n        [[ 7.2415e-01,  5.3856e-03,  6.6507e-01, -1.0110e-01,  3.0512e-01,\\n           2.6739e-01,  4.4576e-01,  6.0863e-01, -2.3685e-01, -3.8550e-01,\\n           1.7861e-01, -1.8809e-01,  2.2458e-01,  7.9285e-01,  2.7836e-01,\\n          -5.5964e-02, -5.5080e-02,  9.8236e-01,  5.4808e-01, -3.0313e-01,\\n           1.4187e-01,  1.1941e-01, -7.1925e-01,  6.6308e-01,  5.5846e-02,\\n           4.9795e-01,  3.3893e-01, -8.9967e-02, -1.5120e-01,  6.3870e-02,\\n          -3.4539e-01,  7.0206e-01,  4.5500e-01,  1.5971e-01,  1.7812e-01,\\n           7.7057e-01,  5.3041e-01,  5.0361e-01,  7.6514e-01, -9.2856e-01,\\n           3.0024e-01]],\\n\\n        [[ 6.8338e-01,  1.5155e-02,  6.3721e-01, -9.8120e-02,  2.9847e-01,\\n           2.9846e-01,  4.6175e-01,  5.9312e-01, -2.3241e-01, -3.9380e-01,\\n           1.3799e-01, -2.4788e-01,  2.4050e-01,  7.9239e-01,  2.4519e-01,\\n          -9.0133e-02, -6.9863e-02,  1.0388e+00,  5.5454e-01, -3.2430e-01,\\n           1.6260e-01,  7.9079e-02, -6.9265e-01,  6.9962e-01,  1.9962e-02,\\n           5.1565e-01,  3.2179e-01, -7.9728e-02, -1.2675e-01,  5.1190e-02,\\n          -3.5526e-01,  6.5993e-01,  4.5513e-01,  1.4050e-01,  2.1906e-01,\\n           8.0910e-01,  4.8625e-01,  5.5585e-01,  7.8931e-01, -9.4429e-01,\\n           3.2874e-01]],\\n\\n        [[ 7.0815e-01, -2.2175e-01,  7.9070e-01, -2.8818e-02,  1.1001e-01,\\n           1.0706e-01,  4.7244e-01,  6.0548e-01, -1.2062e-01, -5.2072e-01,\\n           2.8008e-01, -7.9928e-02,  1.9406e-01,  7.0016e-01,  4.4625e-01,\\n          -3.2851e-03, -2.0875e-02,  7.8890e-01,  3.0228e-01, -3.2555e-01,\\n          -7.4425e-02,  1.3707e-01, -7.8564e-01,  5.2605e-01,  8.0332e-02,\\n           3.8900e-01,  2.3702e-01, -1.1511e-01, -3.6333e-01,  2.0258e-01,\\n          -2.2442e-01,  6.6425e-01,  4.1471e-01,  1.1129e-01,  1.3350e-01,\\n           6.1418e-01,  6.6512e-01,  3.9880e-01,  6.4066e-01, -1.0199e+00,\\n           1.2464e-01]],\\n\\n        [[ 5.9687e-01,  9.9689e-02,  5.3655e-01, -1.1584e-01,  3.3782e-01,\\n           3.9191e-01,  4.6926e-01,  5.4192e-01, -2.5332e-01, -3.7114e-01,\\n           2.1655e-02, -3.9089e-01,  2.8391e-01,  7.9957e-01,  1.3771e-01,\\n          -1.6984e-01, -1.0994e-01,  1.1875e+00,  6.2971e-01, -3.5975e-01,\\n           2.6619e-01,  1.1073e-03, -5.9710e-01,  7.8501e-01, -6.8688e-02,\\n           5.7348e-01,  3.0812e-01, -4.0446e-02, -8.0802e-03, -2.2920e-02,\\n          -4.0642e-01,  5.7423e-01,  4.5598e-01,  1.1238e-01,  2.9965e-01,\\n           9.1783e-01,  3.5871e-01,  6.7922e-01,  8.6249e-01, -9.3598e-01,\\n           4.1936e-01]],\\n\\n        [[ 5.0598e-01,  1.7223e-01,  4.3776e-01, -1.3248e-01,  3.6576e-01,\\n           4.6408e-01,  4.6425e-01,  4.7629e-01, -2.6631e-01, -3.5400e-01,\\n          -9.0704e-02, -5.1793e-01,  3.2656e-01,  7.8860e-01,  4.6411e-02,\\n          -2.4131e-01, -1.4761e-01,  1.3074e+00,  6.8627e-01, -3.9415e-01,\\n           3.5756e-01, -6.6837e-02, -4.8978e-01,  8.4065e-01, -1.6039e-01,\\n           6.1798e-01,  2.8459e-01,  5.3234e-03,  1.0481e-01, -9.5834e-02,\\n          -4.4841e-01,  4.8120e-01,  4.4676e-01,  8.0893e-02,  3.6416e-01,\\n           1.0059e+00,  2.4104e-01,  7.8475e-01,  9.1951e-01, -9.2075e-01,\\n           4.8665e-01]],\\n\\n        [[ 5.4197e-01,  8.4900e-01, -3.7130e-03, -4.1579e-01,  9.4685e-01,\\n           6.3055e-01,  6.0708e-02,  2.0496e-01, -5.8913e-01,  1.0518e-01,\\n          -3.6694e-01, -5.3606e-01,  4.1328e-01,  7.8835e-01, -2.5762e-01,\\n          -2.3256e-01, -2.1628e-01,  1.4131e+00,  1.3047e+00, -2.4545e-01,\\n           9.6734e-01,  1.3584e-01, -2.0521e-03,  7.2045e-01, -2.7261e-01,\\n           7.6061e-01,  5.2548e-01,  2.3317e-01,  8.2912e-01, -6.2986e-01,\\n          -7.4241e-01,  5.4699e-01,  3.9950e-01,  2.4047e-01,  1.4366e-01,\\n           1.1582e+00, -4.2401e-02,  7.6088e-01,  1.0565e+00, -3.6707e-01,\\n           6.7686e-01]],\\n\\n        [[ 6.8346e-01, -9.7305e-02,  7.0537e-01, -6.1655e-02,  2.0467e-01,\\n           2.2286e-01,  4.8040e-01,  6.0193e-01, -1.7724e-01, -4.5962e-01,\\n           1.9426e-01, -1.9218e-01,  2.2279e-01,  7.5468e-01,  3.2792e-01,\\n          -6.2535e-02, -5.1340e-02,  9.4659e-01,  4.3663e-01, -3.3347e-01,\\n           5.4312e-02,  8.8382e-02, -7.3764e-01,  6.4014e-01,  3.9595e-02,\\n           4.6413e-01,  2.7699e-01, -9.7942e-02, -2.3708e-01,  1.2432e-01,\\n          -2.9627e-01,  6.5058e-01,  4.3992e-01,  1.2007e-01,  1.9912e-01,\\n           7.3411e-01,  5.5694e-01,  5.0404e-01,  7.3040e-01, -9.9335e-01,\\n           2.4676e-01]],\\n\\n        [[ 1.1401e-01,  1.2249e+00, -6.7363e-01, -7.1594e-01,  1.1192e+00,\\n           3.1508e-02, -9.6329e-01, -9.4242e-01, -6.0421e-01,  3.8831e-01,\\n          -8.0328e-01, -1.8434e-01,  5.9425e-01, -8.3992e-02, -9.7296e-02,\\n          -4.9144e-02, -2.8741e-01,  5.4112e-01,  1.2658e+00, -1.3799e-01,\\n           1.3160e+00,  6.1898e-01,  1.3736e+00, -6.2381e-01, -7.9943e-01,\\n           4.2434e-01,  2.5691e-01,  9.0902e-01,  1.6604e+00, -1.3550e+00,\\n          -7.5331e-01,  7.2825e-03, -1.4393e-01,  1.6297e-01, -6.4880e-01,\\n           6.1995e-01, -2.2866e-01,  2.1626e-01,  6.1974e-01,  5.8782e-01,\\n          -6.2876e-03]],\\n\\n        [[ 3.0392e-01, -4.7925e-01,  7.2142e-01,  1.0682e-01, -2.5098e-01,\\n           1.3644e-01,  6.4795e-01,  4.4410e-01,  9.9867e-02, -8.0278e-01,\\n           5.9076e-02, -4.5677e-01,  2.9510e-01,  5.4165e-01,  4.0386e-01,\\n          -2.3301e-01, -1.0443e-01,  9.9639e-01, -1.9611e-02, -5.5323e-01,\\n          -2.1488e-01, -1.9972e-01, -6.2749e-01,  6.3266e-01, -2.1753e-01,\\n           3.7853e-01, -8.1458e-02, -5.1774e-02, -4.5731e-01,  2.9212e-01,\\n          -1.2782e-01,  2.1239e-01,  3.4673e-01, -1.4092e-01,  4.3036e-01,\\n           7.1894e-01,  4.6626e-01,  7.0923e-01,  6.6435e-01, -1.2940e+00,\\n           1.0575e-01]],\\n\\n        [[ 1.0185e+00,  2.2876e-01,  6.7811e-01, -2.2945e-01,  5.9893e-01,\\n           1.8813e-01,  2.2724e-01,  6.5213e-01, -4.0963e-01, -1.4358e-01,\\n           3.3097e-01,  1.5096e-01,  1.5450e-01,  8.4939e-01,  3.3530e-01,\\n           1.4755e-01,  9.3947e-03,  7.3586e-01,  7.9100e-01, -1.1170e-01,\\n           2.6891e-01,  4.3037e-01, -7.4707e-01,  4.6598e-01,  2.5889e-01,\\n           4.7414e-01,  5.7052e-01, -9.1523e-02, -2.4914e-02, -5.5284e-02,\\n          -4.1708e-01,  1.0252e+00,  4.6635e-01,  3.5538e-01, -1.2562e-01,\\n           6.3504e-01,  6.8586e-01,  2.0397e-01,  7.0503e-01, -6.3935e-01,\\n           2.5279e-01]],\\n\\n        [[ 4.5003e-01, -4.0621e-01,  7.6058e-01,  6.6563e-02, -1.3734e-01,\\n           1.2275e-01,  5.9857e-01,  5.1302e-01,  2.9319e-02, -7.1452e-01,\\n           1.4779e-01, -3.2110e-01,  2.5570e-01,  6.0121e-01,  4.2726e-01,\\n          -1.5078e-01, -7.2143e-02,  9.2080e-01,  7.9421e-02, -4.7545e-01,\\n          -1.8216e-01, -8.5042e-02, -7.0191e-01,  6.0108e-01, -1.0542e-01,\\n           3.7921e-01,  2.7524e-02, -8.2817e-02, -4.4585e-01,  2.7666e-01,\\n          -1.5444e-01,  3.7517e-01,  3.7405e-01, -5.4097e-02,  3.3142e-01,\\n           6.7826e-01,  5.4651e-01,  5.9923e-01,  6.5311e-01, -1.2130e+00,\\n           1.0905e-01]]], grad_fn=<ViewBackward0>)\\nnext_loss=tensor(1.0447, grad_fn=<NllLossBackward0>)\\nmask_loss=tensor(nan, grad_fn=<NllLossBackward0>)\\ntotal_loss=0\\n bert_inputs=tensor([[ 2],\\n        [24],\\n        [21],\\n        [ 8],\\n        [ 9],\\n        [23],\\n        [16],\\n        [ 3],\\n        [40],\\n        [21],\\n        [ 8],\\n        [ 9],\\n        [23],\\n        [16],\\n        [ 3],\\n        [ 1]])\\nbert_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1]])\\nsegment_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [0]])\\nis_nexts=tensor([0])'},\n",
       " {'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (32, 6, 8, 0.1, 'adam', 0.001, 0.2, 1),\n",
       "  'message': 'Error: loss.item()=nan---next_sentence_prediction=tensor([[0.1311, 0.0441]], grad_fn=<AddmmBackward0>)\\nmasked_language=tensor([[[-0.4978, -0.3174, -0.5764,  0.1442, -0.7046, -0.5076,  0.6573,\\n           0.6596, -0.2724, -0.8272,  0.5125,  0.1418,  1.0263,  0.5478,\\n           0.4015,  0.1029,  0.1320,  0.3092, -0.7604, -0.3483, -0.0162,\\n          -0.6548, -0.3619,  0.7513, -0.0262, -0.4467, -0.3057, -0.5490,\\n           0.0858, -0.5493, -0.5318,  0.2342, -0.7019, -0.0969, -0.2529,\\n          -0.5608,  0.3920, -0.8392, -0.5564,  0.2786,  0.4732]],\\n\\n        [[-0.6195, -0.5285, -0.1007, -0.2020, -0.6773, -0.0249,  0.2859,\\n           1.0627, -0.3535, -0.5750, -0.3766, -0.7448,  0.3074,  0.0824,\\n           0.3588, -0.2073,  0.8194,  0.1405, -1.0980,  0.1474, -0.1138,\\n           0.0075, -0.4329,  0.3745,  1.4810, -0.1342, -0.7103, -1.3642,\\n           0.5035, -1.1898,  0.1538,  0.3461, -0.6266, -0.0703,  0.1730,\\n          -0.2030, -0.1628, -0.5574, -0.5591,  0.3897,  0.3866]],\\n\\n        [[-0.7036,  0.0153, -0.4806, -0.4151, -0.7461, -0.3533,  0.4251,\\n           1.0021, -0.5054, -0.3517,  0.8761,  0.3258,  0.5454,  0.3892,\\n          -0.0670, -0.1214, -0.0227, -0.0015, -0.4356, -0.2173,  0.6150,\\n          -0.5460, -0.3224,  1.0902, -0.1068, -0.3181, -0.8096, -0.5549,\\n          -0.0284, -0.7578, -0.4632, -0.3523, -0.6102, -0.7665,  0.1335,\\n          -0.6167,  0.0453, -0.5965, -0.5181,  0.4067,  0.5478]],\\n\\n        [[-0.7457, -0.4437, -0.1914, -0.3053, -0.9211, -0.1800,  0.6913,\\n           0.4656, -0.4349, -0.6153, -0.0560, -0.4513,  0.7173,  0.3870,\\n           0.6544,  0.4151,  0.3665,  0.4903, -1.0830, -0.1521,  0.4357,\\n          -0.0560, -0.0817,  0.5597,  0.5253, -0.1235, -0.1129, -1.1130,\\n           0.4170, -0.8422, -0.0508,  0.2418, -1.0971, -0.2670,  0.1410,\\n          -0.3617, -0.4479, -0.3953, -0.6406,  0.4404,  0.5306]],\\n\\n        [[-0.2009, -0.6010, -0.4523,  0.1673, -0.5996, -0.0597,  0.6763,\\n           0.8192, -0.0850, -0.8654, -0.1702, -0.4396,  0.5328,  0.3035,\\n           0.4230,  0.1439,  0.5469,  0.2254, -1.3999,  0.1518, -0.2516,\\n          -0.4927, -0.3449,  0.1693,  0.7399, -0.3349, -0.2016, -0.8931,\\n           0.2931, -0.8699,  0.1647,  0.4437, -0.6508,  0.1144,  0.1504,\\n          -0.3926, -0.0016, -0.6410, -0.5815,  0.6026,  0.1042]],\\n\\n        [[-0.6248, -0.3506, -0.3025, -0.0466, -0.8072, -0.0825,  0.3455,\\n           0.6011, -0.0889, -0.6371, -0.1384, -0.8569,  0.6095,  0.4351,\\n           0.7668,  0.3887,  0.3642,  0.4024, -1.4264, -0.2416,  0.5115,\\n          -0.0223, -0.6828,  0.2850,  1.1635, -0.1582, -0.5259, -1.0607,\\n           0.1513, -0.7774,  0.1037,  0.6520, -0.9528, -0.1959, -0.1454,\\n          -0.2642, -0.0095, -0.7088, -0.6342,  0.6989,  0.1787]],\\n\\n        [[-0.4492, -0.2636, -0.3889, -0.4360, -0.9900, -0.3699,  0.7016,\\n           0.5224, -0.3285, -0.9232,  0.1942, -0.7866,  0.7461,  0.7221,\\n           0.7809,  0.3031,  0.4267,  0.7741, -0.8092,  0.0137,  0.0548,\\n          -0.1282, -0.4160,  0.3195,  0.5171, -0.2153, -0.2952, -0.8398,\\n           0.0560, -0.6969, -0.1435,  0.1334, -0.8063, -0.2772, -0.2926,\\n          -0.4006,  0.1750, -0.5477, -0.6777,  0.7829,  0.4227]],\\n\\n        [[-0.7980,  0.0528, -0.5998, -0.5290, -0.5960,  0.1458,  0.3329,\\n          -0.1013, -0.7961, -0.2649,  0.0304,  0.1219,  0.4558, -0.0087,\\n          -0.0845,  0.9815, -0.2973,  0.5456, -0.8736, -1.0307,  0.4648,\\n          -0.4656, -0.5797,  0.7473,  0.3489, -0.2985, -0.8044, -0.6250,\\n           0.2452, -0.8696,  0.0563,  0.3294, -0.9487, -0.8029,  0.0078,\\n          -0.4711,  0.1294, -0.3544, -0.7880,  0.7694,  0.3036]],\\n\\n        [[-0.5542, -0.4672,  0.0519, -0.1997, -0.5003,  0.0262,  0.5875,\\n           0.6005, -0.4881, -0.3452, -0.0573, -0.5636,  0.7858, -0.0163,\\n           0.4083,  0.2530, -0.0462,  0.2720, -1.0274, -0.0383,  0.3242,\\n           0.0386, -0.3860,  0.9165,  0.6682,  0.0072, -0.3214, -1.3475,\\n           0.2045, -1.1356, -0.1252,  0.0963, -0.8807, -0.1324, -0.0706,\\n          -0.3379, -0.2915, -0.5192, -0.5744,  0.4601,  0.4001]],\\n\\n        [[-0.6634, -0.3140, -0.5716, -0.1345, -0.5934,  0.1429,  0.2235,\\n           0.4105, -0.2505, -0.4816,  0.0908, -0.5562,  0.5641, -0.0242,\\n           0.3866,  0.3023,  0.1442,  0.4700, -1.4283, -0.2086,  0.3966,\\n          -0.4451, -0.8423,  0.6553,  0.7549, -0.2306, -0.7322, -0.8827,\\n          -0.0895, -0.8019,  0.1688,  0.4399, -1.0303, -0.3065, -0.2313,\\n          -0.3080, -0.0987, -0.5192, -0.8146,  0.9120,  0.3145]],\\n\\n        [[-0.1867, -0.0736, -0.4791, -0.7038, -0.2960,  0.1208,  0.3136,\\n           0.4330, -0.7785, -0.5692,  0.1074, -0.0870,  0.9743, -0.0867,\\n           0.4417,  0.2493,  0.1105,  0.6730, -1.1531, -0.1658,  0.1110,\\n          -0.6743, -0.7391,  0.6302,  0.4300,  0.0560, -0.9408, -0.9651,\\n           0.0948, -0.9629,  0.1082,  0.0039, -0.7765, -0.4700, -0.5271,\\n          -0.8754,  0.3785, -0.6718, -0.6683,  0.9715,  0.2548]],\\n\\n        [[-0.8033, -0.0113, -0.5449, -0.4229, -0.7312, -0.1544,  0.5379,\\n           0.7141, -0.4839, -0.4176,  0.1798,  0.2852,  0.6625, -0.1364,\\n           0.1908,  0.1911,  0.3204,  0.1576, -1.2021, -0.6441,  0.6019,\\n          -0.7119, -0.5916,  0.6125,  0.5104, -0.0458, -1.1493, -0.7584,\\n          -0.0105, -0.7043, -0.0017,  0.2574, -1.1436, -0.6511, -0.0286,\\n          -0.6997, -0.2325, -0.6670, -0.8448,  0.6908,  0.3056]],\\n\\n        [[-0.5850,  0.0496, -0.4795, -0.1879, -0.4498, -0.2047,  0.4786,\\n           0.7613, -0.4020, -0.2483,  0.3317,  0.4465,  0.7838, -0.1348,\\n           0.0176,  0.3392,  0.1286,  0.1206, -1.0013, -0.5575,  0.2808,\\n          -0.7196, -0.7099,  0.6692,  0.1788, -0.1601, -0.7812, -0.8732,\\n          -0.1283, -0.6971,  0.0321,  0.1949, -1.1198, -0.6425, -0.0667,\\n          -0.5141, -0.1481, -0.4385, -0.8268,  0.6035,  0.4150]],\\n\\n        [[-0.4112, -0.1460, -0.3106, -0.3607, -0.4581,  0.1150,  0.3443,\\n           0.7914, -0.5764, -0.4340,  0.2198,  0.0870,  0.9385, -0.3211,\\n          -0.0343,  0.2500,  0.2460,  0.0665, -1.1907, -0.2730,  0.6231,\\n          -0.9519, -0.5749,  0.7055,  0.3073,  0.2716, -0.9413, -0.7349,\\n           0.0781, -1.0779, -0.0678, -0.1531, -1.1735, -0.7437, -0.2143,\\n          -0.5397, -0.2233, -0.5369, -0.7511,  0.8395,  0.2049]]],\\n       grad_fn=<ViewBackward0>)\\nnext_loss=tensor(0.7376, grad_fn=<NllLossBackward0>)\\nmask_loss=tensor(nan, grad_fn=<NllLossBackward0>)\\ntotal_loss=12.926578760147095\\n bert_inputs=tensor([[ 2],\\n        [ 5],\\n        [24],\\n        [21],\\n        [ 5],\\n        [14],\\n        [ 3],\\n        [ 6],\\n        [21],\\n        [14],\\n        [ 3],\\n        [ 1],\\n        [ 1],\\n        [ 1]])\\nbert_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1]])\\nsegment_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [0],\\n        [0],\\n        [0]])\\nis_nexts=tensor([1])'},\n",
       " {'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (8, 6, 8, 0.2, 'sgd', 0.01, 0.4, 32),\n",
       "  'message': \"Error: 'accuracy'\"},\n",
       " {'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (32, 6, 8, 0.3, 'sgd', 0.0001, 0.1, 1),\n",
       "  'message': 'Error: loss.item()=nan---next_sentence_prediction=tensor([[-0.8731,  0.6910]], grad_fn=<AddmmBackward0>)\\nmasked_language=tensor([[[ 4.9214e-01, -4.3837e-02, -1.3495e+00, -4.6924e-01,  4.3491e-01,\\n           4.4218e-01,  4.8570e-01,  7.1297e-01,  1.2205e-01,  8.2952e-01,\\n          -7.3661e-01,  5.1918e-01, -5.0337e-01, -4.7405e-01, -4.5835e-02,\\n           6.9468e-01,  7.8066e-01, -9.7888e-02, -5.1380e-01, -5.3693e-01,\\n          -3.7895e-01, -4.0014e-01,  1.5439e-01, -2.7625e-01, -8.8688e-01,\\n          -2.5702e-01, -1.4982e-02, -2.9888e-01, -7.5908e-01, -6.8823e-01,\\n          -5.0183e-01, -5.6614e-01,  6.2365e-02,  3.8070e-01,  4.8480e-01,\\n           4.3351e-01, -1.7608e-02, -5.5044e-01,  3.7228e-01, -4.4813e-01,\\n           9.3805e-01]],\\n\\n        [[ 2.2046e-01,  2.9152e-01, -7.9577e-01, -7.0391e-01,  3.0978e-01,\\n           6.8208e-01,  3.8415e-01,  3.5337e-01,  4.2574e-01,  9.9195e-01,\\n          -3.8844e-01,  2.3518e-01, -3.6149e-01, -2.4463e-01,  1.5921e-01,\\n           6.2721e-01,  2.8887e-01, -4.6876e-01, -5.3472e-01, -2.4416e-01,\\n          -1.5237e-01,  5.8784e-02,  6.3588e-01, -4.7028e-02, -5.3608e-01,\\n          -2.6414e-01,  4.3432e-01,  1.0694e-01, -7.4417e-01, -8.0407e-01,\\n          -2.7246e-01, -2.4832e-01,  1.1010e-02, -4.4314e-01,  5.7809e-01,\\n           4.2957e-01, -1.5874e-01, -6.7356e-01,  4.3882e-01, -3.4826e-01,\\n           2.7265e-01]],\\n\\n        [[ 2.7792e-01, -3.0018e-01, -1.4747e+00, -8.1879e-02, -1.6740e-01,\\n           1.7562e-02,  1.4387e-01,  2.7901e-01, -1.8383e-02, -3.6334e-01,\\n          -2.5027e-01, -3.1417e-01, -5.5287e-01, -5.1854e-01, -8.0718e-01,\\n           4.5826e-02,  8.2264e-01,  1.2287e-02, -4.5088e-02, -2.1567e-01,\\n          -2.4375e-01, -1.2723e-01, -9.5870e-01,  5.5876e-02, -1.0110e+00,\\n          -8.0113e-01, -4.2288e-02,  2.1356e-01, -1.0710e-01, -9.6908e-01,\\n          -4.6940e-01,  1.2563e-01,  1.2135e-02,  3.3316e-01, -1.1771e-01,\\n           7.7702e-01, -4.4864e-01, -9.1818e-01,  8.8513e-02, -8.5231e-01,\\n           5.3180e-01]],\\n\\n        [[ 3.0126e-01,  1.7700e-01, -9.0349e-01, -6.7594e-01,  3.8183e-01,\\n          -8.5946e-03, -1.6799e-02,  3.1245e-01,  6.2459e-01,  5.0193e-01,\\n          -7.8915e-01,  6.9400e-02, -7.4174e-01, -1.2801e-01, -2.6422e-02,\\n           1.0168e+00,  9.0681e-01, -4.5481e-01, -5.0531e-01, -5.0477e-01,\\n          -2.5755e-01,  6.5649e-01,  7.0441e-02, -4.6813e-01, -6.1198e-01,\\n          -1.5003e-01,  1.4605e-01,  3.2535e-01, -2.7981e-01, -9.3502e-01,\\n          -4.9990e-01, -5.0870e-01,  1.8917e-01, -1.6957e-01,  6.0834e-01,\\n           3.1802e-01,  7.7104e-02, -1.1987e+00,  6.1360e-02, -8.7303e-01,\\n           5.6816e-01]],\\n\\n        [[-3.3837e-03,  2.1727e-01, -7.3909e-01,  2.6649e-01,  1.0538e+00,\\n          -1.2255e-01,  1.7085e-01,  2.4781e-01,  3.6796e-01,  7.3130e-01,\\n          -1.0429e+00,  3.0480e-01, -3.9119e-01, -6.7502e-01,  1.6390e-01,\\n           5.6377e-01,  1.1092e+00, -2.6767e-01, -2.3172e-01, -2.3665e-01,\\n          -4.0793e-01, -1.1518e-02, -3.5537e-01, -3.5484e-01, -7.1985e-01,\\n          -1.4477e-02,  2.8588e-01,  7.3411e-02, -2.2746e-01, -7.9192e-01,\\n          -7.8701e-01, -4.1387e-01,  3.6773e-01,  4.4000e-01, -1.0466e-01,\\n           5.1935e-01, -8.8967e-03, -6.8680e-01,  1.8959e-01, -6.0141e-01,\\n           2.3949e-01]],\\n\\n        [[ 8.8556e-01,  3.2028e-02, -1.9803e-01, -1.5413e-02,  6.2534e-01,\\n           2.4355e-01,  1.2854e-01, -4.5602e-01,  7.8536e-01,  2.6180e-01,\\n          -6.5489e-01, -1.6500e-01,  4.2413e-01, -6.0820e-01, -6.7107e-01,\\n           8.5733e-01,  1.5273e-01, -1.9631e-01, -3.0385e-01,  5.4320e-02,\\n          -2.3438e-01,  6.6440e-01, -6.5720e-02,  8.6337e-03, -4.5791e-01,\\n          -3.1390e-01,  1.2821e-03,  5.6729e-01, -2.1910e-01, -1.1732e+00,\\n          -5.2316e-01, -3.4036e-01, -3.7974e-01,  6.9511e-02,  6.6750e-01,\\n          -1.6626e-01, -2.1264e-01, -6.9132e-01, -1.0522e-01, -4.2732e-01,\\n           7.9853e-02]],\\n\\n        [[ 2.4731e-01,  2.8699e-01, -5.4737e-01, -1.9224e-01,  8.5048e-01,\\n           4.7279e-01,  3.8492e-01,  1.8895e-01,  4.6413e-01, -2.4692e-01,\\n          -9.2835e-01,  3.2585e-01,  1.9359e-01, -2.2114e-01,  1.1734e-01,\\n           8.8724e-01,  5.2669e-01, -6.8152e-01, -5.6345e-02, -1.3768e-01,\\n          -3.7231e-01,  1.4130e-02, -2.3906e-01,  5.8196e-01, -7.3380e-01,\\n          -3.6390e-01,  1.6661e-01,  4.5031e-01, -2.2460e-01, -8.3569e-01,\\n          -9.7802e-01,  2.3574e-01, -2.0879e-01,  3.5169e-01,  1.2091e+00,\\n          -5.7921e-02,  5.3133e-01, -4.9382e-01,  2.8332e-01, -3.4440e-01,\\n           5.8408e-01]],\\n\\n        [[ 5.5607e-02,  9.0895e-03, -1.0314e-01,  1.0054e-02,  1.0981e+00,\\n           2.1405e-01,  8.4982e-02,  1.9171e-01,  4.9698e-01,  5.6521e-01,\\n          -1.0428e+00, -1.0220e-01, -1.2041e-01,  1.7913e-01, -1.5446e-01,\\n          -1.0378e-01,  5.3318e-02,  5.9252e-01,  4.1830e-01, -2.8827e-01,\\n          -2.1792e-01,  3.4508e-01,  5.9766e-02, -1.5521e-01, -3.4674e-01,\\n          -1.8081e-02, -1.3464e-03, -1.6344e-02, -3.2440e-01, -5.3842e-01,\\n          -3.1336e-01, -7.8613e-01, -1.7511e-01,  2.2924e-01,  1.6205e-01,\\n          -7.8736e-02, -2.8046e-01,  3.8973e-02,  5.6365e-01, -3.3243e-02,\\n           6.6421e-01]],\\n\\n        [[-9.9565e-02, -4.3429e-01,  1.6727e-01, -1.5600e-01,  3.7101e-01,\\n          -2.9642e-01, -8.2121e-02, -4.1631e-01,  5.0872e-01,  7.4254e-01,\\n          -1.2649e+00, -1.8126e-01, -6.6000e-01,  4.6306e-01, -3.9590e-01,\\n           5.6817e-01,  6.8607e-01,  4.4823e-02, -1.4532e-01, -3.9494e-01,\\n          -1.7710e-01,  1.1593e+00,  6.4969e-01, -9.4431e-01, -1.5056e-02,\\n           2.3106e-01, -2.3171e-01,  6.0553e-01, -6.0622e-01, -6.0971e-01,\\n          -7.1204e-01, -4.8189e-01,  3.0710e-01, -2.9726e-01,  2.1612e-01,\\n           6.6874e-01, -3.3430e-02, -8.1768e-01, -3.9589e-01, -8.3771e-01,\\n          -1.9747e-01]],\\n\\n        [[-9.7561e-02,  4.6524e-01, -6.5405e-01,  1.4756e-01,  3.5037e-01,\\n           9.4709e-01,  1.6713e-01,  2.2377e-01,  2.5516e-01,  8.7862e-01,\\n           1.9510e-01, -4.4862e-01,  4.7936e-01, -1.0429e+00, -3.4867e-01,\\n           2.2055e-01,  2.9822e-01, -4.1767e-01, -2.2255e-01, -6.6828e-01,\\n          -1.1330e-01, -1.4206e-01, -9.9214e-02,  8.4043e-02, -8.6091e-01,\\n          -1.1953e-01,  9.7752e-01,  7.9519e-01, -3.6055e-01, -1.0429e+00,\\n          -5.3428e-01,  4.7912e-01,  6.1993e-02, -4.1703e-01,  3.3515e-01,\\n           3.2668e-02, -2.6122e-01, -9.0144e-01,  5.6347e-02, -4.7307e-01,\\n           3.5344e-01]],\\n\\n        [[ 2.3927e-01,  3.4092e-01, -6.9088e-01, -5.5529e-01,  3.1081e-01,\\n           3.3540e-01,  7.9978e-01,  1.6872e-01,  2.8290e-01,  6.5386e-01,\\n          -4.8196e-01,  1.1861e-01, -4.9720e-01, -6.8102e-01,  2.8305e-01,\\n           9.5663e-01,  8.0152e-01, -3.6771e-01, -8.0313e-01, -3.4446e-01,\\n          -1.2019e-01,  4.1489e-02,  2.1486e-01, -2.6738e-01, -3.6730e-01,\\n           4.6469e-02,  3.9108e-02,  5.4644e-01, -5.9239e-01, -1.0438e+00,\\n          -1.1450e+00, -6.1940e-01,  1.3138e-01,  1.9611e-01,  7.1988e-01,\\n           1.1908e-01, -1.5498e-01, -8.7860e-01,  4.8472e-01, -5.9149e-01,\\n          -4.4508e-02]],\\n\\n        [[ 1.1447e-01,  2.0419e-02, -1.1274e+00,  3.5955e-01,  6.1503e-01,\\n          -1.7457e-01,  2.4974e-02,  5.7741e-01, -6.7221e-04,  3.1915e-01,\\n          -8.0717e-01,  9.7785e-04, -6.5752e-01, -4.3545e-01, -6.4104e-01,\\n           5.1406e-01,  6.8011e-01, -6.9846e-02,  3.3888e-01, -4.4991e-01,\\n          -3.4428e-01,  3.3264e-01, -8.4933e-01,  3.1350e-01, -9.2513e-01,\\n          -2.1342e-01,  2.7096e-01, -2.4034e-02, -2.8574e-01, -3.4756e-01,\\n          -4.9471e-01, -1.6829e-01,  3.2179e-01,  6.0808e-01,  2.1339e-01,\\n           3.5247e-01,  6.5765e-01, -5.4425e-01,  2.1284e-01, -5.3170e-01,\\n           7.3936e-01]],\\n\\n        [[ 2.5835e-01,  6.6018e-02, -8.3244e-01, -1.8580e-01,  6.5868e-01,\\n           6.1634e-01,  6.8741e-01,  3.0875e-01,  4.1109e-01,  1.7275e-01,\\n          -5.2314e-01,  6.0838e-02, -2.9233e-01, -5.3721e-01, -3.8594e-01,\\n           2.5584e-01,  5.6020e-01, -3.9258e-01, -6.8475e-02, -4.6159e-02,\\n          -1.8679e-01, -3.5210e-01, -6.9672e-01, -7.5426e-02, -8.4257e-01,\\n          -5.4187e-01,  4.6847e-02, -3.0026e-01, -6.2955e-01, -9.7693e-01,\\n          -8.0709e-01, -3.2663e-01, -3.1659e-01,  2.0288e-01,  1.8815e-01,\\n           1.9973e-01, -3.3744e-01, -7.5882e-01,  4.3231e-01, -7.9935e-01,\\n           7.6873e-01]],\\n\\n        [[ 1.4280e-01,  3.9643e-01, -7.0416e-01, -8.2490e-02,  2.7473e-01,\\n           3.2695e-01,  3.4541e-01,  1.8835e-01,  1.7480e-01,  9.5015e-01,\\n          -1.3552e-01, -1.9167e-01,  8.3827e-02, -1.0250e+00, -5.1243e-02,\\n           7.2713e-01,  6.7205e-01, -3.1734e-02, -4.8135e-01, -5.8557e-01,\\n          -2.0399e-01,  1.3429e-01, -1.1232e-01, -7.4506e-02, -7.1634e-01,\\n           4.1862e-02,  3.8972e-01,  8.5218e-01, -3.7321e-01, -1.1466e+00,\\n          -6.2179e-01, -2.1627e-01,  4.3937e-01,  3.7812e-01,  3.6668e-01,\\n           3.9596e-02,  4.0209e-02, -7.2032e-01,  3.3336e-01, -4.3987e-01,\\n           9.0351e-02]],\\n\\n        [[ 4.3063e-01,  3.1229e-01, -3.0298e-01, -3.5380e-01,  7.1267e-01,\\n           7.0970e-01,  4.2374e-01, -3.1382e-01,  6.0624e-01,  1.2460e-01,\\n          -8.9895e-01,  4.0373e-01,  7.2564e-02, -3.4198e-02, -3.7457e-01,\\n           7.6052e-01,  4.3899e-01, -9.2097e-01, -7.8747e-01, -4.4547e-01,\\n          -4.2780e-01, -7.6672e-02,  1.6878e-01, -6.2535e-03, -7.2183e-01,\\n          -4.2141e-01, -6.1422e-03,  1.6010e-01, -8.1163e-01, -1.0670e+00,\\n          -4.3260e-01, -2.0582e-01, -6.4090e-01,  1.1836e-01,  9.5080e-01,\\n           1.3917e-01, -6.0368e-01, -5.0601e-01, -5.4636e-02, -5.8113e-01,\\n           7.8333e-01]],\\n\\n        [[ 1.8695e-01,  9.5733e-01, -2.0029e-01, -3.3096e-01,  8.6602e-01,\\n           3.1515e-01, -1.9445e-01, -6.4736e-02,  5.9009e-01,  1.1802e+00,\\n          -6.9087e-01,  5.8427e-01, -3.8437e-01, -6.1091e-01,  1.7456e-01,\\n           1.1551e-01,  7.6477e-01, -3.7273e-01, -4.3224e-01, -3.6184e-01,\\n          -1.1869e-01,  4.5415e-01,  3.0507e-01, -4.2726e-01,  1.0988e-01,\\n           4.2772e-01,  8.1401e-01,  1.3282e-01, -7.0164e-02, -9.3447e-01,\\n          -2.6002e-01, -5.8514e-01,  6.1552e-01,  1.0344e-01,  1.4585e-01,\\n           5.7130e-01, -3.7793e-01, -9.0224e-01,  5.4769e-01, -1.3094e-01,\\n          -3.5550e-01]]], grad_fn=<ViewBackward0>)\\nnext_loss=tensor(1.7541, grad_fn=<NllLossBackward0>)\\nmask_loss=tensor(nan, grad_fn=<NllLossBackward0>)\\ntotal_loss=151.8860569000244\\n bert_inputs=tensor([[ 2],\\n        [ 6],\\n        [18],\\n        [10],\\n        [14],\\n        [22],\\n        [ 9],\\n        [ 3],\\n        [24],\\n        [18],\\n        [10],\\n        [14],\\n        [22],\\n        [ 9],\\n        [ 3],\\n        [ 1]])\\nbert_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1]])\\nsegment_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [0]])\\nis_nexts=tensor([0])'},\n",
       " {'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (8, 6, 4, 0.1, 'sgd', 1e-05, 0.3, 64),\n",
       "  'message': \"Error: 'accuracy'\"},\n",
       " {'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (32, 10, 2, 0.4, 'adam', 0.0001, 0.1, 1),\n",
       "  'message': 'Error: loss.item()=nan---next_sentence_prediction=tensor([[0.4481, 0.3568]], grad_fn=<AddmmBackward0>)\\nmasked_language=tensor([[[-1.0742,  0.5196, -0.1447,  1.3976,  0.7485,  0.1669, -0.8200,\\n           0.3782,  0.5069, -0.0562, -0.7225, -0.2648, -0.6292, -0.2222,\\n           0.3336,  0.0433,  0.8936, -0.8733,  0.4381, -0.8028, -0.7604,\\n          -0.3218, -0.6087, -0.3891,  0.6460, -0.2151,  0.5193, -0.8410,\\n           0.6645, -0.0722, -0.2053, -0.6735, -0.9349, -0.6257, -0.1494,\\n          -0.2907, -0.2708, -0.0950,  0.2535,  0.5919,  0.6029]],\\n\\n        [[ 0.4435,  0.5582,  0.0361,  0.4820,  0.2849,  0.4961,  0.2661,\\n           0.3450,  0.9183,  0.1956,  0.5198,  0.6798, -1.4251,  0.3124,\\n           0.2900, -0.4186,  0.2697, -1.2430,  0.2404, -0.6427, -0.9256,\\n           0.4696, -0.2513, -0.2762, -0.1447,  0.0037,  0.3325, -0.2774,\\n           0.3544, -0.0125,  0.1082, -0.1112, -1.4229,  0.5899,  0.1256,\\n          -0.3124, -1.2952, -0.5927,  0.5859,  0.3889,  0.3591]],\\n\\n        [[ 0.2097,  0.7559,  0.4169,  0.5933,  0.0182,  0.7346, -0.0753,\\n           0.7974,  0.5526, -0.2924, -0.5028, -0.2216, -0.7043, -0.0990,\\n          -0.0722, -0.0770,  0.5845, -0.8348,  0.6113, -0.8763, -1.0386,\\n          -0.0196, -0.0076, -0.1952,  0.3641, -0.5303,  0.7568, -0.5377,\\n           0.1128, -0.1936, -0.3298, -0.6168, -1.0618,  0.0937,  0.4220,\\n          -1.0714, -0.6905, -0.0998,  0.6355,  0.5231,  1.1494]],\\n\\n        [[ 0.0648,  0.9244,  0.6969,  0.3795, -0.3453,  0.2258,  0.5091,\\n           0.6082,  0.7902, -0.0253, -0.4245, -0.0837, -1.4079,  0.2099,\\n          -0.2293,  0.1836,  0.0753, -1.3668,  0.6619, -0.3850, -0.7101,\\n           0.3042, -0.4172, -0.0811,  0.2612,  0.0071,  1.0011,  0.0217,\\n           0.2604,  0.2156,  0.0124, -0.6885, -1.5501,  0.3415,  0.4592,\\n          -0.5581, -1.1454, -0.5255,  0.9180,  0.5511,  0.9590]],\\n\\n        [[ 0.0643,  0.3254, -0.0751,  0.4100, -0.1888,  0.3460,  0.5614,\\n           0.4688,  0.3627, -0.0227,  0.3930,  0.3765, -1.0713,  0.9155,\\n           0.0907, -0.3957,  0.1851, -0.9689,  0.3329, -0.7135, -1.1600,\\n           0.5141, -0.1444,  0.0727, -0.7654,  0.0571,  0.9417, -0.3862,\\n           0.7988, -0.5491, -0.2635, -0.2105, -1.3454,  0.4642,  0.2268,\\n          -0.4158, -1.3210, -0.9074,  0.7466, -0.0604,  0.1990]],\\n\\n        [[ 0.0901,  0.3855,  0.3070,  0.0518, -0.1092,  0.5196,  0.2677,\\n           0.5324,  0.5975,  0.3538,  0.1836,  0.6545, -1.4930,  0.5175,\\n          -0.1834, -0.5449,  0.1786, -1.0470,  0.6002, -0.4445, -0.6911,\\n           0.5031, -0.3120, -0.0276, -0.3943, -0.4043,  0.9041, -0.4833,\\n           0.3997, -0.2956,  0.1056, -0.4905, -1.3373,  0.6560,  0.6127,\\n           0.0724, -1.1518, -0.9010,  0.9230,  0.4414,  0.5855]],\\n\\n        [[-0.0505,  0.8147,  0.3050,  0.4620, -0.1503,  0.1373, -0.0187,\\n           0.6021,  0.6890,  0.4070,  0.1046,  0.5490, -1.2355,  0.1941,\\n          -0.1812, -0.3236,  0.7793, -1.3852,  0.0250, -0.3123, -0.9803,\\n           0.6015, -0.3831,  0.0109,  0.0694,  0.1910,  1.2640, -0.1643,\\n          -0.1953, -0.1332,  0.2526, -0.6162, -1.1623,  0.7801,  0.5038,\\n          -0.4512, -1.1713, -0.8431,  0.6320, -0.2384, -0.1262]],\\n\\n        [[ 0.7563, -0.1407,  0.1950, -0.1233, -0.3909,  0.4870,  0.7836,\\n           0.6816,  0.6705, -0.4894,  0.0824,  0.5712, -0.9508,  0.5200,\\n           0.2735,  0.0729,  0.3589, -0.9576,  0.3820, -0.9582, -1.0240,\\n           0.2542,  0.3566, -0.4163,  0.0542, -0.3279,  0.6008, -0.8775,\\n           0.7200, -0.4615, -0.4234, -0.5646, -1.1420,  0.1888,  0.5244,\\n          -0.5474, -0.9321,  0.0287,  0.6704,  0.6937,  1.0301]],\\n\\n        [[-0.0737,  0.7628,  0.4392,  0.1767, -0.2740, -0.2216, -0.0572,\\n           0.2621,  1.1979, -0.0294, -0.0211,  0.8111, -1.6696,  0.1212,\\n          -0.8955, -0.2207,  0.2719, -1.4956,  0.3269, -0.4139, -0.0385,\\n           0.0629, -0.4714, -0.0038,  0.2875,  0.1811,  0.9679, -0.0331,\\n           0.2441,  0.4230, -0.0653, -0.5741, -1.1803,  0.5721,  0.4169,\\n          -0.1436, -0.7313, -0.6020,  0.0283, -0.1279,  0.5397]],\\n\\n        [[-0.4696,  0.8387,  0.8412,  0.4598,  0.4408,  0.7305,  0.0941,\\n           0.4964,  1.2780, -0.2498, -0.0708,  0.1612, -1.2263, -0.0033,\\n          -0.7460,  0.5605, -0.0715, -1.5274,  0.3224, -0.3599, -0.4208,\\n          -0.0412,  0.0441,  0.1264,  0.3517, -0.0131,  0.6257, -0.3518,\\n          -0.1062,  0.5345,  0.1952, -0.9772, -1.4756,  0.8112,  0.2875,\\n          -0.2048, -1.1556,  0.2440,  0.4948,  0.1376,  0.7321]],\\n\\n        [[-0.3058,  0.3408,  0.0452,  0.0132, -0.0700,  0.2645,  0.2562,\\n           0.7671,  0.0776, -0.0796, -0.4892,  0.1940, -1.4775,  0.9019,\\n           0.2048, -0.1687,  0.6182, -0.6692,  0.8525, -0.1703, -0.4783,\\n           0.5428, -0.2463, -0.0213, -0.7120, -0.6475,  0.2021, -0.7290,\\n           0.4761, -0.0380, -0.1765, -0.1121, -1.2103,  0.7378,  0.7376,\\n          -0.2929, -0.7928, -0.3354,  0.2067,  0.8928,  0.4180]],\\n\\n        [[ 0.0390,  0.1588, -0.2781, -0.4036, -0.6461, -0.0462,  0.0293,\\n           0.2952,  0.2260, -0.5529, -0.1298,  0.4023, -1.0405,  0.6025,\\n          -0.8132, -0.7450,  0.5365, -0.6980,  0.8331, -0.3815, -0.2711,\\n           0.4613, -0.4331, -0.1349, -0.7934, -0.1202,  1.1456, -0.2506,\\n           0.4359, -0.4552, -0.2425, -0.2803, -0.3554,  0.8167,  1.1192,\\n          -0.3783, -0.6112, -1.1492,  0.2531, -0.0980,  0.5420]],\\n\\n        [[-0.1103,  0.3018,  0.0765,  0.5173, -0.1439,  0.3474,  0.3077,\\n           0.2981,  0.1957, -0.2022, -0.0558, -0.0408, -0.8603, -0.0075,\\n          -0.3894, -0.0507,  0.6325, -0.9788,  0.5353, -0.6579, -0.9290,\\n           0.5560, -0.3643, -0.3905, -0.5208, -0.0461,  0.8096, -0.2843,\\n           0.2232, -0.3604, -0.0276, -0.5153, -0.8971,  0.4241,  0.5013,\\n          -0.3506, -1.1698, -0.6590,  0.8041,  0.0559,  0.9148]],\\n\\n        [[ 0.0867,  0.5324,  0.5988,  0.2178, -0.4183,  0.5854,  0.3828,\\n           1.1189,  0.8451,  0.0206, -0.4258,  0.2156, -1.1209,  0.3940,\\n           0.1602,  0.1482,  0.6133, -1.2183,  0.6901, -0.6666, -0.7772,\\n           0.2421, -0.1107,  0.1797,  0.4915, -0.7092,  0.6160, -0.8990,\\n           0.7140, -0.0954, -0.4515, -0.6870, -1.1407,  0.1043,  0.2578,\\n          -0.7538, -0.4419, -0.2638,  0.0818,  0.6954,  1.1268]],\\n\\n        [[-0.3320,  0.3137,  0.4546, -0.0060, -0.1263, -0.1438, -0.3364,\\n           0.6610,  1.2508,  0.3794, -0.3697,  0.7928, -1.4125,  0.3989,\\n          -0.2887,  0.1570,  0.5891, -1.2720,  0.6491, -0.5662, -0.5044,\\n           0.5576, -0.5709, -0.1812,  0.3346, -0.1315,  0.4445, -0.6347,\\n           0.1068,  0.1080, -0.1258, -0.7244, -1.3942,  0.3847,  0.2579,\\n          -0.0574, -0.5430, -0.5542,  0.2463,  0.3108,  0.5822]],\\n\\n        [[ 0.4742,  0.4557,  0.3606,  0.5218, -0.1592,  0.6480,  0.4459,\\n           1.1230,  0.7519,  0.1402, -0.0802, -0.0747, -1.2827,  0.5948,\\n           0.3042, -0.2745,  0.7163, -0.9951,  0.5365, -0.6801, -1.2151,\\n           0.3800, -0.2517,  0.0180, -0.1302, -0.3623, -0.2078, -0.4654,\\n           0.3793, -0.3219, -0.0276, -0.2944, -1.2142,  0.6530,  0.0177,\\n          -0.4379, -0.6932, -0.4051,  0.0740,  0.8550,  0.7258]]],\\n       grad_fn=<ViewBackward0>)\\nnext_loss=tensor(0.6485, grad_fn=<NllLossBackward0>)\\nmask_loss=tensor(nan, grad_fn=<NllLossBackward0>)\\ntotal_loss=252.04664540290833\\n bert_inputs=tensor([[ 2],\\n        [ 6],\\n        [21],\\n        [12],\\n        [16],\\n        [23],\\n        [14],\\n        [ 3],\\n        [24],\\n        [21],\\n        [12],\\n        [16],\\n        [23],\\n        [14],\\n        [ 3],\\n        [ 1]])\\nbert_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1]])\\nsegment_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [0]])\\nis_nexts=tensor([0])'},\n",
       " {'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (32, 10, 2, 0.4, 'adam', 0.0001, 0.1, 1),\n",
       "  'message': 'Error: loss.item()=nan---next_sentence_prediction=tensor([[0.1567, 0.4767]], grad_fn=<AddmmBackward0>)\\nmasked_language=tensor([[[-7.5359e-02, -2.5709e-01,  7.1122e-03, -1.0329e-02,  6.0017e-01,\\n           3.8143e-01, -3.3286e-01,  7.3484e-01,  5.3759e-01,  1.1806e+00,\\n          -1.9132e-01, -3.6444e-01,  2.3935e-01,  9.0606e-01,  2.8028e-01,\\n           6.5761e-01, -4.9913e-01,  1.6437e-01,  3.2560e-01,  5.7275e-01,\\n          -5.4260e-01, -1.1331e+00,  9.0116e-02, -3.1134e-01, -2.3211e-01,\\n          -2.7427e-01, -3.9817e-01,  1.6222e-01, -1.2516e+00,  1.1640e+00,\\n           4.8634e-04, -4.4370e-01,  1.6797e-01, -4.6898e-01,  7.2326e-01,\\n          -2.5727e-03,  3.2979e-01, -9.7640e-01,  1.0014e-01, -5.5037e-02,\\n          -3.3373e-01]],\\n\\n        [[ 1.4905e-01,  2.5236e-01, -2.0782e-01,  8.4933e-01,  8.5752e-02,\\n           6.5259e-01,  1.8806e-02, -4.9180e-02, -1.7259e-01,  4.0561e-01,\\n          -7.5185e-01, -3.1291e-01,  5.4973e-01,  1.4261e+00,  7.3339e-01,\\n           1.2604e+00, -2.6563e-01, -2.7982e-01,  1.5739e-01,  1.2243e-01,\\n           9.1390e-02, -1.4328e-01,  7.2209e-01, -6.0960e-01, -3.7804e-01,\\n          -1.6384e-01, -6.4740e-01, -6.8289e-01, -2.6466e-01,  1.1280e+00,\\n           4.5693e-01, -5.0841e-01, -2.7861e-01,  3.1972e-01,  1.3661e+00,\\n           3.2981e-02, -4.8329e-02, -6.6940e-01, -3.9479e-02, -3.6844e-01,\\n          -3.6452e-01]],\\n\\n        [[-1.4082e-01, -1.3628e-01, -2.9891e-01, -4.0928e-02,  8.2343e-01,\\n           5.7942e-01,  1.1649e-01,  4.1253e-01,  1.3069e-01,  9.1964e-01,\\n           6.3725e-02, -5.0703e-01, -5.1916e-01,  4.9367e-01,  3.7403e-01,\\n           5.9944e-01, -4.1803e-01,  6.7663e-01,  4.5347e-01,  8.3338e-01,\\n          -3.4628e-01, -1.0979e+00, -8.3152e-02,  1.2866e-01, -8.8453e-01,\\n           4.8398e-02,  1.9366e-02,  3.4068e-01, -8.8386e-01,  9.8316e-01,\\n           2.3247e-01, -5.0375e-01,  3.1655e-01, -3.3908e-01,  6.6379e-01,\\n          -9.5238e-02,  6.2919e-01, -3.9763e-01, -6.7271e-03,  3.2381e-01,\\n          -1.4599e-01]],\\n\\n        [[-5.4806e-01,  9.8398e-01, -1.3540e-01,  7.7432e-02, -5.8351e-01,\\n           1.1216e+00,  1.9810e-01, -2.0149e-01,  3.3244e-01,  6.6991e-01,\\n          -2.6945e-01,  1.6221e-01, -7.5317e-01,  5.5389e-01,  7.5781e-01,\\n           1.6827e+00, -1.0997e+00,  4.3032e-01,  4.4258e-01, -1.2166e+00,\\n           1.0170e+00, -2.5314e-01,  1.3133e-01, -1.1422e+00, -3.8891e-01,\\n           4.0276e-01, -1.9147e-01, -3.0587e-01, -6.4773e-01,  2.2567e-01,\\n           2.8866e-02, -6.9681e-01, -8.2124e-01, -6.1827e-01,  5.8397e-01,\\n           7.0043e-01,  2.3213e-02, -4.3687e-01,  4.2459e-01, -8.6213e-01,\\n          -1.1765e+00]],\\n\\n        [[ 1.0204e-01,  1.8070e-01, -1.6793e-01, -2.9762e-02, -5.3158e-01,\\n           7.0566e-01,  2.6839e-01,  3.0602e-01,  4.8965e-01,  1.3568e+00,\\n           9.7991e-02,  4.1683e-01, -3.1349e-01,  3.9317e-01,  2.0905e-01,\\n           9.6094e-01,  1.9058e-01,  1.5696e-01,  8.0372e-02, -4.4779e-03,\\n           1.0591e+00, -1.9971e-01, -5.0287e-01, -1.7386e-01, -1.9183e-01,\\n          -5.9735e-01,  1.3930e-01, -5.7821e-01, -8.7579e-01,  9.6529e-01,\\n           2.8811e-01,  8.3833e-02, -4.7115e-01,  2.9413e-02,  1.1247e+00,\\n          -1.6239e-01,  9.1873e-04, -8.0062e-01, -4.6086e-02, -3.5359e-01,\\n          -1.3303e+00]],\\n\\n        [[-1.9248e-01, -6.6039e-01, -1.0322e-01, -6.9612e-01,  5.8641e-01,\\n           1.3782e+00,  6.5347e-02, -3.2913e-01,  5.0369e-01,  7.9371e-01,\\n           3.6715e-01, -4.8209e-01, -5.2709e-01, -2.5099e-01,  3.1052e-01,\\n          -2.7015e-03, -8.7238e-01,  1.4365e+00,  1.3016e-01,  2.9612e-01,\\n          -1.2608e-01, -5.7876e-01, -3.2107e-02,  4.0885e-01, -5.5368e-01,\\n           1.8907e-01,  1.4469e-01,  8.2294e-01, -1.4966e+00,  3.0177e-01,\\n          -1.7778e-01, -3.4443e-01,  6.6757e-01, -4.6816e-02,  9.7292e-02,\\n          -2.0008e-01,  7.8533e-01, -9.2942e-01, -2.5989e-01, -7.6732e-02,\\n          -4.7235e-01]],\\n\\n        [[ 1.7579e-01, -7.1447e-01, -5.3314e-01, -2.9648e-01,  2.8026e-01,\\n           1.8181e+00,  1.4851e-01,  6.4801e-01,  5.0590e-01,  4.2946e-01,\\n           2.4275e-01, -6.7309e-01, -1.7445e-01, -2.4605e-01,  1.3889e-01,\\n           4.8100e-01, -3.1625e-01,  1.2581e+00,  7.8886e-02,  7.5337e-01,\\n           5.3562e-02, -4.4674e-01, -1.4998e-01, -5.8429e-02, -1.0185e+00,\\n           4.9788e-02,  2.0335e-01,  5.0648e-01, -1.1966e+00,  5.8439e-01,\\n          -5.9160e-01, -2.3787e-01,  3.9401e-01, -6.7919e-01, -2.9637e-01,\\n          -2.1829e-02,  9.3474e-01, -4.4899e-02,  1.4231e-01,  5.7999e-01,\\n          -1.1526e+00]],\\n\\n        [[-1.9740e-02, -2.7130e-01, -4.7853e-02,  1.1269e-01, -4.0314e-02,\\n           1.2013e+00, -3.1235e-01,  5.5993e-01,  8.8388e-01,  7.9406e-01,\\n           3.2115e-02,  3.9221e-01, -1.8837e-01,  4.4084e-01,  3.8913e-01,\\n           4.6056e-01, -6.1974e-01,  2.3558e-01,  7.8369e-01,  6.2000e-01,\\n          -1.5692e-01, -9.9517e-01,  1.7596e-01,  6.8479e-01, -3.5890e-01,\\n          -7.3273e-01,  1.5127e-02,  4.5828e-01, -1.1117e+00,  7.0079e-01,\\n           5.4200e-01,  9.5768e-02, -4.7527e-01, -3.3786e-01, -2.2734e-01,\\n           5.1938e-01, -1.2699e-01, -3.5300e-01, -8.3028e-02, -1.8761e-01,\\n          -2.1226e-01]],\\n\\n        [[-3.3762e-01,  1.2187e-01, -4.4586e-01,  1.3724e-01,  3.4719e-01,\\n           1.4122e+00,  1.3776e-01, -6.6216e-02,  9.0900e-02,  7.2348e-01,\\n          -2.3432e-01, -3.6988e-02, -3.4940e-01,  2.5655e-01,  2.4803e-02,\\n           9.8125e-01, -1.3508e+00,  7.0188e-01,  7.8505e-02, -6.3611e-01,\\n           5.9970e-01, -8.0006e-01,  4.4610e-01, -4.0939e-01, -9.1084e-01,\\n           3.2691e-01, -1.0413e+00, -2.4829e-01, -1.0584e+00,  3.1206e-01,\\n           1.7829e-01, -7.3772e-01, -3.1092e-01, -7.0247e-01, -1.9758e-01,\\n           3.4119e-01,  3.7080e-01, -3.8059e-01,  1.2020e-01,  4.1815e-02,\\n          -8.5717e-01]],\\n\\n        [[ 3.3667e-02, -6.4889e-01,  1.7453e-01, -1.5446e-01,  7.8027e-01,\\n           1.5914e+00,  4.5093e-01,  2.0854e-01, -5.8563e-01,  2.8717e-01,\\n          -4.3562e-01, -3.2432e-01, -1.1218e-01, -3.9381e-01,  3.7522e-01,\\n           5.0449e-01, -3.9999e-01,  1.4933e+00, -1.5490e-01,  5.0262e-01,\\n          -4.3046e-01, -7.3996e-01,  3.2294e-01,  1.8764e-01, -1.0715e+00,\\n           2.9763e-01, -2.0804e-01,  4.7540e-01, -1.0346e+00,  6.8931e-01,\\n           6.0289e-02, -1.1392e-01,  4.8008e-01, -2.8344e-01, -1.2021e-01,\\n          -3.6287e-01,  1.0036e+00, -7.5835e-01,  4.9801e-01,  4.5049e-01,\\n          -7.5027e-01]],\\n\\n        [[-1.3075e-01,  8.7994e-01, -1.6683e-01,  1.5776e-01, -1.5562e-02,\\n           1.0219e+00,  6.3893e-02,  6.5325e-01,  5.8342e-01,  9.7113e-01,\\n           6.0181e-02,  2.9051e-01, -4.4676e-01,  9.9070e-02,  7.0502e-02,\\n           9.0707e-01, -1.4337e+00,  1.3031e+00, -3.2724e-01, -7.3566e-02,\\n           5.8713e-01,  2.3454e-01,  4.4065e-01, -2.8466e-01, -1.1663e+00,\\n           8.2886e-02, -4.2388e-02,  9.0402e-02, -1.7830e-01,  5.8090e-01,\\n           2.4722e-01, -4.3948e-01, -6.7810e-01, -1.1872e+00, -1.7815e-01,\\n           2.0908e-01,  2.7836e-01,  5.7752e-01, -1.6943e-01, -4.4537e-01,\\n          -1.0169e+00]],\\n\\n        [[-6.3090e-01,  6.4337e-01, -4.4125e-01, -1.7749e-02, -9.8697e-01,\\n           5.0829e-01, -1.0055e-01, -9.8866e-02,  1.0391e+00,  1.1164e+00,\\n          -3.1101e-01,  1.1488e-01, -5.6773e-01,  3.0594e-01,  6.2342e-01,\\n           1.2415e+00, -1.3056e+00, -3.0370e-01,  6.5574e-01, -9.9620e-01,\\n           1.0506e+00, -5.2388e-01,  1.9770e-01, -1.0106e-01, -5.4761e-01,\\n          -6.6935e-01,  6.9304e-01,  1.9952e-01, -8.4256e-01,  1.2152e-01,\\n           2.1429e-01, -1.4300e-01, -8.1282e-01, -1.3092e+00, -1.2299e-01,\\n           6.0932e-01, -5.4673e-01, -1.4650e-01, -9.9558e-02, -1.6495e+00,\\n          -1.4388e+00]],\\n\\n        [[ 6.1580e-02,  2.7298e-01, -4.8727e-01,  4.3055e-03,  2.7982e-01,\\n           5.3965e-01, -2.9747e-03,  7.8386e-01,  4.8776e-01,  1.2986e+00,\\n           2.5264e-01,  3.9371e-01, -3.8069e-01,  3.6542e-01, -2.4457e-01,\\n           9.9142e-01, -5.7565e-01,  4.9062e-01,  4.5116e-01,  5.3489e-01,\\n          -2.7260e-01, -9.7150e-01,  3.9697e-01, -1.6544e-01, -1.7666e-01,\\n           2.5531e-01, -1.1492e+00, -1.1901e-01, -2.0004e-01,  5.1426e-01,\\n           7.7426e-01,  3.2914e-02, -3.4239e-01, -2.3834e-02,  3.7402e-01,\\n           7.2786e-01, -1.9708e-01, -1.0330e+00, -1.4175e-01, -2.8168e-01,\\n           1.9362e-01]],\\n\\n        [[ 3.2474e-01, -3.3353e-01,  3.2173e-01,  3.0983e-01,  3.8148e-01,\\n           5.7036e-01, -6.9424e-02,  1.3797e-01,  2.0476e-01,  9.2082e-01,\\n          -6.4550e-01, -9.6774e-01,  3.9776e-01,  9.0481e-01,  8.1189e-01,\\n           4.1496e-01, -3.9556e-01,  7.2853e-01, -3.5652e-01,  4.4017e-01,\\n           1.2557e-01, -3.4091e-01, -1.5560e-02, -4.6013e-01, -4.9457e-01,\\n          -5.4021e-02, -5.8988e-01,  5.3100e-01, -8.9531e-01,  7.1164e-01,\\n          -1.7928e-02, -1.0075e+00, -7.0688e-02, -9.6377e-01,  7.6342e-01,\\n          -5.9777e-01,  5.4576e-01, -6.5353e-01, -1.3081e-02,  8.4761e-01,\\n          -3.5528e-01]],\\n\\n        [[ 4.6896e-01, -2.1258e-01,  4.0839e-01, -3.7776e-01,  4.1750e-01,\\n           1.0203e+00, -3.2065e-02, -6.9854e-02,  4.9544e-01,  5.5528e-01,\\n          -5.1350e-01, -3.2688e-01,  7.2819e-02,  3.3259e-01,  5.5625e-01,\\n           5.5903e-01, -8.9481e-01,  1.1083e+00, -6.2923e-01,  6.5171e-01,\\n           2.1512e-01, -4.4360e-01,  3.6267e-01,  2.2794e-01, -7.3473e-01,\\n          -4.4097e-01,  6.7375e-02,  1.1875e-01, -1.1911e+00,  6.2190e-01,\\n          -5.0296e-01, -6.1862e-01,  2.9540e-01, -5.9391e-01,  5.8167e-01,\\n          -2.6986e-01,  9.1171e-01, -3.2234e-01, -1.9823e-01, -2.8068e-02,\\n          -1.1765e+00]],\\n\\n        [[-3.4082e-01,  5.6594e-01, -1.2435e-01, -3.1517e-01, -1.5885e-01,\\n           1.0378e-02, -4.7950e-02,  4.3871e-01,  2.8514e-01,  1.2547e+00,\\n           7.1358e-01,  1.1947e+00, -4.3134e-01,  3.9725e-01, -2.1368e-01,\\n           3.2990e-01, -9.7292e-01,  1.9152e-01, -5.0613e-01,  1.1844e-01,\\n           5.9372e-01, -1.0557e+00,  5.0563e-02, -2.3788e-01,  3.6958e-01,\\n          -1.0343e+00, -1.2578e-01,  8.8337e-02, -5.6542e-01,  6.7194e-01,\\n           6.5527e-01,  1.4104e-01, -7.1430e-01, -6.7695e-01,  2.5509e-01,\\n           8.1092e-01,  2.1964e-01, -3.8864e-01, -2.6910e-01, -5.2928e-01,\\n          -1.5765e-01]],\\n\\n        [[ 5.4998e-01, -1.0341e+00,  1.2665e-01,  1.1639e-01,  6.3071e-01,\\n           9.2799e-01,  1.1926e-01, -2.5175e-02,  1.0927e-01,  4.1401e-01,\\n          -6.0166e-01, -7.8037e-01,  2.3954e-01,  5.5774e-01,  5.8185e-01,\\n          -2.2241e-01,  5.0221e-01,  4.2605e-01,  9.6648e-03,  7.0864e-01,\\n           1.9520e-01,  2.5846e-01,  7.2891e-02,  1.6031e-01, -4.9231e-01,\\n          -4.2171e-01,  5.6706e-01, -1.0437e-01, -8.1088e-01,  8.4030e-01,\\n          -4.4900e-01,  5.2911e-01,  9.9639e-01,  2.6459e-01,  5.7423e-01,\\n          -6.1536e-01,  1.4955e-01, -7.4051e-01, -5.1943e-01,  6.0233e-01,\\n          -1.6532e-01]],\\n\\n        [[-2.0030e-01, -1.1772e-01, -1.7717e-02, -4.9251e-01,  5.5693e-01,\\n           1.3960e+00,  5.6276e-01,  8.1380e-01,  5.0433e-01,  6.3368e-01,\\n          -8.0024e-02, -8.6109e-01, -3.0680e-01, -1.6004e-01, -2.5818e-01,\\n           5.9385e-01,  2.9805e-04,  8.9716e-01,  6.6300e-01,  9.9566e-01,\\n          -5.1352e-01, -1.0402e+00, -1.4929e-01,  4.5068e-01, -3.5177e-01,\\n          -1.5848e-01, -5.2013e-01,  1.0469e+00, -1.1266e+00,  7.2700e-01,\\n          -1.8127e-01, -3.1319e-01,  1.4969e-01, -2.9587e-01, -4.6577e-01,\\n           1.7808e-01,  7.9248e-01, -6.1970e-01,  1.1871e-02,  3.6187e-02,\\n          -3.1269e-01]]], grad_fn=<ViewBackward0>)\\nnext_loss=tensor(0.5459, grad_fn=<NllLossBackward0>)\\nmask_loss=tensor(nan, grad_fn=<NllLossBackward0>)\\ntotal_loss=36.154011249542236\\n bert_inputs=tensor([[ 2],\\n        [ 5],\\n        [ 6],\\n        [18],\\n        [10],\\n        [16],\\n        [23],\\n        [17],\\n        [ 3],\\n        [24],\\n        [18],\\n        [10],\\n        [ 5],\\n        [16],\\n        [22],\\n        [ 5],\\n        [17],\\n        [ 3]])\\nbert_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1]])\\nsegment_labels=tensor([[1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [1],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2],\\n        [2]])\\nis_nexts=tensor([1])'},\n",
       " {'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (4, 4, 6, 0.2, 'adam', 1e-05, 0.1, 64),\n",
       "  'message': \"Error: 'accuracy'\"},\n",
       " {'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (16, 10, 8, 0.2, 'adam', 0.0001, 0.3, 64),\n",
       "  'message': \"Error: 'accuracy'\"},\n",
       " {'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (16, 10, 2, 0.3, 'sgd', 0.0001, 0.4, 4),\n",
       "  'message': \"Error: 'accuracy'\"},\n",
       " {'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (4, 8, 6, 0.1, 'sgd', 0.01, 0.1, 16),\n",
       "  'message': \"Error: 'accuracy'\"},\n",
       " {'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (16, 10, 8, 0.3, 'adam', 0.0001, 0.1, 16),\n",
       "  'message': \"Error: 'accuracy'\"},\n",
       " {'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (4, 10, 4, 0.4, 'adam', 0.01, 0.4, 64),\n",
       "  'message': \"Error: 'accuracy'\"},\n",
       " {'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (4, 4, 6, 0.4, 'adam', 0.0001, 0.4, 4),\n",
       "  'message': \"Error: 'accuracy'\"},\n",
       " {'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (16, 10, 6, 0.4, 'adam', 0.0001, 0.3, 16),\n",
       "  'message': \"Error: 'accuracy'\"},\n",
       " {'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (4, 6, 6, 0.2, 'sgd', 1e-05, 0.2, 4),\n",
       "  'message': \"Error: 'accuracy'\"},\n",
       " {'loss': inf,\n",
       "  'accurracy': inf,\n",
       "  'f1': inf,\n",
       "  'hiperparametros': (32, 6, 8, 0.3, 'sgd', 0.01, 0.4, 32),\n",
       "  'message': \"Error: 'accuracy'\"}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.LOGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44445986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759ce8a4d4b548dbb6a0a193bafbc23c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d03a52dd9794c05b2fb4bf9a53b39e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78009a409c704fa1b1739f1cd5d6c13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c57276aa929433d8db1ff28ae34291b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91d71dce98143b58e572b71c010b78b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4430164872f4816b12f85cfe352cebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc5690de0774ba3a86f6863de9749c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91279757ddf948f888e0f34a1c3ae84a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b57f1089a114cab806abae1e430aa54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1784f4cc36a64caba3b8ad4fb549e528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945efb3671494696a8bc83b32dc6c799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.N_EPOCHS = 10\n",
    "mejor_punto = trainer.puntos[mejor_punto_idx]\n",
    "trainer.TRAINING_IN_EARNEST = True\n",
    "results = trainer.ejecutar_punto(mejor_punto)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
