{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación del dataset para oraciones de relaciones lógicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from src.config import PATHS\n",
    "from src.utils.utils_vocab import BasicTokenizer\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = PATHS[\"training_data_folder\"]\n",
    "tokenizer_folder = PATHS[\"tokenizer_folder\"]\n",
    "\n",
    "raw_dataset =  dataset_folder / 'equivalencia_5.csv'\n",
    "# raw_dataset = 'equivalencia_10.csv'\n",
    "# raw_dataset = 'equivalencia_15.csv'\n",
    "# raw_dataset = 'equivalencia_20.csv'\n",
    "\n",
    "tokenizer_file = tokenizer_folder / 'tokenizer_5.pkl'\n",
    "# tokenizer_file = 'tokenizer_10.pkl'\n",
    "# tokenizer_file = 'tokenizer_15.pkl'\n",
    "# tokenizer_file = 'tokenizer_20.pkl'\n",
    "\n",
    "csv_file_path = dataset_folder / 'bert_data_equivalencia_5.csv'\n",
    "# csv_file_path ='bert_data_equivalencia_10.csv'\n",
    "# csv_file_path ='bert_data_equivalencia_15.csv'\n",
    "# csv_file_path ='bert_data_equivalencia_20.csv'\n",
    "\n",
    "jabberwockie_dataset = dataset_folder / 'equivalencia_jabberwockie_5.csv'\n",
    "# csv_file_path ='bert_data_equivalencia_jabberwockie_5.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos el tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de oraciones dataset normal y jabberwockie: 21300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence 1</th>\n",
       "      <th>Sentence 2</th>\n",
       "      <th>Relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21297</th>\n",
       "      <td>algún jufzyl drifla o brilca</td>\n",
       "      <td>ningún jufzyl drifla o brilca</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21298</th>\n",
       "      <td>algún jufzyl drifla o brunza</td>\n",
       "      <td>ningún jufzyl drifla o brunza</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21299</th>\n",
       "      <td>algún jufzyl drifla o dernea</td>\n",
       "      <td>ningún jufzyl drifla o dernea</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Sentence 1                      Sentence 2  Relation\n",
       "21297  algún jufzyl drifla o brilca    ningún jufzyl drifla o brilca         0\n",
       "21298  algún jufzyl drifla o brunza    ningún jufzyl drifla o brunza         0\n",
       "21299  algún jufzyl drifla o dernea    ningún jufzyl drifla o dernea         0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df1 = pd.read_csv(raw_dataset, names=['Sentence 1', 'Sentence 2', 'Relation'])\n",
    "words_jabberwockie = pd.read_csv(jabberwockie_dataset, names=['Sentence 1', 'Sentence 2', 'Relation'])\n",
    "words_df = pd.concat([words_df1, words_jabberwockie], ignore_index=True)\n",
    "print(f'Cantidad de oraciones dataset normal y jabberwockie:', words_df.shape[0])\n",
    "words_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no todo abuelo alegre acuerda ', 'no todo abuelo alto acuerda ', 'no todo abuelo amargo acuerda ', 'no todo abuelo amplio acuerda ', 'no todo abuelo amarillo acuerda ', 'no todo abuelo alegre aguanta ', 'no todo abuelo alto aguanta ', 'no todo abuelo amargo aguanta ', 'no todo abuelo amplio aguanta ', 'no todo abuelo amarillo aguanta ']\n",
      "42600\n"
     ]
    }
   ],
   "source": [
    "words = list(words_df.iloc[:,0].values)\n",
    "words += list(words_df.iloc[:,1].values)\n",
    "print(words[:10])\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alce', 'drifla', 'alegre', 'albañil', 'y', 'agujero', 'amargo', 'todo', 'amarillo', 'ama', 'flexivo', 'claribundo', 'alto', 'no', 'dernea', 'jufzyl', 'aguanta', 'flakle', 'amplio', 'anochece', 'algún', 'actor', 'brilca', 'brispado', 'florido', 'brunza', 'flajuf', 'amanece', 'dormínico', 'ningún', 'bliscea', 'jufmoq', 'abuelo', 'acuerda', 'blicket', 'o']\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "y = [w.strip().split(' ')  for w in words]\n",
    "y = [x for w in y for x in w]\n",
    "y = [w for w in y if w != '']\n",
    "y = list(set(y))\n",
    "print(y)\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define special symbols for the tokenizer\n",
    "special_symbols = ['[UNK]', '[PAD]', '[CLS]', '[SEP]', '[MASK]']\n",
    "\n",
    "# Create tokenizer from words\n",
    "\n",
    "simple_tokenizer = lambda tokens_string: tokens_string.strip().split()\n",
    "tokenizer = BasicTokenizer(simple_tokenizer, special_symbols)\n",
    "tokenizer.initialize_from_iterable(words)\n",
    "\n",
    "# Save to file\n",
    "\n",
    "tokenizer.save(tokenizer_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario: 41\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(tokenizer.itos)\n",
    "print(f'Tamaño del vocabulario: {VOCAB_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', '[PAD]', '[CLS]', '[SEP]', '[MASK]', 'no', 'todo', 'abuelo', 'alegre', 'acuerda', 'alto', 'amargo', 'amplio', 'amarillo', 'aguanta', 'ama', 'amanece', 'anochece', 'actor', 'agujero', 'albañil', 'alce', 'y', 'o', 'algún', 'blicket', 'brispado', 'bliscea', 'claribundo', 'dormínico', 'florido', 'flexivo', 'brilca', 'brunza', 'dernea', 'drifla', 'flajuf', 'flakle', 'jufmoq', 'jufzyl', 'ningún']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de oraciones dataset normal: (10650, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence 1</th>\n",
       "      <th>sentence 2</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10645</th>\n",
       "      <td>algún alce amanece o anochece</td>\n",
       "      <td>ningún alce amanece o anochece</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10646</th>\n",
       "      <td>algún alce anochece o acuerda</td>\n",
       "      <td>ningún alce anochece o acuerda</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10647</th>\n",
       "      <td>algún alce anochece o aguanta</td>\n",
       "      <td>ningún alce anochece o aguanta</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10648</th>\n",
       "      <td>algún alce anochece o ama</td>\n",
       "      <td>ningún alce anochece o ama</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10649</th>\n",
       "      <td>algún alce anochece o amanece</td>\n",
       "      <td>ningún alce anochece o amanece</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           sentence 1                       sentence 2  \\\n",
       "10645  algún alce amanece o anochece    ningún alce amanece o anochece   \n",
       "10646  algún alce anochece o acuerda    ningún alce anochece o acuerda   \n",
       "10647  algún alce anochece o aguanta    ningún alce anochece o aguanta   \n",
       "10648      algún alce anochece o ama        ningún alce anochece o ama   \n",
       "10649  algún alce anochece o amanece    ningún alce anochece o amanece   \n",
       "\n",
       "       relation  \n",
       "10645         0  \n",
       "10646         0  \n",
       "10647         0  \n",
       "10648         0  \n",
       "10649         0  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df_raw = pd.read_csv(raw_dataset, names=['sentence 1', 'sentence 2', 'relation'])\n",
    "# sentences_df = pd.read_csv(jabberwockie_dataset, names=['sentence 1', 'sentence 2', 'relation'])\n",
    "print('Cantidad de oraciones dataset normal:', sentences_df_raw.shape)\n",
    "sentences_df_raw.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence 1</th>\n",
       "      <th>sentence 2</th>\n",
       "      <th>relation</th>\n",
       "      <th>tokens sentence 1</th>\n",
       "      <th>tokens sentence 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no todo abuelo alegre acuerda</td>\n",
       "      <td>algún abuelo alegre no acuerda</td>\n",
       "      <td>1</td>\n",
       "      <td>[no, todo, abuelo, alegre, acuerda]</td>\n",
       "      <td>[algún, abuelo, alegre, no, acuerda]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no todo abuelo alto acuerda</td>\n",
       "      <td>algún abuelo alto no acuerda</td>\n",
       "      <td>1</td>\n",
       "      <td>[no, todo, abuelo, alto, acuerda]</td>\n",
       "      <td>[algún, abuelo, alto, no, acuerda]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no todo abuelo amargo acuerda</td>\n",
       "      <td>algún abuelo amargo no acuerda</td>\n",
       "      <td>1</td>\n",
       "      <td>[no, todo, abuelo, amargo, acuerda]</td>\n",
       "      <td>[algún, abuelo, amargo, no, acuerda]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no todo abuelo amplio acuerda</td>\n",
       "      <td>algún abuelo amplio no acuerda</td>\n",
       "      <td>1</td>\n",
       "      <td>[no, todo, abuelo, amplio, acuerda]</td>\n",
       "      <td>[algún, abuelo, amplio, no, acuerda]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no todo abuelo amarillo acuerda</td>\n",
       "      <td>algún abuelo amarillo no acuerda</td>\n",
       "      <td>1</td>\n",
       "      <td>[no, todo, abuelo, amarillo, acuerda]</td>\n",
       "      <td>[algún, abuelo, amarillo, no, acuerda]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         sentence 1                         sentence 2  \\\n",
       "0    no todo abuelo alegre acuerda      algún abuelo alegre no acuerda   \n",
       "1      no todo abuelo alto acuerda        algún abuelo alto no acuerda   \n",
       "2    no todo abuelo amargo acuerda      algún abuelo amargo no acuerda   \n",
       "3    no todo abuelo amplio acuerda      algún abuelo amplio no acuerda   \n",
       "4  no todo abuelo amarillo acuerda    algún abuelo amarillo no acuerda   \n",
       "\n",
       "   relation                      tokens sentence 1  \\\n",
       "0         1    [no, todo, abuelo, alegre, acuerda]   \n",
       "1         1      [no, todo, abuelo, alto, acuerda]   \n",
       "2         1    [no, todo, abuelo, amargo, acuerda]   \n",
       "3         1    [no, todo, abuelo, amplio, acuerda]   \n",
       "4         1  [no, todo, abuelo, amarillo, acuerda]   \n",
       "\n",
       "                        tokens sentence 2  \n",
       "0    [algún, abuelo, alegre, no, acuerda]  \n",
       "1      [algún, abuelo, alto, no, acuerda]  \n",
       "2    [algún, abuelo, amargo, no, acuerda]  \n",
       "3    [algún, abuelo, amplio, no, acuerda]  \n",
       "4  [algún, abuelo, amarillo, no, acuerda]  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df_raw['tokens sentence 1'] = sentences_df_raw['sentence 1'].apply(lambda x: tokenizer.encode(x).tokens)\n",
    "sentences_df_raw['tokens sentence 2'] = sentences_df_raw['sentence 2'].apply(lambda x: tokenizer.encode(x).tokens)\n",
    "sentences_df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bernoulli_true_false(p):\n",
    "    # Create a Bernoulli distribution with probability p\n",
    "    bernoulli_dist = torch.distributions.Bernoulli(torch.tensor([p]))\n",
    "    # Sample from this distribution and convert 1 to True and 0 to False\n",
    "    return bernoulli_dist.sample().item() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Masking(token):\n",
    "\n",
    "    # Don't mask [SEP] token\n",
    "    if token == '[SEP]':\n",
    "        return token, '[PAD]'\n",
    "\n",
    "    # Decide whether to mask this token (50% chance)\n",
    "    # mask = bernoulli_true_false(0.5)\n",
    "    mask = bernoulli_true_false(0.25)\n",
    "\n",
    "    # If mask is False, immediately return with '[PAD]' label\n",
    "    if not mask:\n",
    "        return token, '[PAD]'\n",
    "\n",
    "    # If mask is True, proceed with further operations\n",
    "    # Randomly decide on an operation (20% chance each)\n",
    "    # random_opp = bernoulli_true_false(0.2)\n",
    "    random_opp = bernoulli_true_false(0.1)\n",
    "\n",
    "    random_swich = bernoulli_true_false(0.5)\n",
    "\n",
    "    # Case 1: If mask, random_opp, and random_swich are True\n",
    "    if random_opp and random_swich:\n",
    "        # Replace the token with '[MASK]' and set label to a random token\n",
    "        token_ = '[MASK]'\n",
    "        mask_label = tokenizer.decode(torch.randint(0, VOCAB_SIZE, (1,)))[0]\n",
    "\n",
    "    # Case 2: If mask and random_opp are True, but random_swich is False\n",
    "    elif random_opp and not random_swich:\n",
    "        # Leave the token unchanged and set label to the same token\n",
    "        token_ = token\n",
    "        mask_label = token\n",
    "\n",
    "    # Case 3: If mask is True, but random_opp is False\n",
    "    else:\n",
    "        # Replace the token with '[MASK]' and set label to the original token\n",
    "        token_ = '[MASK]'\n",
    "        mask_label = token\n",
    "\n",
    "    return token_, mask_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abuelo abuelo \t Actual token *abuelo* is replaced with random token #abuelo#\n",
      "abuelo [PAD] \t Actual token *abuelo* is left unchanged\n",
      "abuelo abuelo \t Actual token *abuelo* is replaced with random token #abuelo#\n",
      "[MASK] abuelo \t Actual token *abuelo* is masked with '[MASK]'\n",
      "abuelo [PAD] \t Actual token *abuelo* is left unchanged\n",
      "abuelo [PAD] \t Actual token *abuelo* is left unchanged\n",
      "[MASK] abuelo \t Actual token *abuelo* is masked with '[MASK]'\n",
      "abuelo [PAD] \t Actual token *abuelo* is left unchanged\n",
      "[MASK] abuelo \t Actual token *abuelo* is masked with '[MASK]'\n",
      "abuelo [PAD] \t Actual token *abuelo* is left unchanged\n"
     ]
    }
   ],
   "source": [
    "# Test Masking\n",
    "# torch.manual_seed(100)\n",
    "for l in range(10):\n",
    "  token=\"abuelo\"\n",
    "  token_, label=Masking(token)\n",
    "  if token==token_ and label==\"[PAD]\":\n",
    "    print(token_,label,f\"\\t Actual token *{token}* is left unchanged\")\n",
    "  elif token_==\"[MASK]\" and label==token:\n",
    "    print(token_,label,f\"\\t Actual token *{token}* is masked with '{token_}'\")\n",
    "  else:\n",
    "    print(token_,label,f\"\\t Actual token *{token}* is replaced with random token #{label}#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_mlm(tokens):\n",
    "    \"\"\"\n",
    "    Prepares tokenized text for BERT's Masked Language Model (MLM) training.\n",
    "\n",
    "    \"\"\"\n",
    "    bert_input = []  # List to store sentences processed for BERT's MLM\n",
    "    bert_label = []  # List to store labels for each token (mask, random, or unchanged)\n",
    "\n",
    "    for token in tokens:\n",
    "        # Apply BERT's MLM masking strategy to the token\n",
    "        masked_token, mask_label = Masking(token)\n",
    "\n",
    "        # Append the processed token and its label to the current sentence and label list\n",
    "        bert_input.append(masked_token)\n",
    "        bert_label.append(mask_label)\n",
    "\n",
    "    # Return the prepared lists for BERT's MLM training\n",
    "    return bert_input, bert_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without raw tokens: \t  \n",
      " \t original_input is: \t  algún abuelo alegre no ama \n",
      " \t bert_input is: \t  ['[MASK]', 'abuelo', 'alegre', 'no', 'ama'] \n",
      " \t bert_label is: \t  ['algún', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(200)\n",
    "# original_input=\"The sun sets behind the distant mountains.\"\n",
    "original_input = \"algún abuelo alegre no ama\"\n",
    "tokens=tokenizer.encode(original_input).tokens\n",
    "bert_input, bert_label= prepare_for_mlm(tokens)\n",
    "print(\"Without raw tokens: \\t \",\"\\n \\t original_input is: \\t \", original_input,\"\\n \\t bert_input is: \\t \", bert_input,\"\\n \\t bert_label is: \\t \", bert_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad aumentada de oraciones: 53250\n"
     ]
    }
   ],
   "source": [
    "sentences_df = pd.concat([sentences_df_raw]*5, ignore_index=True)\n",
    "print('Cantidad aumentada de oraciones:', sentences_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando bert_input_label 1...\n",
      "Creando bert_label 1...\n",
      "Creando bert_input_label 2...\n",
      "Creando bert_label 2...\n",
      "¡Listo! Cantidad de oraciones final: 53250\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence 1</th>\n",
       "      <th>sentence 2</th>\n",
       "      <th>relation</th>\n",
       "      <th>tokens sentence 1</th>\n",
       "      <th>tokens sentence 2</th>\n",
       "      <th>bert_input 1</th>\n",
       "      <th>bert_label 1</th>\n",
       "      <th>bert_input 2</th>\n",
       "      <th>bert_label 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no todo abuelo alegre acuerda</td>\n",
       "      <td>algún abuelo alegre no acuerda</td>\n",
       "      <td>1</td>\n",
       "      <td>[no, todo, abuelo, alegre, acuerda]</td>\n",
       "      <td>[algún, abuelo, alegre, no, acuerda]</td>\n",
       "      <td>[no, [MASK], [MASK], alegre, acuerda]</td>\n",
       "      <td>[[PAD], todo, abuelo, [PAD], [PAD]]</td>\n",
       "      <td>[algún, abuelo, alegre, no, acuerda]</td>\n",
       "      <td>[[PAD], [PAD], [PAD], [PAD], [PAD]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no todo abuelo alto acuerda</td>\n",
       "      <td>algún abuelo alto no acuerda</td>\n",
       "      <td>1</td>\n",
       "      <td>[no, todo, abuelo, alto, acuerda]</td>\n",
       "      <td>[algún, abuelo, alto, no, acuerda]</td>\n",
       "      <td>[no, todo, abuelo, alto, [MASK]]</td>\n",
       "      <td>[[PAD], [PAD], [PAD], [PAD], acuerda]</td>\n",
       "      <td>[algún, abuelo, [MASK], no, acuerda]</td>\n",
       "      <td>[algún, abuelo, alto, [PAD], [PAD]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no todo abuelo amargo acuerda</td>\n",
       "      <td>algún abuelo amargo no acuerda</td>\n",
       "      <td>1</td>\n",
       "      <td>[no, todo, abuelo, amargo, acuerda]</td>\n",
       "      <td>[algún, abuelo, amargo, no, acuerda]</td>\n",
       "      <td>[no, todo, abuelo, amargo, acuerda]</td>\n",
       "      <td>[[PAD], [PAD], abuelo, [PAD], acuerda]</td>\n",
       "      <td>[algún, abuelo, amargo, no, acuerda]</td>\n",
       "      <td>[[PAD], [PAD], [PAD], [PAD], [PAD]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no todo abuelo amplio acuerda</td>\n",
       "      <td>algún abuelo amplio no acuerda</td>\n",
       "      <td>1</td>\n",
       "      <td>[no, todo, abuelo, amplio, acuerda]</td>\n",
       "      <td>[algún, abuelo, amplio, no, acuerda]</td>\n",
       "      <td>[no, todo, abuelo, amplio, acuerda]</td>\n",
       "      <td>[[PAD], [PAD], [PAD], [PAD], [PAD]]</td>\n",
       "      <td>[algún, [MASK], [MASK], no, acuerda]</td>\n",
       "      <td>[[PAD], abuelo, amplio, [PAD], [PAD]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no todo abuelo amarillo acuerda</td>\n",
       "      <td>algún abuelo amarillo no acuerda</td>\n",
       "      <td>1</td>\n",
       "      <td>[no, todo, abuelo, amarillo, acuerda]</td>\n",
       "      <td>[algún, abuelo, amarillo, no, acuerda]</td>\n",
       "      <td>[no, todo, abuelo, [MASK], acuerda]</td>\n",
       "      <td>[[PAD], [PAD], [PAD], amarillo, acuerda]</td>\n",
       "      <td>[algún, abuelo, amarillo, no, acuerda]</td>\n",
       "      <td>[[PAD], [PAD], [PAD], no, [PAD]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         sentence 1                         sentence 2  \\\n",
       "0    no todo abuelo alegre acuerda      algún abuelo alegre no acuerda   \n",
       "1      no todo abuelo alto acuerda        algún abuelo alto no acuerda   \n",
       "2    no todo abuelo amargo acuerda      algún abuelo amargo no acuerda   \n",
       "3    no todo abuelo amplio acuerda      algún abuelo amplio no acuerda   \n",
       "4  no todo abuelo amarillo acuerda    algún abuelo amarillo no acuerda   \n",
       "\n",
       "   relation                      tokens sentence 1  \\\n",
       "0         1    [no, todo, abuelo, alegre, acuerda]   \n",
       "1         1      [no, todo, abuelo, alto, acuerda]   \n",
       "2         1    [no, todo, abuelo, amargo, acuerda]   \n",
       "3         1    [no, todo, abuelo, amplio, acuerda]   \n",
       "4         1  [no, todo, abuelo, amarillo, acuerda]   \n",
       "\n",
       "                        tokens sentence 2  \\\n",
       "0    [algún, abuelo, alegre, no, acuerda]   \n",
       "1      [algún, abuelo, alto, no, acuerda]   \n",
       "2    [algún, abuelo, amargo, no, acuerda]   \n",
       "3    [algún, abuelo, amplio, no, acuerda]   \n",
       "4  [algún, abuelo, amarillo, no, acuerda]   \n",
       "\n",
       "                            bert_input 1  \\\n",
       "0  [no, [MASK], [MASK], alegre, acuerda]   \n",
       "1       [no, todo, abuelo, alto, [MASK]]   \n",
       "2    [no, todo, abuelo, amargo, acuerda]   \n",
       "3    [no, todo, abuelo, amplio, acuerda]   \n",
       "4    [no, todo, abuelo, [MASK], acuerda]   \n",
       "\n",
       "                               bert_label 1  \\\n",
       "0       [[PAD], todo, abuelo, [PAD], [PAD]]   \n",
       "1     [[PAD], [PAD], [PAD], [PAD], acuerda]   \n",
       "2    [[PAD], [PAD], abuelo, [PAD], acuerda]   \n",
       "3       [[PAD], [PAD], [PAD], [PAD], [PAD]]   \n",
       "4  [[PAD], [PAD], [PAD], amarillo, acuerda]   \n",
       "\n",
       "                             bert_input 2  \\\n",
       "0    [algún, abuelo, alegre, no, acuerda]   \n",
       "1    [algún, abuelo, [MASK], no, acuerda]   \n",
       "2    [algún, abuelo, amargo, no, acuerda]   \n",
       "3    [algún, [MASK], [MASK], no, acuerda]   \n",
       "4  [algún, abuelo, amarillo, no, acuerda]   \n",
       "\n",
       "                            bert_label 2  \n",
       "0    [[PAD], [PAD], [PAD], [PAD], [PAD]]  \n",
       "1    [algún, abuelo, alto, [PAD], [PAD]]  \n",
       "2    [[PAD], [PAD], [PAD], [PAD], [PAD]]  \n",
       "3  [[PAD], abuelo, amplio, [PAD], [PAD]]  \n",
       "4       [[PAD], [PAD], [PAD], no, [PAD]]  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Creando bert_input_label 1...')\n",
    "sentences_df['bert_input_label 1'] = sentences_df['tokens sentence 1'].apply(lambda x: prepare_for_mlm(x))\n",
    "print('Creando bert_label 1...')\n",
    "sentences_df['bert_input 1'] = sentences_df['bert_input_label 1'].apply(lambda x: x[0])\n",
    "sentences_df['bert_label 1'] = sentences_df['bert_input_label 1'].apply(lambda x: x[1])\n",
    "\n",
    "print('Creando bert_input_label 2...')\n",
    "sentences_df['bert_input_label 2'] = sentences_df['tokens sentence 2'].apply(lambda x: prepare_for_mlm(x))\n",
    "print('Creando bert_label 2...')\n",
    "sentences_df['bert_input 2'] = sentences_df['bert_input_label 2'].apply(lambda x: x[0])\n",
    "sentences_df['bert_label 2'] = sentences_df['bert_input_label 2'].apply(lambda x: x[1])\n",
    "del sentences_df['bert_input_label 1']\n",
    "del sentences_df['bert_input_label 2']\n",
    "print('¡Listo! Cantidad de oraciones final:', sentences_df.shape[0])\n",
    "sentences_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentences_pair = sentences_df[['bert_input 1', 'bert_input 2']].values.tolist()\n",
    "input_masked_labels_pair = sentences_df[['bert_label 1', 'bert_label 2']].values.tolist()\n",
    "relations = sentences_df['relation'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_for_nsp(input_sentences_pair, input_masked_labels_pair, relations):\n",
    "    \"\"\"\n",
    "    Prepares data for understanding logical relationship.\n",
    "\n",
    "    Args:\n",
    "    input_sentences (list): List of tokenized sentences.\n",
    "    input_masked_labels (list): Corresponding list of masked labels for the sentences.\n",
    "\n",
    "    Returns:\n",
    "    bert_input (list): List of sentence pairs for BERT input.\n",
    "    bert_label (list): List of masked labels for the sentence pairs.\n",
    "    is_next (list): Binary label list where 1 indicates 'logical relationship' and 0 indicates 'not logical relationship'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Verify that both input lists are of the same length and have a sufficient number of sentences\n",
    "    if len(input_sentences_pair) != len(input_masked_labels_pair):\n",
    "        raise ValueError(\"Both lists, input_sentences_pair and input_masked_labels_pair, must have the same number of items.\")\n",
    "    if len(input_sentences_pair) != len(relations):\n",
    "        raise ValueError(\"Both lists, input_sentences_pair and relations, must have the same number of items.\")\n",
    "\n",
    "    bert_input = []\n",
    "    bert_label = []\n",
    "    is_next = []\n",
    "\n",
    "    for sentence_pair, masked_pair, relation in zip(input_sentences_pair, input_masked_labels_pair, relations):\n",
    "        # append list and add  '[CLS]' and  '[SEP]' tokens\n",
    "        bert_input.append([['[CLS]'] + sentence_pair[0] + ['[SEP]'], sentence_pair[1] + ['[SEP]']])\n",
    "        bert_label.append([['[PAD]'] + masked_pair[0] + ['[PAD]'], masked_pair[1]+ ['[PAD]']])\n",
    "        is_next.append(relation)  # Label 1 indicates these sentences have the required logical relationship\n",
    "\n",
    "    return bert_input, bert_label, is_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs, bert_labels, is_nexts = process_for_nsp(input_sentences_pair, input_masked_labels_pair, relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['[CLS]', 'no', '[MASK]', '[MASK]', 'alegre', 'acuerda', '[SEP]'],\n",
       "  ['algún', 'abuelo', 'alegre', 'no', 'acuerda', '[SEP]']],\n",
       " [['[CLS]', 'no', 'todo', 'abuelo', 'alto', '[MASK]', '[SEP]'],\n",
       "  ['algún', 'abuelo', '[MASK]', 'no', 'acuerda', '[SEP]']],\n",
       " [['[CLS]', 'no', 'todo', 'abuelo', 'amargo', 'acuerda', '[SEP]'],\n",
       "  ['algún', 'abuelo', 'amargo', 'no', 'acuerda', '[SEP]']],\n",
       " [['[CLS]', 'no', 'todo', 'abuelo', 'amplio', 'acuerda', '[SEP]'],\n",
       "  ['algún', '[MASK]', '[MASK]', 'no', 'acuerda', '[SEP]']],\n",
       " [['[CLS]', 'no', 'todo', 'abuelo', '[MASK]', 'acuerda', '[SEP]'],\n",
       "  ['algún', 'abuelo', 'amarillo', 'no', 'acuerda', '[SEP]']],\n",
       " [['[CLS]', 'no', 'todo', 'abuelo', 'alegre', 'aguanta', '[SEP]'],\n",
       "  ['[MASK]', 'abuelo', 'alegre', 'no', 'aguanta', '[SEP]']],\n",
       " [['[CLS]', '[MASK]', 'todo', 'abuelo', 'alto', 'aguanta', '[SEP]'],\n",
       "  ['algún', '[MASK]', '[MASK]', 'no', 'aguanta', '[SEP]']],\n",
       " [['[CLS]', 'no', 'todo', 'abuelo', 'amargo', 'aguanta', '[SEP]'],\n",
       "  ['algún', 'abuelo', '[MASK]', '[MASK]', '[MASK]', '[SEP]']],\n",
       " [['[CLS]', '[MASK]', 'todo', '[MASK]', 'amplio', 'aguanta', '[SEP]'],\n",
       "  ['algún', 'abuelo', 'amplio', 'no', 'aguanta', '[SEP]']],\n",
       " [['[CLS]', '[MASK]', '[MASK]', 'abuelo', 'amarillo', 'aguanta', '[SEP]'],\n",
       "  ['algún', 'abuelo', 'amarillo', 'no', 'aguanta', '[SEP]']]]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_inputs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_bert_final_inputs(bert_inputs, bert_labels, is_nexts, to_tensor=True):\n",
    "    \"\"\"\n",
    "    Prepare the final input lists for BERT training.\n",
    "    \"\"\"\n",
    "    def zero_pad_list_pair(pair_, pad='[PAD]'):\n",
    "        pair = deepcopy(pair_)\n",
    "        max_len = max(len(pair[0]), len(pair[1]))\n",
    "        #append [PAD] to each sentence in the pair till the maximum length reaches\n",
    "        pair[0].extend([pad] * (max_len - len(pair[0])))\n",
    "        pair[1].extend([pad] * (max_len - len(pair[1])))\n",
    "        return pair[0], pair[1]\n",
    "\n",
    "    #flatten the tensor\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    #transform tokens to vocab indices\n",
    "    tokens_to_index=lambda tokens: [tokenizer.stoi[token] for token in tokens]\n",
    "\n",
    "    bert_inputs_final, bert_labels_final, segment_labels_final, is_nexts_final = [], [], [], []\n",
    "\n",
    "    for bert_input, bert_label,is_next in zip(bert_inputs, bert_labels,is_nexts):\n",
    "        # Create segment labels for each pair of sentences\n",
    "        segment_label = [[1] * len(bert_input[0]), [2] * len(bert_input[1])]\n",
    "\n",
    "        # Zero-pad the bert_input and bert_label and segment_label\n",
    "        bert_input_padded = zero_pad_list_pair(bert_input)\n",
    "        bert_label_padded = zero_pad_list_pair(bert_label)\n",
    "        segment_label_padded = zero_pad_list_pair(segment_label,pad=0)\n",
    "\n",
    "        #convert to tensors\n",
    "        if to_tensor:\n",
    "\n",
    "            # Flatten the padded inputs and labels, transform tokens to their corresponding vocab indices, and convert them to tensors\n",
    "            # bert_inputs_final.append(torch.tensor(tokens_to_index(flatten(bert_input_padded)),dtype=torch.int64))\n",
    "            # bert_labels_final.append(torch.tensor(tokens_to_index(flatten(bert_label_padded)),dtype=torch.int64))\n",
    "            # segment_labels_final.append(torch.tensor(flatten(segment_label_padded),dtype=torch.int64))\n",
    "            bert_inputs_final.append(tokens_to_index(flatten(bert_input_padded)))\n",
    "            bert_labels_final.append(tokens_to_index(flatten(bert_label_padded)))\n",
    "            segment_labels_final.append(flatten(segment_label_padded))\n",
    "            is_nexts_final.append(is_next)\n",
    "\n",
    "        else:\n",
    "          # Flatten the padded inputs and labels\n",
    "            bert_inputs_final.append(flatten(bert_input_padded))\n",
    "            bert_labels_final.append(flatten(bert_label_padded))\n",
    "            segment_labels_final.append(flatten(segment_label_padded))\n",
    "            is_nexts_final.append(is_next)\n",
    "\n",
    "    return bert_inputs_final, bert_labels_final, segment_labels_final, is_nexts_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs_final, bert_labels_final, segment_labels_final, is_nexts_final = prepare_bert_final_inputs(bert_inputs, bert_labels, is_nexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 5, 4, 4, 8, 9, 3, 24, 7, 8, 5, 9, 3, 1],\n",
       " [2, 5, 6, 7, 10, 4, 3, 24, 7, 4, 5, 9, 3, 1],\n",
       " [2, 5, 6, 7, 11, 9, 3, 24, 7, 11, 5, 9, 3, 1],\n",
       " [2, 5, 6, 7, 12, 9, 3, 24, 4, 4, 5, 9, 3, 1],\n",
       " [2, 5, 6, 7, 4, 9, 3, 24, 7, 13, 5, 9, 3, 1],\n",
       " [2, 5, 6, 7, 8, 14, 3, 4, 7, 8, 5, 14, 3, 1],\n",
       " [2, 4, 6, 7, 10, 14, 3, 24, 4, 4, 5, 14, 3, 1],\n",
       " [2, 5, 6, 7, 11, 14, 3, 24, 7, 4, 4, 4, 3, 1],\n",
       " [2, 4, 6, 4, 12, 14, 3, 24, 7, 12, 5, 14, 3, 1],\n",
       " [2, 4, 4, 7, 13, 14, 3, 24, 7, 13, 5, 14, 3, 1]]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_inputs_final[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 9, 1, 24, 7, 10, 1, 1, 1, 1],\n",
       " [1, 1, 1, 7, 1, 9, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 7, 12, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 13, 9, 1, 1, 1, 1, 5, 1, 1, 1],\n",
       " [1, 1, 6, 1, 8, 1, 1, 24, 1, 1, 1, 1, 1, 1],\n",
       " [1, 5, 1, 1, 1, 14, 1, 1, 7, 10, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 14, 1, 1, 1, 11, 5, 14, 1, 1],\n",
       " [1, 5, 1, 20, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 17, 6, 1, 1, 1, 1, 24, 1, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_labels_final[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0]]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_labels_final[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de oraciones en el dataset final: 53250\n"
     ]
    }
   ],
   "source": [
    "df_final = pd.DataFrame({\n",
    "    'bert_input': bert_inputs_final,\n",
    "    'bert_label': bert_labels_final,\n",
    "    'segment_label': segment_labels_final,\n",
    "    'relation': is_nexts_final\n",
    "})\n",
    "print('Cantidad de oraciones en el dataset final:', df_final.shape[0])\n",
    "\n",
    "df_final.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
